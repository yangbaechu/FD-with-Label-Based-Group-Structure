{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-11T12:19:49.817210Z",
     "iopub.status.busy": "2023-08-11T12:19:49.817006Z",
     "iopub.status.idle": "2023-08-11T12:19:51.338884Z",
     "shell.execute_reply": "2023-08-11T12:19:51.337819Z",
     "shell.execute_reply.started": "2023-08-11T12:19:49.817186Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from IPython.display import clear_output\n",
    "import os\n",
    "from copy import deepcopy\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import pytz\n",
    "import torch.nn as nn\n",
    "from sklearn.decomposition import PCA\n",
    "import random\n",
    "\n",
    "from helper import ExperimentLogger, display_train_stats\n",
    "from fl_devices import Server, Client\n",
    "from data_utils import generate_server_idcs, CustomSubset, split_3class_unbalanced, split_7plus3class_unbalanced\n",
    "from torchvision.models import mobilenet_v3_large\n",
    "from models import ConvNet, Representation\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from scipy.spatial import distance\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-11T12:19:51.340440Z",
     "iopub.status.busy": "2023-08-11T12:19:51.340166Z",
     "iopub.status.idle": "2023-08-11T12:19:51.344173Z",
     "shell.execute_reply": "2023-08-11T12:19:51.343465Z",
     "shell.execute_reply.started": "2023-08-11T12:19:51.340422Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "LOCAL_EPOCHS = 25\n",
    "N_CLIENTS = 100\n",
    "NUMBER_OF_CLUSTER = 3\n",
    "ALPHA = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-11T12:19:51.345337Z",
     "iopub.status.busy": "2023-08-11T12:19:51.345194Z",
     "iopub.status.idle": "2023-08-11T12:19:51.413661Z",
     "shell.execute_reply": "2023-08-11T12:19:51.412384Z",
     "shell.execute_reply.started": "2023-08-11T12:19:51.345323Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data = datasets.CIFAR10(root=\"CIFAR10/\", download=False)\n",
    "data = datasets.MNIST(root=\"MNIST/\", download=False)\n",
    "idcs = np.random.permutation(len(data))\n",
    "\n",
    "def cluster(server, clients, number_of_cluster):\n",
    "    label_predicted = pd.DataFrame()\n",
    "    # label_acc = pd.DataFrame()\n",
    "    for i, client in enumerate(clients):\n",
    "        pred = server.check_cluster(client.model)\n",
    "        # print(f'pred: {pred}')\n",
    "        label_predicted = pd.concat([label_predicted, pd.DataFrame(pred, index=[i])])\n",
    "        # label_acc = pd.concat([label_acc, pd.DataFrame(acc, index=[i])])\n",
    "    label_predicted.reset_index(drop=True, inplace=True)\n",
    "    label_predicted.fillna(0, inplace=True)\n",
    "    \n",
    "    print(f'predicted label')\n",
    "    print(label_predicted)\n",
    "\n",
    "    cluster_idcs = server.cluster_clients_GMM(label_predicted, number_of_cluster)\n",
    "    return label_predicted, cluster_idcs\n",
    "\n",
    "\n",
    "\n",
    "def get_cluster_averages(df, cluster_idcs):\n",
    "    cluster_averages = {}\n",
    "\n",
    "    for i, cluster in enumerate(cluster_idcs):\n",
    "        cluster_data = df.loc[cluster, :]\n",
    "        cluster_average = cluster_data.mean()\n",
    "        cluster_averages[i] = cluster_average\n",
    "\n",
    "    cluster_averages_df = pd.DataFrame(cluster_averages).T\n",
    "\n",
    "    # calculate percentage for each value in a row\n",
    "    cluster_percentages_df = cluster_averages_df.div(cluster_averages_df.sum(axis=1), axis=0).multiply(100)\n",
    "\n",
    "    # apply threshold and rounding\n",
    "    cluster_percentages_df = cluster_percentages_df.where(cluster_percentages_df >= 5, 0).round()\n",
    "\n",
    "    return cluster_percentages_df / 10\n",
    "\n",
    "\n",
    "def get_cluster_weights(cluster_logits, cluster_weight_per_class):\n",
    "    # Step 1: Find the class with the maximum value in each logit in cluster_logits\n",
    "    # Assuming the dimension for classes is the second one\n",
    "    max_classes = [torch.argmax(logit, dim=1) for logit in cluster_logits]\n",
    "    \n",
    "    print(max_classes)\n",
    "    cluster_weights = []\n",
    "    #c luster별로 \n",
    "    for i, iogits in enumerate(cluster_logits):\n",
    "        weights = []\n",
    "        for j, logit in enumerate(logits):\n",
    "            \n",
    "            # print(f'max_classes: {max_classes[i][j]}')\n",
    "            # print(\"Shape of cluster_weight_per_class[{}]: \".format(i), cluster_weight_per_class[i].shape)\n",
    "            weights.append(max_classes[i][j])\n",
    "        print(weights)\n",
    "        cluster_weights.append(weights)\n",
    "\n",
    "def visualize_clusters(label_predicted, clusters, real_cluster_distribution):\n",
    "    # Reduce the dimension of the data\n",
    "    pca = PCA(n_components=2)\n",
    "    label_predicted_pca = pca.fit_transform(label_predicted)\n",
    "\n",
    "    # Define colors for the clusters\n",
    "    colors = ['blue', 'red', 'green', 'purple', 'orange', 'yellow', 'black']\n",
    "\n",
    "    # Plot the clusters\n",
    "    plt.figure(figsize=(10,7))\n",
    "    \n",
    "    for i, cluster in enumerate(clusters):\n",
    "        plt.scatter(label_predicted_pca[cluster, 0], label_predicted_pca[cluster, 1], c=colors[i % len(colors)], label=f'Cluster {i+1}')\n",
    "\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # Print the real cluster distribution\n",
    "    print(\"Real cluster distribution:\", real_cluster_distribution)\n",
    "\n",
    "    # Calculate and print each client's cluster identity based on the real_cluster_distribution\n",
    "    n_clients = len(label_predicted)\n",
    "    cumulative_distribution = [0] + [sum(real_cluster_distribution[:i+1]) for i in range(len(real_cluster_distribution))]\n",
    "    client_cluster_id_real = [next((i for i, val in enumerate(cumulative_distribution) if val > client_idx / n_clients), -1) - 1 for client_idx in range(n_clients)]\n",
    "\n",
    "    print(\"Real cluster identity for each client:\", client_cluster_id_real)\n",
    "\n",
    "    # Print each client's cluster identity based on the clusters argument\n",
    "    client_cluster_id_predicted = [next((i for i, cluster in enumerate(clusters) if client_idx in cluster), -1) for client_idx in range(n_clients)]\n",
    "    print(\"Predicted cluster identity for each client:\", client_cluster_id_predicted)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def test_acc(server, clients, client_accs, cluster_accs, global_accs, client_distribution=[0.5, 0.3, 0.2]):\n",
    "    \n",
    "    # Get individual client accuracies\n",
    "    acc_clients = [client.evaluate() for client in clients]\n",
    "\n",
    "    # Compute the average accuracy for each client\n",
    "    client_acc = round(sum(acc_clients) / len(acc_clients), 3) if len(acc_clients) > 0 else 0\n",
    "    client_accs.append(client_acc)\n",
    "\n",
    "    # Compute cluster accuracies for this iteration\n",
    "    cluster_accs_iteration = []\n",
    "    start_idx = 0\n",
    "    for distribution in client_distribution:\n",
    "        end_idx = start_idx + int(distribution * len(clients))\n",
    "        cluster_acc = round(sum(acc_clients[start_idx:end_idx]) / (end_idx - start_idx), 3)\n",
    "        cluster_accs_iteration.append(cluster_acc)\n",
    "        start_idx = end_idx\n",
    "    cluster_accs.append(cluster_accs_iteration)\n",
    "    \n",
    "    accuracies = [server.evaluate_distil(client.model) for client in clients]\n",
    "    global_acc = round(np.mean(accuracies), 3)\n",
    "    global_accs.append(global_acc)\n",
    "    \n",
    "    return client_accs, cluster_accs, global_accs\n",
    "\n",
    "\n",
    "def get_global_logits(client_logits):\n",
    "    avg_logits = torch.mean(torch.stack(client_logits), dim=0)\n",
    "    return avg_logits\n",
    "\n",
    "def get_cluster_logits(client_logits, cluster_idcs):\n",
    "    cluster_logits = []\n",
    "    for i, cluster in enumerate(cluster_idcs):\n",
    "        cluster_client_logits = [client_logits[i] for i in cluster]\n",
    "        avg_cluster_logits = torch.mean(torch.stack(cluster_client_logits), dim=0)\n",
    "        cluster_logits.append(avg_cluster_logits)\n",
    "    return cluster_logits\n",
    "\n",
    "\n",
    "def get_cluster_averages(df, cluster_idcs):\n",
    "    cluster_averages = {}\n",
    "\n",
    "    for i, cluster in enumerate(cluster_idcs):\n",
    "        cluster_data = df.loc[cluster, :]\n",
    "        cluster_average = cluster_data.mean()\n",
    "        cluster_averages[i] = cluster_average\n",
    "\n",
    "    cluster_averages_df = pd.DataFrame(cluster_averages).T\n",
    "\n",
    "    # calculate percentage for each value in a row\n",
    "    cluster_percentages_df = cluster_averages_df.div(cluster_averages_df.sum(axis=1), axis=0).multiply(100)\n",
    "\n",
    "    # apply threshold and rounding\n",
    "    cluster_percentages_df = cluster_percentages_df.where(cluster_percentages_df >= 5, 0).round()\n",
    "\n",
    "    return cluster_percentages_df / 10\n",
    "\n",
    "\n",
    "# def get_cluster_weights(cluster_logits, cluster_weight_per_class):\n",
    "#     # Step 1: Find the class with the maximum value in each logit in cluster_logits\n",
    "#     # Assuming the dimension for classes is the second one\n",
    "#     max_classes = [torch.argmax(logit, dim=1) for logit in cluster_logits]\n",
    "    \n",
    "#     print(max_classes)\n",
    "#     cluster_weights = []\n",
    "#     #c luster별로 \n",
    "#     for i, iogits in enumerate(cluster_logits):\n",
    "#         weights = []\n",
    "#         for j, logit in enumerate(logits):\n",
    "            \n",
    "#             # print(f'max_classes: {max_classes[i][j]}')\n",
    "#             # print(\"Shape of cluster_weight_per_class[{}]: \".format(i), cluster_weight_per_class[i].shape)\n",
    "#             weights.append(max_classes[i][j])\n",
    "#         print(weights)\n",
    "#         cluster_weights.append(weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SimCLR_distill_experiments(total_client_data, distill_data, alpha, number_of_cluster, cluster_distribution):\n",
    "    print(f'number_of_cluster: {number_of_cluster}')\n",
    "    data_per_class=int(distill_data//10)\n",
    "    train_idcs, test_idcs = idcs[:total_client_data], idcs[total_client_data:(total_client_data + int(distill_data * 2))]\n",
    "    train_labels = data.targets\n",
    "    test_labels = data.targets\n",
    "    \n",
    "    server_idcs = generate_server_idcs(test_idcs, test_labels, int(distill_data//10))\n",
    "\n",
    "    # client_idcs = split_noniid(train_idcs, train_labels, alpha=alpha, n_clients=N_CLIENTS)\n",
    "    client_idcs = split_7plus3class_unbalanced(train_idcs, train_labels, N_CLIENTS, cluster_distribution)\n",
    "    \n",
    "    print('client idcs generated!')\n",
    "    client_data = [CustomSubset(data, idcs) for idcs in client_idcs]\n",
    "    test_data = CustomSubset(data, server_idcs, transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "    for i, client_datum in enumerate(client_data):\n",
    "        client_datum.subset_transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "    server = Server(ConvNet, lambda x : torch.optim.Adam(x, weight_decay=0.1),test_data)\n",
    "\n",
    "    clients = [Client(ConvNet, lambda x: torch.optim.Adam(x, weight_decay=0.1), dat, i) \n",
    "           for i, dat in enumerate(client_data) if len(dat) > 20]\n",
    "    \n",
    "    print(f'client count: {len(clients)}')\n",
    "\n",
    "    client_accs = []\n",
    "    cluster_accs = []\n",
    "    global_accs = []\n",
    "    client_logits = []\n",
    "    \n",
    "    # 1. Pre-Train Representaion with SimCLR\n",
    "    for epoch in range(LOCAL_EPOCHS):\n",
    "        for i, client in enumerate(clients):\n",
    "            client.learn_representation()\n",
    "    # 2. Train Local Major Class Classifier\n",
    "    for epoch in range(LOCAL_EPOCHS):\n",
    "        for i, client in enumerate(clients):\n",
    "            client.compute_weight_update(epochs=1)\n",
    "\n",
    "        if epoch % 5 == 0:\n",
    "            client_accs, cluster_accs, global_accs = test_acc(server, clients, client_accs, cluster_accs, global_accs, cluster_distribution)\n",
    "            print(f'client_acc: {client_accs[-1]}, cluster_acc: {cluster_distribution}: {cluster_accs[-1]},  global_acc: {global_accs[-1]}')\n",
    "    \n",
    "    # 3. Train In and Out- Class Classifier \n",
    "    # 2. get global loigt\n",
    "    for i, client in enumerate(clients):\n",
    "        if i == 0:\n",
    "            distill_data = server.get_clients_logit(client.model)\n",
    "            client_logits.append(distill_data[2])\n",
    "        else:\n",
    "            client_logits.append(server.get_clients_logit(client.model)[2])\n",
    "    global_logits = get_global_logits(client_logits)\n",
    "    \n",
    "    # 3.Distillation\n",
    "    for i, client in enumerate(clients):\n",
    "        if i % 10 == 0:\n",
    "            print(f'client {i} distill')\n",
    "        \n",
    "        client.distill((distill_data[0], global_logits))\n",
    "    \n",
    "    client_accs, cluster_accs, global_accs = test_acc(server, clients, client_accs, cluster_accs, global_accs, cluster_distribution)\n",
    "    \n",
    "    print(f'total_client_data: {total_client_data}, cluster_distribution: {cluster_distribution}')\n",
    "    print(f'first acc: {client_accs[0]}, {cluster_accs[0]}, {global_accs[0]}')\n",
    "    print(f'acc before distill: {client_accs[-2]}, {cluster_accs[-2]}, {global_accs[-2]}')\n",
    "    print(f'last acc: {client_accs[-1]}, {cluster_accs[-1]}, {global_accs[-1]}')\n",
    "    return client_accs, cluster_accs, global_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-11T12:19:51.415478Z",
     "iopub.status.busy": "2023-08-11T12:19:51.415161Z",
     "iopub.status.idle": "2023-08-11T12:19:51.427500Z",
     "shell.execute_reply": "2023-08-11T12:19:51.426868Z",
     "shell.execute_reply.started": "2023-08-11T12:19:51.415451Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def global_distill_experiments(total_client_data, distill_data, alpha, number_of_cluster, cluster_distribution):\n",
    "    print(f'number_of_cluster: {number_of_cluster}')\n",
    "    data_per_class=int(distill_data//10)\n",
    "    train_idcs, test_idcs = idcs[:total_client_data], idcs[total_client_data:(total_client_data + int(distill_data * 2))]\n",
    "    train_labels = data.targets\n",
    "    test_labels = data.targets\n",
    "    \n",
    "    server_idcs = generate_server_idcs(test_idcs, test_labels, int(distill_data//10))\n",
    "\n",
    "    # client_idcs = split_noniid(train_idcs, train_labels, alpha=alpha, n_clients=N_CLIENTS)\n",
    "    client_idcs = split_7plus3class_unbalanced(train_idcs, train_labels, N_CLIENTS, cluster_distribution)\n",
    "    \n",
    "    print('client idcs generated!')\n",
    "    client_data = [CustomSubset(data, idcs) for idcs in client_idcs]\n",
    "    test_data = CustomSubset(data, server_idcs, transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "    for i, client_datum in enumerate(client_data):\n",
    "        client_datum.subset_transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "    server = Server(ConvNet, lambda x : torch.optim.Adam(x, weight_decay=0.1),test_data)\n",
    "\n",
    "    clients = [Client(ConvNet, lambda x: torch.optim.Adam(x, weight_decay=0.1), dat, i) \n",
    "           for i, dat in enumerate(client_data) if len(dat) > 20]\n",
    "    \n",
    "    print(f'client count: {len(clients)}')\n",
    "\n",
    "    client_accs = []\n",
    "    cluster_accs = []\n",
    "    global_accs = []\n",
    "    client_logits = []\n",
    "    \n",
    "    # 1.Local training\n",
    "    for epoch in range(LOCAL_EPOCHS):\n",
    "        for i, client in enumerate(clients):\n",
    "            client.compute_weight_update(epochs=1)\n",
    "\n",
    "        if epoch % 5 == 0:\n",
    "            client_accs, cluster_accs, global_accs = test_acc(server, clients, client_accs, cluster_accs, global_accs, cluster_distribution)\n",
    "            print(f'client_acc: {client_accs[-1]}, cluster_acc: {cluster_distribution}: {cluster_accs[-1]},  global_acc: {global_accs[-1]}')\n",
    "      \n",
    "    # 2. get global loigt\n",
    "    for i, client in enumerate(clients):\n",
    "        if i == 0:\n",
    "            distill_data = server.get_clients_logit(client.model)\n",
    "            client_logits.append(distill_data[2])\n",
    "        else:\n",
    "            client_logits.append(server.get_clients_logit(client.model)[2])\n",
    "    global_logits = get_global_logits(client_logits)\n",
    "    \n",
    "    # 3.Distillation\n",
    "    for i, client in enumerate(clients):\n",
    "        if i % 10 == 0:\n",
    "            print(f'client {i} distill')\n",
    "        \n",
    "        client.distill((distill_data[0], global_logits))\n",
    "    \n",
    "    client_accs, cluster_accs, global_accs = test_acc(server, clients, client_accs, cluster_accs, global_accs, cluster_distribution)\n",
    "    \n",
    "    print(f'total_client_data: {total_client_data}, cluster_distribution: {cluster_distribution}')\n",
    "    print(f'first acc: {client_accs[0]}, {cluster_accs[0]}, {global_accs[0]}')\n",
    "    print(f'acc before distill: {client_accs[-2]}, {cluster_accs[-2]}, {global_accs[-2]}')\n",
    "    print(f'last acc: {client_accs[-1]}, {cluster_accs[-1]}, {global_accs[-1]}')\n",
    "    return client_accs, cluster_accs, global_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-11T12:19:51.428628Z",
     "iopub.status.busy": "2023-08-11T12:19:51.428397Z",
     "iopub.status.idle": "2023-08-11T12:19:51.436943Z",
     "shell.execute_reply": "2023-08-11T12:19:51.436233Z",
     "shell.execute_reply.started": "2023-08-11T12:19:51.428613Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cluster_distill_experiments(total_client_data, distill_data, alpha, number_of_cluster, cluster_distribution):\n",
    "    print(f'number_of_cluster: {number_of_cluster}')\n",
    "    data_per_class=int(distill_data//10)\n",
    "    train_idcs, test_idcs = idcs[:total_client_data], idcs[total_client_data:(total_client_data + int(distill_data * 2))]\n",
    "    train_labels = data.targets\n",
    "    test_labels = data.targets\n",
    "    \n",
    "    server_idcs = generate_server_idcs(test_idcs, test_labels, int(distill_data//10))\n",
    "\n",
    "    #client_idcs = split_noniid(train_idcs, train_labels, alpha=alpha, n_clients=N_CLIENTS)\n",
    "    client_idcs = split_7plus3class_unbalanced(train_idcs, train_labels, N_CLIENTS, cluster_distribution)\n",
    "    \n",
    "    print('client idcs generated!')\n",
    "    client_data = [CustomSubset(data, idcs) for idcs in client_idcs]\n",
    "    print(f'server data length: {len(server_idcs)}')\n",
    "    test_data = CustomSubset(data, server_idcs, transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "    for i, client_datum in enumerate(client_data):\n",
    "        client_datum.subset_transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "    server = Server(ConvNet, lambda x : torch.optim.Adam(x, weight_decay=0.1),test_data)\n",
    "\n",
    "    clients = [Client(ConvNet, lambda x: torch.optim.Adam(x, weight_decay=0.1), dat, i) \n",
    "           for i, dat in enumerate(client_data) if len(dat) > 20]\n",
    "    \n",
    "    print(f'client count: {len(clients)}')\n",
    "\n",
    "    client_accs = []\n",
    "    cluster_accs = []\n",
    "    global_accs = []\n",
    "    client_logits = []\n",
    "    \n",
    "    # 1.Local training\n",
    "    for epoch in range(1, LOCAL_EPOCHS + 1):\n",
    "        for i, client in enumerate(clients):\n",
    "            client.compute_weight_update(epochs=1)\n",
    "\n",
    "        if epoch % 5 == 0:\n",
    "            client_accs, cluster_accs, global_accs = test_acc(server, clients, client_accs, cluster_accs, global_accs, cluster_distribution)\n",
    "            print(f'client_acc: {client_accs[-1]}, cluster_acc: {cluster_distribution}: {cluster_accs[-1]},  global_acc: {global_accs[-1]}')\n",
    "\n",
    "    # 2.Clustering\n",
    "    label_predicted, cluster_idcs = cluster(server, clients, number_of_cluster)\n",
    "    cluster_weight_per_class = get_cluster_averages(label_predicted.sort_index(axis=1), cluster_idcs)\n",
    "    # print(cluster_weight_per_class)\n",
    "    visualize_clusters(label_predicted, cluster_idcs, cluster_distribution)\n",
    "        \n",
    "    # 3.Get cluster, global loigt\n",
    "    for i, client in enumerate(clients):\n",
    "        if i == 0:\n",
    "            distill_data = server.get_clients_logit(client.model)\n",
    "            client_logits.append(distill_data[2])\n",
    "        else:\n",
    "            client_logits.append(server.get_clients_logit(client.model)[2])\n",
    "    global_logits = get_global_logits(client_logits)\n",
    "    \n",
    "    cluster_logits = get_cluster_logits(client_logits, cluster_idcs)\n",
    "    # cluster_weights = get_cluster_weights(cluster_logits, cluster_weight_per_class)\n",
    "    \n",
    "    # 4.Distillation\n",
    "    for i, client in enumerate(clients):\n",
    "        if i % 10 == 0:\n",
    "            print(f'client {i} distill')\n",
    "        \n",
    "             # Find the corresponding cluster for the client\n",
    "        cluster_idx = next(j for j, cluster in enumerate(cluster_idcs) if i in cluster)\n",
    "\n",
    "        # Extract the corresponding cluster logits\n",
    "        my_cluster_logit = cluster_logits[cluster_idx]\n",
    "        \n",
    "        client.distill((distill_data[0], my_cluster_logit))\n",
    "    \n",
    "    client_accs, cluster_accs, global_accs = test_acc(server, clients, client_accs, cluster_accs, global_accs, cluster_distribution)\n",
    "    \n",
    "    print(f'total_client_data: {total_client_data}, cluster_distribution: {cluster_distribution}')\n",
    "    print(f'first acc: {client_accs[0]}, {cluster_accs[0]}, {global_accs[0]}')\n",
    "    print(f'acc before distill: {client_accs[-2]}, {cluster_accs[-2]}, {global_accs[-2]}')\n",
    "    print(f'last acc: {client_accs[-1]}, {cluster_accs[-1]}, {global_accs[-1]}')\n",
    "    return client_accs, cluster_accs, global_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-11T12:19:51.437937Z",
     "iopub.status.busy": "2023-08-11T12:19:51.437759Z",
     "iopub.status.idle": "2023-08-11T12:29:58.025596Z",
     "shell.execute_reply": "2023-08-11T12:29:58.024709Z",
     "shell.execute_reply.started": "2023-08-11T12:19:51.437923Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number_of_cluster: 3\n",
      "client idcs generated!\n",
      "server data length: 5000\n",
      "Train Label Distribution for client 0: Counter({0: 35, 1: 35, 2: 35, 3: 7, 4: 7, 8: 7, 9: 7, 6: 7, 5: 7, 7: 7})\n",
      "Evaluation Label Distribution for client 0: Counter({2: 15, 1: 15, 0: 15, 9: 3, 6: 3, 4: 3, 8: 3, 3: 3, 5: 3, 7: 3})\n",
      "Train Label Distribution for client 10: Counter({0: 35, 1: 35, 2: 35, 5: 7, 9: 7, 6: 7, 4: 7, 8: 7, 3: 7, 7: 7})\n",
      "Evaluation Label Distribution for client 10: Counter({2: 15, 1: 15, 0: 15, 8: 3, 5: 3, 4: 3, 6: 3, 3: 3, 9: 3, 7: 3})\n",
      "Train Label Distribution for client 20: Counter({2: 35, 0: 35, 1: 35, 8: 7, 4: 7, 3: 7, 7: 7, 5: 7, 9: 7, 6: 7})\n",
      "Evaluation Label Distribution for client 20: Counter({0: 15, 1: 15, 2: 15, 8: 3, 3: 3, 7: 3, 6: 3, 9: 3, 4: 3, 5: 3})\n",
      "Train Label Distribution for client 30: Counter({1: 35, 2: 35, 0: 35, 9: 7, 8: 7, 6: 7, 4: 7, 3: 7, 7: 7, 5: 7})\n",
      "Evaluation Label Distribution for client 30: Counter({2: 15, 1: 15, 0: 15, 5: 3, 7: 3, 9: 3, 3: 3, 8: 3, 6: 3, 4: 3})\n",
      "Train Label Distribution for client 40: Counter({2: 35, 0: 35, 1: 35, 9: 7, 5: 7, 6: 7, 8: 7, 7: 7, 3: 7, 4: 7})\n",
      "Evaluation Label Distribution for client 40: Counter({2: 15, 0: 15, 1: 15, 4: 3, 8: 3, 9: 3, 3: 3, 6: 3, 5: 3, 7: 3})\n",
      "Train Label Distribution for client 50: Counter({4: 35, 5: 35, 3: 35, 8: 7, 2: 7, 6: 7, 7: 7, 0: 7, 1: 7, 9: 7})\n",
      "Evaluation Label Distribution for client 50: Counter({4: 15, 5: 15, 3: 15, 8: 3, 9: 3, 6: 3, 7: 3, 0: 3, 1: 3, 2: 3})\n",
      "Train Label Distribution for client 60: Counter({4: 35, 3: 35, 5: 35, 8: 7, 1: 7, 9: 7, 0: 7, 6: 7, 7: 7, 2: 7})\n",
      "Evaluation Label Distribution for client 60: Counter({4: 15, 3: 15, 5: 15, 7: 3, 1: 3, 9: 3, 6: 3, 8: 3, 0: 3, 2: 3})\n",
      "Train Label Distribution for client 70: Counter({4: 35, 5: 35, 3: 35, 2: 7, 9: 7, 7: 7, 8: 7, 1: 7, 6: 7, 0: 7})\n",
      "Evaluation Label Distribution for client 70: Counter({5: 15, 4: 15, 3: 15, 2: 3, 8: 3, 6: 3, 0: 3, 7: 3, 1: 3, 9: 3})\n",
      "Train Label Distribution for client 80: Counter({8: 35, 6: 35, 7: 35, 4: 7, 1: 7, 0: 7, 5: 7, 2: 7, 9: 7, 3: 7})\n",
      "Evaluation Label Distribution for client 80: Counter({8: 15, 6: 15, 7: 15, 0: 3, 3: 3, 2: 3, 5: 3, 4: 3, 1: 3, 9: 3})\n",
      "Train Label Distribution for client 90: Counter({7: 35, 8: 35, 6: 35, 2: 7, 3: 7, 4: 7, 9: 7, 1: 7, 5: 7, 0: 7})\n",
      "Evaluation Label Distribution for client 90: Counter({6: 15, 8: 15, 7: 15, 2: 3, 1: 3, 0: 3, 4: 3, 5: 3, 3: 3, 9: 3})\n",
      "client count: 100\n",
      "client_acc: 0.289, cluster_acc: [0.5, 0.3, 0.2]: [0.297, 0.282, 0.28],  global_acc: 0.192\n",
      "client_acc: 0.402, cluster_acc: [0.5, 0.3, 0.2]: [0.413, 0.383, 0.402],  global_acc: 0.294\n",
      "client_acc: 0.538, cluster_acc: [0.5, 0.3, 0.2]: [0.571, 0.483, 0.54],  global_acc: 0.436\n",
      "client_acc: 0.591, cluster_acc: [0.5, 0.3, 0.2]: [0.616, 0.545, 0.599],  global_acc: 0.464\n",
      "client_acc: 0.615, cluster_acc: [0.5, 0.3, 0.2]: [0.64, 0.573, 0.617],  global_acc: 0.479\n",
      "predicted label\n",
      "         0       1       2    3    9       7     4    5       6       8\n",
      "0   1306.0  1032.0  2662.0  0.0  0.0     0.0   0.0  0.0     0.0     0.0\n",
      "1   1974.0  1358.0  1668.0  0.0  0.0     0.0   0.0  0.0     0.0     0.0\n",
      "2   1767.0  1634.0  1596.0  1.0  1.0     1.0   0.0  0.0     0.0     0.0\n",
      "3    955.0  1718.0  2327.0  0.0  0.0     0.0   0.0  0.0     0.0     0.0\n",
      "4   1354.0  2169.0  1328.0  0.0  0.0    95.0  54.0  0.0     0.0     0.0\n",
      "..     ...     ...     ...  ...  ...     ...   ...  ...     ...     ...\n",
      "95     0.0     0.0     0.0  0.0  0.0   893.0   0.0  0.0   975.0  3132.0\n",
      "96     3.0     0.0     0.0  0.0  0.0  1701.0   0.0  0.0  1529.0  1767.0\n",
      "97     0.0     0.0     0.0  0.0  0.0  1323.0   0.0  0.0  1883.0  1794.0\n",
      "98     0.0     0.0     0.0  0.0  0.0  1219.0   0.0  0.0  1057.0  2724.0\n",
      "99    14.0     0.0     0.0  0.0  0.0  1690.0   0.0  0.0  1874.0  1422.0\n",
      "\n",
      "[100 rows x 10 columns]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real cluster distribution: [0.5, 0.3, 0.2]\n",
      "Real cluster identity for each client: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "Predicted cluster identity for each client: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "client 0 distill\n",
      "distill epoch 5, averaged loss: 0.0065\n",
      "distill epoch 10, averaged loss: 0.0051\n",
      "distill epoch 15, averaged loss: 0.0051\n",
      "distill epoch 20, averaged loss: 0.0048\n",
      "client 10 distill\n",
      "client 20 distill\n",
      "client 30 distill\n",
      "client 40 distill\n",
      "client 50 distill\n",
      "distill epoch 5, averaged loss: 0.0027\n",
      "distill epoch 10, averaged loss: 0.0025\n",
      "distill epoch 15, averaged loss: 0.0026\n",
      "distill epoch 20, averaged loss: 0.0026\n",
      "client 60 distill\n",
      "client 70 distill\n",
      "client 80 distill\n",
      "client 90 distill\n",
      "total_client_data: 50000, cluster_distribution: [0.5, 0.3, 0.2]\n",
      "first acc: 0.289, [0.297, 0.282, 0.28], 0.192\n",
      "acc before distill: 0.615, [0.64, 0.573, 0.617], 0.479\n",
      "last acc: 0.627, [0.65, 0.582, 0.637], 0.485\n",
      "number_of_cluster: 3\n",
      "client idcs generated!\n",
      "Train Label Distribution for client 0: Counter({0: 35, 1: 35, 2: 35, 3: 7, 4: 7, 8: 7, 9: 7, 6: 7, 5: 7, 7: 7})\n",
      "Evaluation Label Distribution for client 0: Counter({2: 15, 1: 15, 0: 15, 9: 3, 6: 3, 4: 3, 8: 3, 3: 3, 5: 3, 7: 3})\n",
      "Train Label Distribution for client 10: Counter({0: 35, 1: 35, 2: 35, 5: 7, 9: 7, 6: 7, 4: 7, 8: 7, 3: 7, 7: 7})\n",
      "Evaluation Label Distribution for client 10: Counter({2: 15, 1: 15, 0: 15, 8: 3, 5: 3, 4: 3, 6: 3, 3: 3, 9: 3, 7: 3})\n",
      "Train Label Distribution for client 20: Counter({2: 35, 0: 35, 1: 35, 8: 7, 4: 7, 3: 7, 7: 7, 5: 7, 9: 7, 6: 7})\n",
      "Evaluation Label Distribution for client 20: Counter({0: 15, 1: 15, 2: 15, 8: 3, 3: 3, 7: 3, 6: 3, 9: 3, 4: 3, 5: 3})\n",
      "Train Label Distribution for client 30: Counter({1: 35, 2: 35, 0: 35, 9: 7, 8: 7, 6: 7, 4: 7, 3: 7, 7: 7, 5: 7})\n",
      "Evaluation Label Distribution for client 30: Counter({2: 15, 1: 15, 0: 15, 5: 3, 7: 3, 9: 3, 3: 3, 8: 3, 6: 3, 4: 3})\n",
      "Train Label Distribution for client 40: Counter({2: 35, 0: 35, 1: 35, 9: 7, 5: 7, 6: 7, 8: 7, 7: 7, 3: 7, 4: 7})\n",
      "Evaluation Label Distribution for client 40: Counter({2: 15, 0: 15, 1: 15, 4: 3, 8: 3, 9: 3, 3: 3, 6: 3, 5: 3, 7: 3})\n",
      "Train Label Distribution for client 50: Counter({4: 35, 5: 35, 3: 35, 8: 7, 2: 7, 6: 7, 7: 7, 0: 7, 1: 7, 9: 7})\n",
      "Evaluation Label Distribution for client 50: Counter({4: 15, 5: 15, 3: 15, 8: 3, 9: 3, 6: 3, 7: 3, 0: 3, 1: 3, 2: 3})\n",
      "Train Label Distribution for client 60: Counter({4: 35, 3: 35, 5: 35, 8: 7, 1: 7, 9: 7, 0: 7, 6: 7, 7: 7, 2: 7})\n",
      "Evaluation Label Distribution for client 60: Counter({4: 15, 3: 15, 5: 15, 7: 3, 1: 3, 9: 3, 6: 3, 8: 3, 0: 3, 2: 3})\n",
      "Train Label Distribution for client 70: Counter({4: 35, 5: 35, 3: 35, 2: 7, 9: 7, 7: 7, 8: 7, 1: 7, 6: 7, 0: 7})\n",
      "Evaluation Label Distribution for client 70: Counter({5: 15, 4: 15, 3: 15, 2: 3, 8: 3, 6: 3, 0: 3, 7: 3, 1: 3, 9: 3})\n",
      "Train Label Distribution for client 80: Counter({8: 35, 6: 35, 7: 35, 4: 7, 1: 7, 0: 7, 5: 7, 2: 7, 9: 7, 3: 7})\n",
      "Evaluation Label Distribution for client 80: Counter({8: 15, 6: 15, 7: 15, 0: 3, 3: 3, 2: 3, 5: 3, 4: 3, 1: 3, 9: 3})\n",
      "Train Label Distribution for client 90: Counter({7: 35, 8: 35, 6: 35, 2: 7, 3: 7, 4: 7, 9: 7, 1: 7, 5: 7, 0: 7})\n",
      "Evaluation Label Distribution for client 90: Counter({6: 15, 8: 15, 7: 15, 2: 3, 1: 3, 0: 3, 4: 3, 5: 3, 3: 3, 9: 3})\n",
      "client count: 100\n",
      "client_acc: 0.211, cluster_acc: [0.5, 0.3, 0.2]: [0.211, 0.228, 0.184],  global_acc: 0.159\n",
      "client_acc: 0.309, cluster_acc: [0.5, 0.3, 0.2]: [0.329, 0.292, 0.283],  global_acc: 0.226\n",
      "client_acc: 0.44, cluster_acc: [0.5, 0.3, 0.2]: [0.465, 0.413, 0.416],  global_acc: 0.328\n",
      "client_acc: 0.548, cluster_acc: [0.5, 0.3, 0.2]: [0.587, 0.473, 0.562],  global_acc: 0.444\n",
      "client_acc: 0.595, cluster_acc: [0.5, 0.3, 0.2]: [0.627, 0.525, 0.619],  global_acc: 0.473\n",
      "client 0 distill\n",
      "distill epoch 5, averaged loss: 0.0041\n",
      "distill epoch 10, averaged loss: 0.0032\n",
      "distill epoch 15, averaged loss: 0.0031\n",
      "distill epoch 20, averaged loss: 0.0031\n",
      "client 10 distill\n",
      "client 20 distill\n",
      "client 30 distill\n",
      "client 40 distill\n",
      "client 50 distill\n",
      "distill epoch 5, averaged loss: 0.0045\n",
      "distill epoch 10, averaged loss: 0.0034\n",
      "distill epoch 15, averaged loss: 0.0031\n",
      "distill epoch 20, averaged loss: 0.0033\n",
      "client 60 distill\n",
      "client 70 distill\n",
      "client 80 distill\n",
      "client 90 distill\n",
      "total_client_data: 50000, cluster_distribution: [0.5, 0.3, 0.2]\n",
      "first acc: 0.211, [0.211, 0.228, 0.184], 0.159\n",
      "acc before distill: 0.595, [0.627, 0.525, 0.619], 0.473\n",
      "last acc: 0.435, [0.668, 0.225, 0.166], 0.969\n"
     ]
    }
   ],
   "source": [
    "now = datetime.datetime.now(pytz.timezone('Asia/Seoul'))\n",
    "date_time = now.strftime(\"%m%d_%H%M\")\n",
    "\n",
    "columns = pd.MultiIndex.from_product([['client_accs', 'cluster_accs', 'global_accs'], ['before_distill', 'after_distill']],\n",
    "                                     names=['acc_type', 'distill_state'])\n",
    "\n",
    "# The tuples for which we want to run the experiment \n",
    "desired_pairs = [(50000, 5000)]\n",
    "cluster_distribution = [0.5, 0.3, 0.2]\n",
    "# Add additional index 'global_distill' and 'cluster_distill'\n",
    "experiments = ['cluster_distill', 'global_distill']\n",
    "index = pd.MultiIndex.from_product([experiments, desired_pairs], names=['experiment', 'data_pair'])\n",
    "\n",
    "# Initialize an empty DataFrame with the desired index for rows and columns\n",
    "df = pd.DataFrame(index=index, columns=columns)\n",
    "\n",
    "for exp in experiments:\n",
    "    for pair in desired_pairs:\n",
    "        client_data, distill_data = pair\n",
    "\n",
    "        if exp == 'global_distill':\n",
    "            client_accs, cluster_accs, global_accs = global_distill_experiments(client_data, distill_data, ALPHA, NUMBER_OF_CLUSTER, cluster_distribution)\n",
    "        else:\n",
    "            client_accs, cluster_accs, global_accs = cluster_distill_experiments(client_data, distill_data, ALPHA, NUMBER_OF_CLUSTER, cluster_distribution)\n",
    "\n",
    "        # Set the values in the DataFrame\n",
    "        df.loc[(exp, pair), ('client_accs', 'before_distill')] = client_accs[-2]\n",
    "        df.loc[(exp, pair), ('client_accs', 'after_distill')] = client_accs[-1]\n",
    "        df.loc[(exp, pair), ('global_accs', 'before_distill')] = global_accs[-2]\n",
    "        df.loc[(exp, pair), ('global_accs', 'after_distill')] = global_accs[-1]\n",
    "        df.loc[(exp, pair), ('cluster_accs', 'before_distill')] = cluster_accs[-2]\n",
    "        df.loc[(exp, pair), ('cluster_accs', 'after_distill')] = cluster_accs[-1]\n",
    "\n",
    "        directory = f'results/Unbalanced_cluster'\n",
    "\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "        cluster_distribution_str = \"_\".join(map(str, cluster_distribution))\n",
    "        file_name = f'{directory}/client:{N_CLIENTS}_cluster:{NUMBER_OF_CLUSTER}_distribution:{cluster_distribution_str}_{date_time}.csv'\n",
    "        df = df.round(decimals=3)\n",
    "        df.to_csv(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-11T12:29:58.028278Z",
     "iopub.status.busy": "2023-08-11T12:29:58.028094Z",
     "iopub.status.idle": "2023-08-11T12:29:58.039630Z",
     "shell.execute_reply": "2023-08-11T12:29:58.039127Z",
     "shell.execute_reply.started": "2023-08-11T12:29:58.028262Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>acc_type</th>\n",
       "      <th colspan=\"2\" halign=\"left\">client_accs</th>\n",
       "      <th colspan=\"2\" halign=\"left\">cluster_accs</th>\n",
       "      <th colspan=\"2\" halign=\"left\">global_accs</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>distill_state</th>\n",
       "      <th>before_distill</th>\n",
       "      <th>after_distill</th>\n",
       "      <th>before_distill</th>\n",
       "      <th>after_distill</th>\n",
       "      <th>before_distill</th>\n",
       "      <th>after_distill</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment</th>\n",
       "      <th>data_pair</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cluster_distill</th>\n",
       "      <th>(50000, 5000)</th>\n",
       "      <td>0.615</td>\n",
       "      <td>0.627</td>\n",
       "      <td>[0.64, 0.573, 0.617]</td>\n",
       "      <td>[0.65, 0.582, 0.637]</td>\n",
       "      <td>0.479</td>\n",
       "      <td>0.485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>global_distill</th>\n",
       "      <th>(50000, 5000)</th>\n",
       "      <td>0.595</td>\n",
       "      <td>0.435</td>\n",
       "      <td>[0.627, 0.525, 0.619]</td>\n",
       "      <td>[0.668, 0.225, 0.166]</td>\n",
       "      <td>0.473</td>\n",
       "      <td>0.969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "acc_type                         client_accs                \\\n",
       "distill_state                 before_distill after_distill   \n",
       "experiment      data_pair                                    \n",
       "cluster_distill (50000, 5000)          0.615         0.627   \n",
       "global_distill  (50000, 5000)          0.595         0.435   \n",
       "\n",
       "acc_type                                cluster_accs                         \\\n",
       "distill_state                         before_distill          after_distill   \n",
       "experiment      data_pair                                                     \n",
       "cluster_distill (50000, 5000)   [0.64, 0.573, 0.617]   [0.65, 0.582, 0.637]   \n",
       "global_distill  (50000, 5000)  [0.627, 0.525, 0.619]  [0.668, 0.225, 0.166]   \n",
       "\n",
       "acc_type                         global_accs                \n",
       "distill_state                 before_distill after_distill  \n",
       "experiment      data_pair                                   \n",
       "cluster_distill (50000, 5000)          0.479         0.485  \n",
       "global_distill  (50000, 5000)          0.473         0.969  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-11T12:29:58.040466Z",
     "iopub.status.busy": "2023-08-11T12:29:58.040324Z",
     "iopub.status.idle": "2023-08-11T12:29:58.421033Z",
     "shell.execute_reply": "2023-08-11T12:29:58.419594Z",
     "shell.execute_reply.started": "2023-08-11T12:29:58.040453Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'results/global_distill/CIFAR_0720_0435.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mresults/global_distill/CIFAR_0720_0435.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# 그릴 데이터와 제목을 리스트로 저장\u001b[39;00m\n\u001b[1;32m      4\u001b[0m heatmap_data \u001b[38;5;241m=\u001b[39m [(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclient_accs\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchange_after_distill\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClient Accuracy change after Distillation\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m      5\u001b[0m                 (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mglobal_accs\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchange_after_distill\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGlobal Accuracy change after Distillation\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n",
      "File \u001b[0;32m~/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages/pandas/io/common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'results/global_distill/CIFAR_0720_0435.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('results/global_distill/CIFAR_0720_0435.csv', index_col=[0,1], header=[0,1])\n",
    "\n",
    "# 그릴 데이터와 제목을 리스트로 저장\n",
    "heatmap_data = [('client_accs', 'change_after_distill', 'Client Accuracy change after Distillation'),\n",
    "                ('global_accs', 'change_after_distill', 'Global Accuracy change after Distillation')]\n",
    "\n",
    "# Compute change in accuracy\n",
    "df[('client_accs', 'change_after_distill')] = df[('client_accs', 'after_distill')] - df[('client_accs', 'before_distill')]\n",
    "df[('global_accs', 'change_after_distill')] = df[('global_accs', 'after_distill')] - df[('global_accs', 'before_distill')]\n",
    "\n",
    "# 전체 데이터의 최솟값, 최댓값 계산\n",
    "vmin = min(df[data1][data2].min() for data1, data2, _ in heatmap_data)\n",
    "vmax = max(df[data1][data2].max() for data1, data2, _ in heatmap_data)\n",
    "\n",
    "for data1, data2, title in heatmap_data:\n",
    "    plt.figure(figsize=(9, 5))\n",
    "    sns.heatmap(df[(data1, data2)].unstack(), annot=True, cmap='coolwarm', center=0, vmin=-0.1, vmax=0.2)\n",
    "    plt.title(title)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Clustering 실험"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-11T12:29:58.421814Z",
     "iopub.status.idle": "2023-08-11T12:29:58.422011Z",
     "shell.execute_reply": "2023-08-11T12:29:58.421917Z",
     "shell.execute_reply.started": "2023-08-11T12:29:58.421908Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def do_clustering_experiments(total_client_data=total_client_data, data_per_class=data_per_class, ALPHA=ALPHA):\n",
    "    train_idcs, test_idcs = idcs[:int(total_client_data*10)], idcs[int(total_client_data*10):]\n",
    "    train_labels = data.train_labels.numpy()\n",
    "    test_labels = data.train_labels.numpy()[int(total_client_data*10):]\n",
    "\n",
    "    client_idcs = split_noniid(train_idcs, train_labels, alpha=ALPHA, n_clients=N_CLIENTS)#, data_per_class=int(total_client_data/10))\n",
    "    # server_idcs = generate_server_idcs(test_idcs, test_labels, int(total_client_data*10))\n",
    "\n",
    "    client_data = [CustomSubset(data, idcs) for idcs in client_idcs]\n",
    "    test_data = CustomSubset(data, test_idcs, transforms.Compose([transforms.ToTensor()]))\n",
    "    \n",
    "    for i, client_datum in enumerate(client_data):\n",
    "        client_datum.subset_transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "    server = Server(resnet18, lambda x : torch.optim.SGD(x, lr=0.1, momentum=0.9),test_data)\n",
    "\n",
    "    \n",
    "    distillation_data_file = f'distillation_data_{data_per_class}_per_class.pth'\n",
    "\n",
    "    # Check if the file already exists\n",
    "    if not os.path.exists(distillation_data_file):\n",
    "        # The file does not exist, generate and save the distillation data\n",
    "        distillation_data = server.make_distillation_data(data_per_class=data_per_class)\n",
    "        torch.save(distillation_data, distillation_data_file)\n",
    "\n",
    "    # Load the distillation data\n",
    "    distillation_data = torch.load(distillation_data_file)\n",
    "\n",
    "    clients = [Client(resnet18, lambda x : torch.optim.SGD(x, lr=0.1, momentum=0.9), dat, i, distillation_data) \n",
    "               for i, dat in enumerate(client_data)]\n",
    "\n",
    "    def aggregate(cluster_indices_new):\n",
    "        cluster_indices = cluster_indices_new\n",
    "        client_clusters = [[clients[i] for i in idcs] for idcs in cluster_indices]\n",
    "\n",
    "        server.aggregate_clusterwise(client_clusters)\n",
    "\n",
    "        return cluster_indices\n",
    "\n",
    "    cfl_stats = ExperimentLogger()\n",
    "\n",
    "    cluster_indices = [np.arange(len(clients)).astype(\"int\")]\n",
    "    client_clusters = [[clients[i] for i in idcs] for idcs in cluster_indices]\n",
    "\n",
    "\n",
    "    for epoch in range(1, LOCAL_EPOCHS+1):\n",
    "\n",
    "        if epoch == 1:\n",
    "            for client in clients:\n",
    "                client.synchronize_with_server(server)\n",
    "\n",
    "        participating_clients = server.select_clients(clients, frac=1.0)\n",
    "\n",
    "        for client in participating_clients:\n",
    "            if epoch == 1:\n",
    "                client.distill()\n",
    "\n",
    "            train_stats = client.compute_weight_update(epochs=1) #train client\n",
    "\n",
    "            if epoch == 1000:\n",
    "                client.reset()\n",
    "\n",
    "        cluster_indices_new = []\n",
    "\n",
    "        for idc in cluster_indices:\n",
    "            max_norm = server.compute_max_update_norm([clients[i] for i in idc])\n",
    "            mean_norm = server.compute_mean_update_norm([clients[i] for i in idc])\n",
    "\n",
    "            #cluster 나누는 기준\n",
    "            if epoch == LOCAL_EPOCHS: #무조건 한번 나누기\n",
    "                similarities = server.compute_pairwise_similarities(clients)\n",
    "\n",
    "                server.cache_model(idc, clients[idc[0]].W, acc_clients)\n",
    "\n",
    "                c1, c2, c3 = server.cluster_clients_GMM(similarities[idc][:,idc])\n",
    "                cluster_indices_new += [c1, c2, c3]\n",
    "\n",
    "        if epoch == 1000:\n",
    "            cluster_indices = aggregate(cluster_indices_new)\n",
    "\n",
    "        acc_clients = [client.evaluate() for client in clients]\n",
    "\n",
    "        if epoch == LOCAL_EPOCHS: #무조건 한번 나누기\n",
    "            label_accuracies = pd.DataFrame()\n",
    "            label_predicted = pd.DataFrame()\n",
    "            label_soft_sum = pd.DataFrame()\n",
    "            label_diff = pd.DataFrame()\n",
    "\n",
    "            for i, client in enumerate(clients):\n",
    "                acc, pred, sum_, diff = server.evaluate(client.model)\n",
    "                # Convert each dictionary to a DataFrame and append to the respective DataFrame\n",
    "                label_accuracies = label_accuracies.append(pd.DataFrame(acc, index=[i]))\n",
    "                label_predicted = label_predicted.append(pd.DataFrame(pred, index=[i]))\n",
    "                label_soft_sum = label_soft_sum.append(pd.DataFrame(sum_, index=[i]))\n",
    "                label_diff = label_diff.append(pd.DataFrame(diff, index=[i]))\n",
    "\n",
    "            # Reset index for all DataFrames\n",
    "            label_accuracies.reset_index(drop=True, inplace=True)\n",
    "            label_predicted.reset_index(drop=True, inplace=True)\n",
    "            label_soft_sum.reset_index(drop=True, inplace=True)\n",
    "            label_diff.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        if epoch == 1:\n",
    "            first_accuracies = pd.DataFrame()\n",
    "            for i, client in enumerate(clients):\n",
    "                first_acc, pred, sum_, diff = server.evaluate(client.model)\n",
    "                first_accuracies = pd.concat([first_accuracies, pd.DataFrame(first_acc, index=[i])])\n",
    "            first_accuracies = first_accuracies.fillna(0)\n",
    "\n",
    "            client_acc_after_distill = sum(acc_clients)/len(acc_clients)\n",
    "            global_acc_after_distill = np.mean(np.ravel(first_accuracies.values))\n",
    "\n",
    "\n",
    "        elif epoch == LOCAL_EPOCHS:\n",
    "            client_acc_final = sum(acc_clients)/len(acc_clients)\n",
    "            global_acc_final = np.mean(np.ravel(label_accuracies.values))\n",
    "\n",
    "        average_dw = server.get_average_dw(clients)\n",
    "        #print(average_dw)\n",
    "        cfl_stats.log({\"acc_clients\" : acc_clients, \"mean_norm\" : mean_norm, \"max_norm\" : max_norm,\n",
    "                      \"rounds\" : epoch, \"clusters\" : cluster_indices, \"average_dw\": average_dw})\n",
    "\n",
    "\n",
    "        display_train_stats(cfl_stats, EPS_1, EPS_2, LOCAL_EPOCHS)\n",
    "\n",
    "\n",
    "    for idc in cluster_indices:    \n",
    "        server.cache_model(idc, clients[idc[0]].W, acc_clients)\n",
    "    \n",
    "    client_acc_after_distill = round(client_acc_after_distill, 3)\n",
    "    global_acc_after_distill = round(global_acc_after_distill, 3)\n",
    "    client_acc_final = round(client_acc_final, 3)\n",
    "    global_acc_final = round(global_acc_final, 3)\n",
    "    \n",
    "    return client_acc_after_distill, global_acc_after_distill, client_acc_final, global_acc_final\n",
    "\n",
    "    print(client_acc_after_distill, global_acc_after_distill)\n",
    "    print(client_acc_final, global_acc_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-11T12:29:58.423577Z",
     "iopub.status.idle": "2023-08-11T12:29:58.423763Z",
     "shell.execute_reply": "2023-08-11T12:29:58.423679Z",
     "shell.execute_reply.started": "2023-08-11T12:29:58.423670Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "first_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-11T12:29:58.424547Z",
     "iopub.status.idle": "2023-08-11T12:29:58.424719Z",
     "shell.execute_reply": "2023-08-11T12:29:58.424639Z",
     "shell.execute_reply.started": "2023-08-11T12:29:58.424630Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "label_accuracies.sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-11T12:29:58.425702Z",
     "iopub.status.idle": "2023-08-11T12:29:58.425901Z",
     "shell.execute_reply": "2023-08-11T12:29:58.425797Z",
     "shell.execute_reply.started": "2023-08-11T12:29:58.425788Z"
    }
   },
   "outputs": [],
   "source": [
    "label_soft_sum.sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-11T12:29:58.427038Z",
     "iopub.status.idle": "2023-08-11T12:29:58.427347Z",
     "shell.execute_reply": "2023-08-11T12:29:58.427192Z",
     "shell.execute_reply.started": "2023-08-11T12:29:58.427178Z"
    }
   },
   "outputs": [],
   "source": [
    "label_diff.sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-11T12:29:58.428570Z",
     "iopub.status.idle": "2023-08-11T12:29:58.428903Z",
     "shell.execute_reply": "2023-08-11T12:29:58.428747Z",
     "shell.execute_reply.started": "2023-08-11T12:29:58.428731Z"
    }
   },
   "outputs": [],
   "source": [
    "label_predicted.sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-11T12:29:58.430403Z",
     "iopub.status.idle": "2023-08-11T12:29:58.430824Z",
     "shell.execute_reply": "2023-08-11T12:29:58.430630Z",
     "shell.execute_reply.started": "2023-08-11T12:29:58.430613Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "# Instantiate PCA\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "# Apply PCA to the dataframes\n",
    "label_accuracies_pca = pca.fit_transform(label_accuracies)\n",
    "label_predicted_pca = pca.fit_transform(label_predicted)\n",
    "label_soft_sum_pca = pca.fit_transform(label_soft_sum)\n",
    "label_diff_pca = pca.fit_transform(label_diff)\n",
    "transformed_data = pca.fit_transform(similarities)\n",
    "\n",
    "# Create labels\n",
    "labels = [0, 0, 0, 1, 1, 1, 2, 2, 2]\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(10, 10))\n",
    "\n",
    "# Scatter plots with larger dots\n",
    "dot_size = 50\n",
    "axs[0, 0].scatter(label_accuracies_pca[:, 0], label_accuracies_pca[:, 1], c=labels, s=dot_size)\n",
    "axs[0, 0].set_title('Label Accuracies')\n",
    "axs[0, 1].scatter(label_predicted_pca[:, 0], label_predicted_pca[:, 1], c=labels, s=dot_size)\n",
    "axs[0, 1].set_title('Label Predicted')\n",
    "axs[1, 0].scatter(label_soft_sum_pca[:, 0], label_soft_sum_pca[:, 1], c=labels, s=dot_size)\n",
    "axs[1, 0].set_title('Label Soft Sum')\n",
    "axs[1, 1].scatter(label_diff_pca[:, 0], label_diff_pca[:, 1], c=labels, s=dot_size)\n",
    "axs[1, 1].set_title('Label Soft Diff')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-11T12:29:58.431946Z",
     "iopub.status.idle": "2023-08-11T12:29:58.432308Z",
     "shell.execute_reply": "2023-08-11T12:29:58.432157Z",
     "shell.execute_reply.started": "2023-08-11T12:29:58.432134Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Calculate Silhouette Scores\n",
    "silhouette_accuracies = silhouette_score(label_accuracies_pca, labels)\n",
    "silhouette_predicted = silhouette_score(label_predicted_pca, labels)\n",
    "silhouette_soft_sum = silhouette_score(label_soft_sum_pca, labels)\n",
    "silhouette_diff = silhouette_score(label_diff_pca, labels)\n",
    "silhouette_transformed_data = silhouette_score(transformed_data, labels)\n",
    "\n",
    "print('Silhouette Score for Accuracies:', silhouette_accuracies)\n",
    "print('Silhouette Score for Predicted:', silhouette_predicted)\n",
    "print('Silhouette Score for Soft Sum:', silhouette_soft_sum)\n",
    "print('Silhouette Score for diff:', silhouette_diff)\n",
    "print('Silhouette Score for Model params:', silhouette_transformed_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-11T12:29:58.433744Z",
     "iopub.status.idle": "2023-08-11T12:29:58.434097Z",
     "shell.execute_reply": "2023-08-11T12:29:58.433927Z",
     "shell.execute_reply.started": "2023-08-11T12:29:58.433913Z"
    }
   },
   "outputs": [],
   "source": [
    "#df.sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 Cluster 별 모델 파라미터 분포"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-11T12:29:58.435208Z",
     "iopub.status.idle": "2023-08-11T12:29:58.435423Z",
     "shell.execute_reply": "2023-08-11T12:29:58.435305Z",
     "shell.execute_reply.started": "2023-08-11T12:29:58.435297Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Fit and transform your data to 2D\n",
    "pca = PCA(n_components=2)\n",
    "transformed_data = pca.fit_transform(similarities)\n",
    "\n",
    "# Assign labels based on index ranges\n",
    "labels = [0, 0, 0, 1, 1, 1, 2, 2, 2]\n",
    "unique_labels = np.unique(labels)\n",
    "colors = plt.cm.Spectral(np.linspace(0, 0.35, len(unique_labels)))\n",
    "\n",
    "# Plot the transformed data with labels\n",
    "for label, color in zip(unique_labels, colors):\n",
    "    idx = np.where(labels == label)\n",
    "    plt.scatter(transformed_data[idx, 0], transformed_data[idx, 1], color=color, label=f'Cluster {label}')\n",
    "\n",
    "# Add a legend\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch1.12.1-py3.8-cuda11.3",
   "language": "python",
   "name": "torch1.12.1-py3.8-cuda11.3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "f79394e62bebc70f4ea6374f6a04753660b8235adfdaf8a6dfe67d7c0f65c745"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-07T02:34:00.535063Z",
     "iopub.status.busy": "2023-08-07T02:34:00.534872Z",
     "iopub.status.idle": "2023-08-07T02:34:02.168262Z",
     "shell.execute_reply": "2023-08-07T02:34:02.167268Z",
     "shell.execute_reply.started": "2023-08-07T02:34:00.535043Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from IPython.display import clear_output\n",
    "import os\n",
    "from copy import deepcopy\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import pytz\n",
    "import torch.nn as nn\n",
    "from sklearn.decomposition import PCA\n",
    "import random\n",
    "\n",
    "from helper import ExperimentLogger, display_train_stats\n",
    "from fl_devices import Server, Client\n",
    "from data_utils import generate_server_idcs, CustomSubset, split_noniid, split_contain_2class, split_2class_plus_alpha, split_contain_3class_unbalanced\n",
    "from torchvision.models import mobilenet_v3_large\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from scipy.spatial import distance\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-07T02:34:02.169644Z",
     "iopub.status.busy": "2023-08-07T02:34:02.169372Z",
     "iopub.status.idle": "2023-08-07T02:34:02.173153Z",
     "shell.execute_reply": "2023-08-07T02:34:02.172396Z",
     "shell.execute_reply.started": "2023-08-07T02:34:02.169627Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "LOCAL_EPOCHS = 25\n",
    "N_CLIENTS = 10\n",
    "NUMBER_OF_CLUSTER = 3\n",
    "ALPHA = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-07T02:34:02.174025Z",
     "iopub.status.busy": "2023-08-07T02:34:02.173891Z",
     "iopub.status.idle": "2023-08-07T02:34:02.638255Z",
     "shell.execute_reply": "2023-08-07T02:34:02.637248Z",
     "shell.execute_reply.started": "2023-08-07T02:34:02.174012Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = datasets.CIFAR10(root=\"CIFAR10/\", download=False)\n",
    "idcs = np.random.permutation(len(data))\n",
    "\n",
    "\n",
    "def cluster(server, clients, number_of_cluster):\n",
    "    label_predicted = pd.DataFrame()\n",
    "    # label_acc = pd.DataFrame()\n",
    "    for i, client in enumerate(clients):\n",
    "        pred = server.check_cluster(client.model)\n",
    "        # print(f'pred: {pred}')\n",
    "        label_predicted = pd.concat([label_predicted, pd.DataFrame(pred, index=[i])])\n",
    "        # label_acc = pd.concat([label_acc, pd.DataFrame(acc, index=[i])])\n",
    "    label_predicted.reset_index(drop=True, inplace=True)\n",
    "    label_predicted.fillna(0, inplace=True)\n",
    "    \n",
    "    print(f'predicted label')\n",
    "    print(label_predicted)\n",
    "\n",
    "    cluster_idcs = server.cluster_clients_GMM(label_predicted, number_of_cluster)\n",
    "    return label_predicted, cluster_idcs\n",
    "\n",
    "\n",
    "\n",
    "def get_cluster_averages(df, cluster_idcs):\n",
    "    cluster_averages = {}\n",
    "\n",
    "    for i, cluster in enumerate(cluster_idcs):\n",
    "        cluster_data = df.loc[cluster, :]\n",
    "        cluster_average = cluster_data.mean()\n",
    "        cluster_averages[i] = cluster_average\n",
    "\n",
    "    cluster_averages_df = pd.DataFrame(cluster_averages).T\n",
    "\n",
    "    # calculate percentage for each value in a row\n",
    "    cluster_percentages_df = cluster_averages_df.div(cluster_averages_df.sum(axis=1), axis=0).multiply(100)\n",
    "\n",
    "    # apply threshold and rounding\n",
    "    cluster_percentages_df = cluster_percentages_df.where(cluster_percentages_df >= 5, 0).round()\n",
    "\n",
    "    return cluster_percentages_df / 10\n",
    "\n",
    "\n",
    "def get_cluster_weights(cluster_logits, cluster_weight_per_class):\n",
    "    # Step 1: Find the class with the maximum value in each logit in cluster_logits\n",
    "    # Assuming the dimension for classes is the second one\n",
    "    max_classes = [torch.argmax(logit, dim=1) for logit in cluster_logits]\n",
    "    \n",
    "    print(max_classes)\n",
    "    cluster_weights = []\n",
    "    #c luster별로 \n",
    "    for i, iogits in enumerate(cluster_logits):\n",
    "        weights = []\n",
    "        for j, logit in enumerate(logits):\n",
    "            \n",
    "            # print(f'max_classes: {max_classes[i][j]}')\n",
    "            # print(\"Shape of cluster_weight_per_class[{}]: \".format(i), cluster_weight_per_class[i].shape)\n",
    "            weights.append(max_classes[i][j])\n",
    "        print(weights)\n",
    "        cluster_weights.append(weights)\n",
    "\n",
    "def visualize_clusters(label_predicted, clusters, real_cluster_distribution):\n",
    "    # Reduce the dimension of the data\n",
    "    pca = PCA(n_components=2)\n",
    "    label_predicted_pca = pca.fit_transform(label_predicted)\n",
    "\n",
    "    # Define colors for the clusters\n",
    "    colors = ['blue', 'red', 'green', 'purple', 'orange', 'yellow', 'black']\n",
    "\n",
    "    # Plot the clusters\n",
    "    plt.figure(figsize=(10,7))\n",
    "    \n",
    "    for i, cluster in enumerate(clusters):\n",
    "        plt.scatter(label_predicted_pca[cluster, 0], label_predicted_pca[cluster, 1], c=colors[i % len(colors)], label=f'Cluster {i+1}')\n",
    "\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # Print the real cluster distribution\n",
    "    print(\"Real cluster distribution:\", real_cluster_distribution)\n",
    "\n",
    "    # Calculate and print each client's cluster identity based on the real_cluster_distribution\n",
    "    n_clients = len(label_predicted)\n",
    "    cumulative_distribution = [0] + [sum(real_cluster_distribution[:i+1]) for i in range(len(real_cluster_distribution))]\n",
    "    client_cluster_id_real = [next((i for i, val in enumerate(cumulative_distribution) if val > client_idx / n_clients), -1) - 1 for client_idx in range(n_clients)]\n",
    "\n",
    "    print(\"Real cluster identity for each client:\", client_cluster_id_real)\n",
    "\n",
    "    # Print each client's cluster identity based on the clusters argument\n",
    "    client_cluster_id_predicted = [next((i for i, cluster in enumerate(clusters) if client_idx in cluster), -1) for client_idx in range(n_clients)]\n",
    "    print(\"Predicted cluster identity for each client:\", client_cluster_id_predicted)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def test_acc(server, clients, client_accs, cluster_accs, global_accs, client_distribution=[0.5, 0.3, 0.2]):\n",
    "    \n",
    "    # Get individual client accuracies\n",
    "    acc_clients = [client.evaluate() for client in clients]\n",
    "\n",
    "    # Compute the average accuracy for each client\n",
    "    client_acc = round(sum(acc_clients) / len(acc_clients), 3) if len(acc_clients) > 0 else 0\n",
    "    client_accs.append(client_acc)\n",
    "\n",
    "    # Compute cluster accuracies for this iteration\n",
    "    cluster_accs_iteration = []\n",
    "    start_idx = 0\n",
    "    for distribution in client_distribution:\n",
    "        end_idx = start_idx + int(distribution * len(clients))\n",
    "        cluster_acc = round(sum(acc_clients[start_idx:end_idx]) / (end_idx - start_idx), 3)\n",
    "        cluster_accs_iteration.append(cluster_acc)\n",
    "        start_idx = end_idx\n",
    "    cluster_accs.append(cluster_accs_iteration)\n",
    "    \n",
    "    accuracies = [server.evaluate_distil(client.model) for client in clients]\n",
    "    global_acc = round(np.mean(accuracies), 3)\n",
    "    global_accs.append(global_acc)\n",
    "    \n",
    "    return client_accs, cluster_accs, global_accs\n",
    "\n",
    "\n",
    "def get_global_logits(client_logits):\n",
    "    avg_logits = torch.mean(torch.stack(client_logits), dim=0)\n",
    "    return avg_logits\n",
    "\n",
    "def get_cluster_logits(client_logits, cluster_idcs):\n",
    "    cluster_logits = []\n",
    "    for i, cluster in enumerate(cluster_idcs):\n",
    "        cluster_client_logits = [client_logits[i] for i in cluster]\n",
    "        avg_cluster_logits = torch.mean(torch.stack(cluster_client_logits), dim=0)\n",
    "        cluster_logits.append(avg_cluster_logits)\n",
    "    return cluster_logits\n",
    "\n",
    "\n",
    "def get_cluster_averages(df, cluster_idcs):\n",
    "    cluster_averages = {}\n",
    "\n",
    "    for i, cluster in enumerate(cluster_idcs):\n",
    "        cluster_data = df.loc[cluster, :]\n",
    "        cluster_average = cluster_data.mean()\n",
    "        cluster_averages[i] = cluster_average\n",
    "\n",
    "    cluster_averages_df = pd.DataFrame(cluster_averages).T\n",
    "\n",
    "    # calculate percentage for each value in a row\n",
    "    cluster_percentages_df = cluster_averages_df.div(cluster_averages_df.sum(axis=1), axis=0).multiply(100)\n",
    "\n",
    "    # apply threshold and rounding\n",
    "    cluster_percentages_df = cluster_percentages_df.where(cluster_percentages_df >= 5, 0).round()\n",
    "\n",
    "    return cluster_percentages_df / 10\n",
    "\n",
    "\n",
    "# def get_cluster_weights(cluster_logits, cluster_weight_per_class):\n",
    "#     # Step 1: Find the class with the maximum value in each logit in cluster_logits\n",
    "#     # Assuming the dimension for classes is the second one\n",
    "#     max_classes = [torch.argmax(logit, dim=1) for logit in cluster_logits]\n",
    "    \n",
    "#     print(max_classes)\n",
    "#     cluster_weights = []\n",
    "#     #c luster별로 \n",
    "#     for i, iogits in enumerate(cluster_logits):\n",
    "#         weights = []\n",
    "#         for j, logit in enumerate(logits):\n",
    "            \n",
    "#             # print(f'max_classes: {max_classes[i][j]}')\n",
    "#             # print(\"Shape of cluster_weight_per_class[{}]: \".format(i), cluster_weight_per_class[i].shape)\n",
    "#             weights.append(max_classes[i][j])\n",
    "#         print(weights)\n",
    "#         cluster_weights.append(weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-07T02:34:02.639309Z",
     "iopub.status.busy": "2023-08-07T02:34:02.639132Z",
     "iopub.status.idle": "2023-08-07T02:34:02.647050Z",
     "shell.execute_reply": "2023-08-07T02:34:02.646459Z",
     "shell.execute_reply.started": "2023-08-07T02:34:02.639294Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def global_distill_experiments(total_client_data, distill_data, alpha, number_of_cluster, cluster_distribution):\n",
    "    print(f'number_of_cluster: {number_of_cluster}')\n",
    "    data_per_class=int(distill_data//10)\n",
    "    train_idcs, test_idcs = idcs[:total_client_data], idcs[total_client_data:(total_client_data + int(distill_data * 2))]\n",
    "    train_labels = data.targets\n",
    "    test_labels = data.targets\n",
    "    \n",
    "    server_idcs = generate_server_idcs(test_idcs, test_labels, int(distill_data//10))\n",
    "\n",
    "    # client_idcs = split_noniid(train_idcs, train_labels, alpha=alpha, n_clients=N_CLIENTS)\n",
    "    client_idcs = split_contain_3class_unbalanced(train_idcs, train_labels, N_CLIENTS, cluster_distribution)\n",
    "    \n",
    "    print('client idcs generated!')\n",
    "    client_data = [CustomSubset(data, idcs) for idcs in client_idcs]\n",
    "    test_data = CustomSubset(data, server_idcs, transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "    for i, client_datum in enumerate(client_data):\n",
    "        client_datum.subset_transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "    server = Server(mobilenet_v3_large, lambda x : torch.optim.Adam(x, weight_decay=0.1),test_data)\n",
    "\n",
    "    clients = [Client(mobilenet_v3_large, lambda x: torch.optim.Adam(x, weight_decay=0.1), dat, i) \n",
    "           for i, dat in enumerate(client_data) if len(dat) > 20]\n",
    "    \n",
    "    print(f'client count: {len(clients)}')\n",
    "\n",
    "    client_accs = []\n",
    "    cluster_accs = []\n",
    "    global_accs = []\n",
    "    client_logits = []\n",
    "    \n",
    "    # 1.Local training\n",
    "    for epoch in range(LOCAL_EPOCHS):\n",
    "        for i, client in enumerate(clients):\n",
    "            client.compute_weight_update(epochs=1)\n",
    "\n",
    "        if epoch % 5 == 0:\n",
    "            client_accs, cluster_accs, global_accs = test_acc(server, clients, client_accs, cluster_accs, global_accs, cluster_distribution)\n",
    "            print(f'client_acc: {client_accs[-1]}, cluster_acc: {cluster_distribution}: {cluster_accs[-1]},  global_acc: {global_accs[-1]}')\n",
    "      \n",
    "    # 2. get global loigt\n",
    "    for i, client in enumerate(clients):\n",
    "        if i == 0:\n",
    "            distill_data = server.get_clients_logit(client.model)\n",
    "            client_logits.append(distill_data[2])\n",
    "        else:\n",
    "            client_logits.append(server.get_clients_logit(client.model)[2])\n",
    "    global_logits = get_global_logits(client_logits)\n",
    "    \n",
    "    # 3.Distillation\n",
    "    for i, client in enumerate(clients):\n",
    "        if i % 10 == 0:\n",
    "            print(f'client {i} distill')\n",
    "        \n",
    "        client.distill((distill_data[0], global_logits))\n",
    "    \n",
    "    client_accs, cluster_accs, global_accs = test_acc(server, clients, client_accs, cluster_accs, global_accs, cluster_distribution)\n",
    "    \n",
    "    print(f'total_client_data: {total_client_data}, data_per_class: {data_per_class}, cluster_distribution: {cluster_distribution}')\n",
    "    print(f'first acc: {client_accs[0]}, {cluster_accs[0]}, {global_accs[0]}')\n",
    "    print(f'acc before distill: {client_accs[-2]}, {cluster_accs[-2]}, {global_accs[-2]}')\n",
    "    print(f'last acc: {client_accs[-1]}, {cluster_accs[-1]}, {global_accs[-1]}')\n",
    "    return client_accs, cluster_accs, global_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-07T02:34:02.648898Z",
     "iopub.status.busy": "2023-08-07T02:34:02.648753Z",
     "iopub.status.idle": "2023-08-07T02:34:02.658119Z",
     "shell.execute_reply": "2023-08-07T02:34:02.657307Z",
     "shell.execute_reply.started": "2023-08-07T02:34:02.648885Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cluster_distill_experiments(total_client_data, distill_data, alpha, number_of_cluster, cluster_distribution):\n",
    "    print(f'number_of_cluster: {number_of_cluster}')\n",
    "    data_per_class=int(distill_data//10)\n",
    "    train_idcs, test_idcs = idcs[:total_client_data], idcs[total_client_data:(total_client_data + int(distill_data * 2))]\n",
    "    train_labels = data.targets\n",
    "    test_labels = data.targets\n",
    "    \n",
    "    server_idcs = generate_server_idcs(test_idcs, test_labels, int(distill_data//10))\n",
    "\n",
    "    #client_idcs = split_noniid(train_idcs, train_labels, alpha=alpha, n_clients=N_CLIENTS)\n",
    "    client_idcs = split_contain_3class_unbalanced(train_idcs, train_labels, N_CLIENTS, cluster_distribution)\n",
    "    \n",
    "    print('client idcs generated!')\n",
    "    client_data = [CustomSubset(data, idcs) for idcs in client_idcs]\n",
    "    print(f'server data length: {len(server_idcs)}')\n",
    "    test_data = CustomSubset(data, server_idcs, transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "    for i, client_datum in enumerate(client_data):\n",
    "        client_datum.subset_transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "    server = Server(mobilenet_v3_large, lambda x : torch.optim.Adam(x, weight_decay=0.1),test_data)\n",
    "\n",
    "    clients = [Client(mobilenet_v3_large, lambda x: torch.optim.Adam(x, weight_decay=0.1), dat, i) \n",
    "           for i, dat in enumerate(client_data) if len(dat) > 20]\n",
    "    \n",
    "    print(f'client count: {len(clients)}')\n",
    "\n",
    "    client_accs = []\n",
    "    cluster_accs = []\n",
    "    global_accs = []\n",
    "    client_logits = []\n",
    "    \n",
    "    # 1.Local training\n",
    "    for epoch in range(1, LOCAL_EPOCHS + 1):\n",
    "        for i, client in enumerate(clients):\n",
    "            client.compute_weight_update(epochs=1)\n",
    "\n",
    "        if epoch % 5 == 0:\n",
    "            client_accs, cluster_accs, global_accs = test_acc(server, clients, client_accs, cluster_accs, global_accs, cluster_distribution)\n",
    "            print(f'client_acc: {client_accs[-1]}, cluster_acc: {cluster_distribution}: {cluster_accs[-1]},  global_acc: {global_accs[-1]}')\n",
    "\n",
    "    # 2.Clustering\n",
    "    label_predicted, cluster_idcs = cluster(server, clients, number_of_cluster)\n",
    "    cluster_weight_per_class = get_cluster_averages(label_predicted.sort_index(axis=1), cluster_idcs)\n",
    "    # print(cluster_weight_per_class)\n",
    "    visualize_clusters(label_predicted, cluster_idcs, cluster_distribution)\n",
    "        \n",
    "    # 3.Get cluster, global loigt\n",
    "    for i, client in enumerate(clients):\n",
    "        if i == 0:\n",
    "            distill_data = server.get_clients_logit(client.model)\n",
    "            client_logits.append(distill_data[2])\n",
    "        else:\n",
    "            client_logits.append(server.get_clients_logit(client.model)[2])\n",
    "    global_logits = get_global_logits(client_logits)\n",
    "    \n",
    "    cluster_logits = get_cluster_logits(client_logits, cluster_idcs)\n",
    "    # cluster_weights = get_cluster_weights(cluster_logits, cluster_weight_per_class)\n",
    "    \n",
    "    # 4.Distillation\n",
    "    for i, client in enumerate(clients):\n",
    "        if i % 10 == 0:\n",
    "            print(f'client {i} distill')\n",
    "        \n",
    "             # Find the corresponding cluster for the client\n",
    "        cluster_idx = next(j for j, cluster in enumerate(cluster_idcs) if i in cluster)\n",
    "\n",
    "        # Extract the corresponding cluster logits\n",
    "        my_cluster_logit = cluster_logits[cluster_idx]\n",
    "        \n",
    "        client.distill((distill_data[0], my_cluster_logit))\n",
    "    \n",
    "    client_accs, cluster_accs, global_accs = test_acc(server, clients, client_accs, cluster_accs, global_accs, cluster_distribution)\n",
    "    \n",
    "    print(f'total_client_data: {total_client_data}, data_per_class: {data_per_class}, cluster_distribution: {cluster_distribution}')\n",
    "    print(f'first acc: {client_accs[0]}, {cluster_accs[0]}, {global_accs[0]}')\n",
    "    print(f'acc before distill: {client_accs[-2]}, {cluster_accs[-2]}, {global_accs[-2]}')\n",
    "    print(f'last acc: {client_accs[-1]}, {cluster_accs[-1]}, {global_accs[-1]}')\n",
    "    return client_accs, cluster_accs, global_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-07T02:34:02.659474Z",
     "iopub.status.busy": "2023-08-07T02:34:02.659133Z",
     "iopub.status.idle": "2023-08-07T02:44:32.364577Z",
     "shell.execute_reply": "2023-08-07T02:44:32.363159Z",
     "shell.execute_reply.started": "2023-08-07T02:34:02.659447Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number_of_cluster: 3\n",
      "client idcs generated!\n",
      "server data length: 4000\n",
      "Train Label Distribution for client 0: Counter({2: 140, 0: 140, 1: 140})\n",
      "Evaluation Label Distribution for client 0: Counter({2: 60, 0: 60, 1: 60})\n",
      "Train Label Distribution for client 1: Counter({1: 140, 0: 140, 2: 140})\n",
      "Evaluation Label Distribution for client 1: Counter({2: 60, 0: 60, 1: 60})\n",
      "Train Label Distribution for client 2: Counter({2: 140, 0: 140, 1: 140})\n",
      "Evaluation Label Distribution for client 2: Counter({1: 60, 0: 60, 2: 60})\n",
      "Train Label Distribution for client 3: Counter({1: 140, 2: 140, 0: 140})\n",
      "Evaluation Label Distribution for client 3: Counter({1: 60, 0: 60, 2: 60})\n",
      "Train Label Distribution for client 4: Counter({1: 140, 0: 140, 2: 140})\n",
      "Evaluation Label Distribution for client 4: Counter({1: 60, 0: 60, 2: 60})\n",
      "Train Label Distribution for client 5: Counter({5: 140, 3: 140, 4: 140})\n",
      "Evaluation Label Distribution for client 5: Counter({4: 60, 5: 60, 3: 60})\n",
      "Train Label Distribution for client 6: Counter({5: 140, 4: 140, 3: 140})\n",
      "Evaluation Label Distribution for client 6: Counter({5: 60, 3: 60, 4: 60})\n",
      "Train Label Distribution for client 7: Counter({4: 140, 5: 140, 3: 140})\n",
      "Evaluation Label Distribution for client 7: Counter({4: 60, 3: 60, 5: 60})\n",
      "Train Label Distribution for client 8: Counter({8: 140, 6: 140, 7: 140})\n",
      "Evaluation Label Distribution for client 8: Counter({7: 60, 6: 60, 8: 60})\n",
      "Train Label Distribution for client 9: Counter({6: 140, 7: 140, 8: 140})\n",
      "Evaluation Label Distribution for client 9: Counter({6: 60, 8: 60, 7: 60})\n",
      "client count: 10\n",
      "client_acc: 0.632, cluster_acc: [0.5, 0.3, 0.2]: [0.631, 0.556, 0.747],  global_acc: 0.2\n",
      "client_acc: 0.709, cluster_acc: [0.5, 0.3, 0.2]: [0.731, 0.604, 0.814],  global_acc: 0.196\n",
      "client_acc: 0.734, cluster_acc: [0.5, 0.3, 0.2]: [0.771, 0.598, 0.847],  global_acc: 0.183\n",
      "client_acc: 0.752, cluster_acc: [0.5, 0.3, 0.2]: [0.783, 0.613, 0.881],  global_acc: 0.213\n",
      "output in train\n",
      "(tensor([4.0640, 4.4517, 5.1783, 5.3974, 5.4376, 5.8734, 4.3313, 3.6133, 4.7425,\n",
      "        4.4299, 4.9322, 3.6971, 8.7796, 3.8995, 3.9938, 3.3488, 5.5976, 3.9615,\n",
      "        4.7532, 4.5096, 5.5275, 4.0964, 3.3369, 6.3500, 2.9376, 5.9658, 4.2791,\n",
      "        6.0354, 4.5082, 2.2887, 4.5603, 3.7001, 4.6888, 6.7694, 4.7774, 2.8084,\n",
      "        5.4194, 4.0366, 4.0925, 3.4678, 5.6907, 6.5048, 5.7329, 6.2501, 2.8841,\n",
      "        5.4441, 3.7897, 5.5115, 5.7195, 3.5497, 5.6270, 5.8481, 4.4934, 4.0225,\n",
      "        4.5114, 5.5906, 5.4531, 4.4620, 3.3768, 5.4761, 4.8875, 4.5595, 5.2157,\n",
      "        4.1167, 7.3907, 4.6672, 4.4940, 3.7896, 4.1411, 4.2055, 2.5270, 4.2073,\n",
      "        6.1040, 3.3261, 6.5673, 4.8595, 3.8006, 4.3283, 7.5460, 8.3301, 5.3769,\n",
      "        1.1216, 5.9844, 5.6531, 5.0029, 3.2432, 3.3640, 3.9617, 3.7761, 3.3223,\n",
      "        4.0822, 5.1609, 6.4123, 3.2554, 6.5440, 2.9455, 2.9923, 3.4682, 3.5972,\n",
      "        3.3233, 5.4152, 7.0518, 4.0530, 3.7592, 6.2252, 5.5022, 4.6343, 6.7312,\n",
      "        5.8666, 2.8905, 1.7817, 3.2204, 6.1789, 7.3179, 4.1888, 4.9576, 5.4854,\n",
      "        6.0059, 4.1934, 4.6319, 2.7185, 5.4314, 4.8647, 3.9179, 7.4232, 4.1384,\n",
      "        4.1638, 8.2699], device='cuda:0'), tensor([6, 8, 6, 8, 7, 7, 8, 8, 7, 6, 8, 6, 7, 6, 8, 6, 8, 6, 7, 8, 7, 8, 7, 7,\n",
      "        7, 6, 7, 7, 8, 6, 7, 8, 6, 7, 7, 6, 6, 7, 7, 6, 8, 8, 6, 6, 6, 7, 7, 7,\n",
      "        6, 7, 8, 6, 8, 6, 6, 7, 7, 8, 8, 6, 6, 8, 8, 7, 8, 6, 8, 7, 7, 6, 7, 6,\n",
      "        7, 8, 6, 8, 7, 8, 8, 6, 6, 7, 6, 7, 8, 6, 6, 6, 8, 7, 6, 7, 7, 8, 7, 6,\n",
      "        7, 8, 8, 7, 6, 8, 8, 7, 7, 8, 7, 7, 6, 8, 7, 6, 6, 6, 7, 7, 8, 6, 7, 6,\n",
      "        7, 6, 8, 8, 6, 8, 8, 8], device='cuda:0'))\n",
      "client_acc: 0.751, cluster_acc: [0.5, 0.3, 0.2]: [0.779, 0.619, 0.881],  global_acc: 0.222\n",
      "tensor([[ 0.5700,  0.5231,  0.5030, -0.4492, -0.3235, -0.3025, -0.5850, -0.5040,\n",
      "         -0.5322, -0.4119],\n",
      "        [ 0.5623,  0.5198,  0.5079, -0.4490, -0.3243, -0.3028, -0.5860, -0.5036,\n",
      "         -0.5312, -0.4109],\n",
      "        [ 0.5635,  0.5139,  0.5255, -0.4501, -0.3254, -0.3041, -0.5862, -0.5054,\n",
      "         -0.5328, -0.4118],\n",
      "        [ 0.5693,  0.5158,  0.5009, -0.4474, -0.3237, -0.3023, -0.5826, -0.5027,\n",
      "         -0.5303, -0.4107]], device='cuda:0')\n",
      "tensor([[ 0.5700,  0.5231,  0.5030, -0.4492, -0.3235, -0.3025, -0.5850, -0.5040,\n",
      "         -0.5322, -0.4119],\n",
      "        [ 0.5623,  0.5198,  0.5079, -0.4490, -0.3243, -0.3028, -0.5860, -0.5036,\n",
      "         -0.5312, -0.4109],\n",
      "        [ 0.5635,  0.5139,  0.5255, -0.4501, -0.3254, -0.3041, -0.5862, -0.5054,\n",
      "         -0.5328, -0.4118],\n",
      "        [ 0.5693,  0.5158,  0.5009, -0.4474, -0.3237, -0.3023, -0.5826, -0.5027,\n",
      "         -0.5303, -0.4107]], device='cuda:0')\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "tensor([[ 0.5284,  0.4062,  0.2736, -0.1172, -0.2596, -0.3558, -0.2932, -0.2772,\n",
      "         -0.4032, -0.3067],\n",
      "        [ 0.5397,  0.4186,  0.2682, -0.1188, -0.2633, -0.3594, -0.2971, -0.2817,\n",
      "         -0.4090, -0.3105],\n",
      "        [ 0.5361,  0.4119,  0.2688, -0.1184, -0.2617, -0.3574, -0.2954, -0.2799,\n",
      "         -0.4054, -0.3089],\n",
      "        [ 0.5329,  0.4124,  0.2702, -0.1182, -0.2611, -0.3571, -0.2950, -0.2793,\n",
      "         -0.4053, -0.3085]], device='cuda:0')\n",
      "tensor([[ 0.5284,  0.4062,  0.2736, -0.1172, -0.2596, -0.3558, -0.2932, -0.2772,\n",
      "         -0.4032, -0.3067],\n",
      "        [ 0.5397,  0.4186,  0.2682, -0.1188, -0.2633, -0.3594, -0.2971, -0.2817,\n",
      "         -0.4090, -0.3105],\n",
      "        [ 0.5361,  0.4119,  0.2688, -0.1184, -0.2617, -0.3574, -0.2954, -0.2799,\n",
      "         -0.4054, -0.3089],\n",
      "        [ 0.5329,  0.4124,  0.2702, -0.1182, -0.2611, -0.3571, -0.2950, -0.2793,\n",
      "         -0.4053, -0.3085]], device='cuda:0')\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "tensor([[ 0.5437,  0.4232,  0.2616, -0.1201, -0.2644, -0.3598, -0.2978, -0.2832,\n",
      "         -0.4082, -0.3115],\n",
      "        [ 0.5401,  0.4238,  0.2621, -0.1202, -0.2643, -0.3594, -0.2976, -0.2826,\n",
      "         -0.4073, -0.3114],\n",
      "        [ 0.5420,  0.4208,  0.2621, -0.1201, -0.2645, -0.3595, -0.2976, -0.2827,\n",
      "         -0.4083, -0.3113],\n",
      "        [ 0.5369,  0.4150,  0.2646, -0.1184, -0.2619, -0.3573, -0.2952, -0.2800,\n",
      "         -0.4049, -0.3089]], device='cuda:0')\n",
      "tensor([[ 0.5437,  0.4232,  0.2616, -0.1201, -0.2644, -0.3598, -0.2978, -0.2832,\n",
      "         -0.4082, -0.3115],\n",
      "        [ 0.5401,  0.4238,  0.2621, -0.1202, -0.2643, -0.3594, -0.2976, -0.2826,\n",
      "         -0.4073, -0.3114],\n",
      "        [ 0.5420,  0.4208,  0.2621, -0.1201, -0.2645, -0.3595, -0.2976, -0.2827,\n",
      "         -0.4083, -0.3113],\n",
      "        [ 0.5369,  0.4150,  0.2646, -0.1184, -0.2619, -0.3573, -0.2952, -0.2800,\n",
      "         -0.4049, -0.3089]], device='cuda:0')\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "tensor([[-0.3268, -0.1712, -0.3240,  0.3799,  0.5905,  0.6131, -0.4987, -0.5348,\n",
      "         -0.4035, -0.4760],\n",
      "        [-0.3292, -0.1720, -0.3257,  0.3770,  0.6018,  0.6173, -0.5017, -0.5380,\n",
      "         -0.4060, -0.4789],\n",
      "        [-0.3241, -0.1696, -0.3211,  0.3730,  0.5941,  0.6056, -0.4955, -0.5303,\n",
      "         -0.4010, -0.4720],\n",
      "        [-0.3222, -0.1683, -0.3199,  0.3638,  0.5973,  0.6099, -0.4938, -0.5301,\n",
      "         -0.4002, -0.4719]], device='cuda:0')\n",
      "tensor([[-0.3268, -0.1712, -0.3240,  0.3799,  0.5905,  0.6131, -0.4987, -0.5348,\n",
      "         -0.4035, -0.4760],\n",
      "        [-0.3292, -0.1720, -0.3257,  0.3770,  0.6018,  0.6173, -0.5017, -0.5380,\n",
      "         -0.4060, -0.4789],\n",
      "        [-0.3241, -0.1696, -0.3211,  0.3730,  0.5941,  0.6056, -0.4955, -0.5303,\n",
      "         -0.4010, -0.4720],\n",
      "        [-0.3222, -0.1683, -0.3199,  0.3638,  0.5973,  0.6099, -0.4938, -0.5301,\n",
      "         -0.4002, -0.4719]], device='cuda:0')\n",
      "tensor([5, 5, 5, 5, 5, 4, 5, 4, 5, 5, 5, 4, 4, 4, 5, 5, 5, 5, 5, 4, 5, 4, 5, 5,\n",
      "        4, 5, 5, 5, 4, 5, 4, 5, 4, 5, 5, 4, 5, 4, 5, 5, 5, 5, 4, 5, 5, 5, 4, 5,\n",
      "        4, 4, 5, 5, 5, 5, 5, 5, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4,\n",
      "        4, 5, 4, 5, 5, 5, 5, 4, 4, 5, 5, 4, 4, 5, 5, 5, 5, 5, 5, 4, 5, 5, 5, 5,\n",
      "        4, 5, 5, 5, 4, 5, 4, 5, 4, 4, 5, 5, 4, 5, 5, 5, 5, 5, 5, 4, 5, 5, 4, 4,\n",
      "        5, 5, 5, 5, 4, 5, 5, 5], device='cuda:0')\n",
      "tensor([[-0.3716, -0.3658, -0.3084,  0.2963,  0.5069,  0.3977, -0.5199, -0.3354,\n",
      "         -0.3765, -0.2063],\n",
      "        [-0.3707, -0.3652, -0.3076,  0.2915,  0.5079,  0.3968, -0.5179, -0.3338,\n",
      "         -0.3751, -0.2059],\n",
      "        [-0.3712, -0.3654, -0.3079,  0.2947,  0.5029,  0.3994, -0.5184, -0.3341,\n",
      "         -0.3759, -0.2059],\n",
      "        [-0.3713, -0.3652, -0.3088,  0.2962,  0.5055,  0.3967, -0.5195, -0.3355,\n",
      "         -0.3764, -0.2069]], device='cuda:0')\n",
      "tensor([[-0.3716, -0.3658, -0.3084,  0.2963,  0.5069,  0.3977, -0.5199, -0.3354,\n",
      "         -0.3765, -0.2063],\n",
      "        [-0.3707, -0.3652, -0.3076,  0.2915,  0.5079,  0.3968, -0.5179, -0.3338,\n",
      "         -0.3751, -0.2059],\n",
      "        [-0.3712, -0.3654, -0.3079,  0.2947,  0.5029,  0.3994, -0.5184, -0.3341,\n",
      "         -0.3759, -0.2059],\n",
      "        [-0.3713, -0.3652, -0.3088,  0.2962,  0.5055,  0.3967, -0.5195, -0.3355,\n",
      "         -0.3764, -0.2069]], device='cuda:0')\n",
      "tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4], device='cuda:0')\n",
      "predicted label\n",
      "        1       0       4       5       8       7\n",
      "0  3987.0    13.0     0.0     0.0     0.0     0.0\n",
      "1    22.0  3978.0     0.0     0.0     0.0     0.0\n",
      "2     0.0  4000.0     0.0     0.0     0.0     0.0\n",
      "3     0.0  4000.0     0.0     0.0     0.0     0.0\n",
      "4  4000.0     0.0     0.0     0.0     0.0     0.0\n",
      "5     0.0     0.0  2158.0  1842.0     0.0     0.0\n",
      "6     0.0     0.0  4000.0     0.0     0.0     0.0\n",
      "7     0.0     0.0  4000.0     0.0     0.0     0.0\n",
      "8     0.0     0.0     0.0     0.0  4000.0     0.0\n",
      "9     0.0     0.0     0.0     0.0     0.0  4000.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real cluster distribution: [0.5, 0.3, 0.2]\n",
      "Real cluster identity for each client: [0, 0, 0, 0, 0, 1, 1, 1, 2, 2]\n",
      "Predicted cluster identity for each client: [1, 0, 0, 0, 1, 2, 2, 2, 2, 2]\n",
      "output of get_client_logit\n",
      "(tensor([0.5437, 0.5401, 0.5420, 0.5369, 0.5396, 0.5467, 0.5462, 0.5422, 0.5423,\n",
      "        0.5440, 0.5475, 0.5369, 0.5429, 0.5425, 0.5399, 0.5420, 0.5424, 0.5414,\n",
      "        0.5420, 0.5373, 0.5417, 0.5446, 0.5425, 0.5406, 0.5435, 0.5393, 0.5472,\n",
      "        0.5399, 0.5441, 0.5449, 0.5430, 0.5480, 0.5351, 0.5393, 0.5402, 0.5424,\n",
      "        0.5395, 0.5460, 0.5442, 0.5424, 0.5377, 0.5444, 0.5428, 0.5433, 0.5387,\n",
      "        0.5401, 0.5429, 0.5410, 0.5424, 0.5383, 0.5421, 0.5318, 0.5385, 0.5379,\n",
      "        0.5437, 0.5418, 0.5481, 0.5450, 0.5416, 0.5412, 0.5451, 0.5443, 0.5438,\n",
      "        0.5436, 0.5412, 0.5438, 0.5458, 0.5509, 0.5372, 0.5460, 0.5443, 0.5435,\n",
      "        0.5331, 0.5488, 0.5410, 0.5460, 0.5329, 0.5417, 0.5432, 0.5387, 0.5424,\n",
      "        0.5432, 0.5461, 0.5438, 0.5463, 0.5389, 0.5407, 0.5426, 0.5428, 0.5401,\n",
      "        0.5435, 0.5360, 0.5399, 0.5457, 0.5422, 0.5389, 0.5444, 0.5462, 0.5417,\n",
      "        0.5424, 0.5439, 0.5408, 0.5425, 0.5450, 0.5408, 0.5460, 0.5461, 0.5471,\n",
      "        0.5451, 0.5372, 0.5434, 0.5416, 0.5408, 0.5401, 0.5432, 0.5481, 0.5440,\n",
      "        0.5351, 0.5451, 0.5456, 0.5470, 0.5336, 0.5482, 0.5356, 0.5477, 0.5464,\n",
      "        0.5420, 0.5460], device='cuda:0'), tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0'))\n",
      "output of get_client_logit\n",
      "(tensor([0.5741, 0.5697, 0.5722, 0.5725, 0.5638, 0.5641, 0.5794, 0.5785, 0.5796,\n",
      "        0.5680, 0.5703, 0.5746, 0.5628, 0.5727, 0.5783, 0.5725, 0.5786, 0.5772,\n",
      "        0.5660, 0.5757, 0.5750, 0.5672, 0.5623, 0.5709, 0.5773, 0.5715, 0.5750,\n",
      "        0.5816, 0.5811, 0.5735, 0.5696, 0.5757, 0.5709, 0.5672, 0.5706, 0.5783,\n",
      "        0.5761, 0.5762, 0.5693, 0.5708, 0.5750, 0.5709, 0.5710, 0.5663, 0.5690,\n",
      "        0.5731, 0.5863, 0.5759, 0.5719, 0.5774, 0.5731, 0.5717, 0.5770, 0.5714,\n",
      "        0.5761, 0.5724, 0.5744, 0.5779, 0.5713, 0.5772, 0.5719, 0.5661, 0.5717,\n",
      "        0.5748, 0.5671, 0.5658, 0.5748, 0.5689, 0.5608, 0.5583, 0.5581, 0.5646,\n",
      "        0.5645, 0.5713, 0.5682, 0.5795, 0.5665, 0.5690, 0.5567, 0.5676, 0.5573,\n",
      "        0.5675, 0.5652, 0.5648, 0.5619, 0.5634, 0.5593, 0.5720, 0.5675, 0.5737,\n",
      "        0.5667, 0.5629, 0.5676, 0.5624, 0.5584, 0.5611, 0.5752, 0.5599, 0.5674,\n",
      "        0.5704, 0.5691, 0.5678, 0.5734, 0.5641, 0.5669, 0.5713, 0.5554, 0.5605,\n",
      "        0.5637, 0.5643, 0.5652, 0.5628, 0.5808, 0.5646, 0.5641, 0.5628, 0.5686,\n",
      "        0.5659, 0.5636, 0.5676, 0.5703, 0.5696, 0.5568, 0.5621, 0.5669, 0.5620,\n",
      "        0.5570, 0.5725], device='cuda:0'), tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4], device='cuda:0'))\n",
      "output of get_client_logit\n",
      "(tensor([0.7481, 0.7521, 0.7413, 0.7570, 0.7526, 0.7552, 0.7465, 0.7470, 0.7444,\n",
      "        0.7537, 0.7481, 0.7396, 0.7535, 0.7576, 0.7539, 0.7556, 0.7474, 0.7553,\n",
      "        0.7522, 0.7499, 0.7591, 0.7501, 0.7561, 0.7533, 0.7485, 0.7523, 0.7492,\n",
      "        0.7462, 0.7464, 0.7467, 0.7498, 0.7475, 0.7506, 0.7527, 0.7513, 0.7596,\n",
      "        0.7461, 0.7425, 0.7511, 0.7466, 0.7503, 0.7512, 0.7618, 0.7533, 0.7505,\n",
      "        0.7492, 0.7466, 0.7498, 0.7441, 0.7486, 0.7534, 0.7584, 0.7535, 0.7406,\n",
      "        0.7401, 0.7497, 0.7526, 0.7508, 0.7514, 0.7460, 0.7504, 0.7557, 0.7490,\n",
      "        0.7547, 0.7457, 0.7515, 0.7484, 0.7464, 0.7555, 0.7601, 0.7577, 0.7574,\n",
      "        0.7553, 0.7469, 0.7531, 0.7429, 0.7603, 0.7557, 0.7560, 0.7502, 0.7606,\n",
      "        0.7593, 0.7589, 0.7465, 0.7579, 0.7592, 0.7563, 0.7455, 0.7546, 0.7547,\n",
      "        0.7545, 0.7582, 0.7555, 0.7575, 0.7558, 0.7623, 0.7488, 0.7480, 0.7519,\n",
      "        0.7474, 0.7536, 0.7544, 0.7448, 0.7532, 0.7600, 0.7481, 0.7629, 0.7509,\n",
      "        0.7595, 0.7512, 0.7574, 0.7583, 0.7480, 0.7558, 0.7630, 0.7611, 0.7547,\n",
      "        0.7488, 0.7563, 0.7524, 0.7457, 0.7576, 0.7498, 0.7497, 0.7559, 0.7521,\n",
      "        0.7553, 0.7432], device='cuda:0'), tensor([7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
      "        7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
      "        7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
      "        7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
      "        7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
      "        7, 7, 7, 7, 7, 7, 7, 7], device='cuda:0'))\n",
      "client 0 distill\n",
      "distill epoch 5, loss: 0.0009219719795510173\n",
      "distill epoch 5, loss: 0.0008787676924839616\n",
      "distill epoch 5, loss: 0.0009410922648385167\n",
      "distill epoch 5, loss: 0.000914344796910882\n",
      "distill epoch 5, loss: 0.001184436259791255\n",
      "distill epoch 5, loss: 0.0010228228056803346\n",
      "distill epoch 5, loss: 0.0010882860515266657\n",
      "distill epoch 5, loss: 0.0009559120517224073\n",
      "distill epoch 5, loss: 0.0008892093319445848\n",
      "distill epoch 5, loss: 0.0010476227616891265\n",
      "distill epoch 5, loss: 0.001028546248562634\n",
      "distill epoch 5, loss: 0.0010524853132665157\n",
      "distill epoch 5, loss: 0.0010372619144618511\n",
      "distill epoch 5, loss: 0.001038341666571796\n",
      "distill epoch 5, loss: 0.0008018373046070337\n",
      "distill epoch 5, loss: 0.0008450559107586741\n",
      "distill epoch 5, loss: 0.0010158633813261986\n",
      "distill epoch 5, loss: 0.0008491521002724767\n",
      "distill epoch 5, loss: 0.0010439404286444187\n",
      "distill epoch 5, loss: 0.0010927943512797356\n",
      "distill epoch 5, loss: 0.0009737106738612056\n",
      "distill epoch 5, loss: 0.0008119128178805113\n",
      "distill epoch 5, loss: 0.0008437959477305412\n",
      "distill epoch 5, loss: 0.0008726697415113449\n",
      "distill epoch 5, loss: 0.0009011913789436221\n",
      "distill epoch 5, loss: 0.0012340252287685871\n",
      "distill epoch 5, loss: 0.001150219701230526\n",
      "distill epoch 5, loss: 0.00094390450976789\n",
      "distill epoch 5, loss: 0.0009909083601087332\n",
      "distill epoch 5, loss: 0.0009157463791780174\n",
      "distill epoch 5, loss: 0.0010328921489417553\n",
      "distill epoch 5, loss: 0.00021961686434224248\n",
      "distill epoch 10, loss: 0.0012151924893260002\n",
      "distill epoch 10, loss: 0.0012973600532859564\n",
      "distill epoch 10, loss: 0.0010527733247727156\n",
      "distill epoch 10, loss: 0.0012659551575779915\n",
      "distill epoch 10, loss: 0.0012487791245803237\n",
      "distill epoch 10, loss: 0.0012969428207725286\n",
      "distill epoch 10, loss: 0.0011964230798184872\n",
      "distill epoch 10, loss: 0.001104914816096425\n",
      "distill epoch 10, loss: 0.0010287840850651264\n",
      "distill epoch 10, loss: 0.001301004085689783\n",
      "distill epoch 10, loss: 0.0012269081780686975\n",
      "distill epoch 10, loss: 0.0014441062230616808\n",
      "distill epoch 10, loss: 0.0013422835618257523\n",
      "distill epoch 10, loss: 0.001301166252233088\n",
      "distill epoch 10, loss: 0.0012042024172842503\n",
      "distill epoch 10, loss: 0.0012992550618946552\n",
      "distill epoch 10, loss: 0.001350012025795877\n",
      "distill epoch 10, loss: 0.0011643804609775543\n",
      "distill epoch 10, loss: 0.0012290789745748043\n",
      "distill epoch 10, loss: 0.0011891413014382124\n",
      "distill epoch 10, loss: 0.0014293388230726123\n",
      "distill epoch 10, loss: 0.0012176251038908958\n",
      "distill epoch 10, loss: 0.0012777664232999086\n",
      "distill epoch 10, loss: 0.0011204107431694865\n",
      "distill epoch 10, loss: 0.0013445413205772638\n",
      "distill epoch 10, loss: 0.0013195086503401399\n",
      "distill epoch 10, loss: 0.00116761215031147\n",
      "distill epoch 10, loss: 0.001344177289865911\n",
      "distill epoch 10, loss: 0.0012679147766903043\n",
      "distill epoch 10, loss: 0.0013941170182079077\n",
      "distill epoch 10, loss: 0.0014055928913876414\n",
      "distill epoch 10, loss: 0.0002965618623420596\n",
      "distill epoch 15, loss: 0.0016352785751223564\n",
      "distill epoch 15, loss: 0.0013511520810425282\n",
      "distill epoch 15, loss: 0.0014620234724134207\n",
      "distill epoch 15, loss: 0.0016097169136628509\n",
      "distill epoch 15, loss: 0.0016401781467720866\n",
      "distill epoch 15, loss: 0.001553365378640592\n",
      "distill epoch 15, loss: 0.0015779880341142416\n",
      "distill epoch 15, loss: 0.0016781706362962723\n",
      "distill epoch 15, loss: 0.0014600250869989395\n",
      "distill epoch 15, loss: 0.001401035115122795\n",
      "distill epoch 15, loss: 0.0015494207618758082\n",
      "distill epoch 15, loss: 0.0013666895683854818\n",
      "distill epoch 15, loss: 0.0015646121464669704\n",
      "distill epoch 15, loss: 0.0014721672050654888\n",
      "distill epoch 15, loss: 0.0012784075224772096\n",
      "distill epoch 15, loss: 0.001356276567094028\n",
      "distill epoch 15, loss: 0.0015730527229607105\n",
      "distill epoch 15, loss: 0.001496827811934054\n",
      "distill epoch 15, loss: 0.0014944563154131174\n",
      "distill epoch 15, loss: 0.0017933824565261602\n",
      "distill epoch 15, loss: 0.0017427441198378801\n",
      "distill epoch 15, loss: 0.0016796006821095943\n",
      "distill epoch 15, loss: 0.0016073589213192463\n",
      "distill epoch 15, loss: 0.0015069509390741587\n",
      "distill epoch 15, loss: 0.0013130224542692304\n",
      "distill epoch 15, loss: 0.0013364466140046716\n",
      "distill epoch 15, loss: 0.0012781484983861446\n",
      "distill epoch 15, loss: 0.001304042525589466\n",
      "distill epoch 15, loss: 0.001185151981189847\n",
      "distill epoch 15, loss: 0.0016226605512201786\n",
      "distill epoch 15, loss: 0.0014069410972297192\n",
      "distill epoch 15, loss: 0.0003455511759966612\n",
      "distill epoch 20, loss: 0.0016447268426418304\n",
      "distill epoch 20, loss: 0.0014538911636918783\n",
      "distill epoch 20, loss: 0.0015632433351129293\n",
      "distill epoch 20, loss: 0.0016602473333477974\n",
      "distill epoch 20, loss: 0.0014039503876119852\n",
      "distill epoch 20, loss: 0.0017130146734416485\n",
      "distill epoch 20, loss: 0.001737877493724227\n",
      "distill epoch 20, loss: 0.0014880673261359334\n",
      "distill epoch 20, loss: 0.0017141455318778753\n",
      "distill epoch 20, loss: 0.0016050920821726322\n",
      "distill epoch 20, loss: 0.0014064182760193944\n",
      "distill epoch 20, loss: 0.0014295380096882582\n",
      "distill epoch 20, loss: 0.0016920322086662054\n",
      "distill epoch 20, loss: 0.0015721695963293314\n",
      "distill epoch 20, loss: 0.001481904648244381\n",
      "distill epoch 20, loss: 0.0015161170158535242\n",
      "distill epoch 20, loss: 0.0016397270374000072\n",
      "distill epoch 20, loss: 0.0014124361332505941\n",
      "distill epoch 20, loss: 0.0014648694777861238\n",
      "distill epoch 20, loss: 0.001440216787159443\n",
      "distill epoch 20, loss: 0.0015904325991868973\n",
      "distill epoch 20, loss: 0.001623931573703885\n",
      "distill epoch 20, loss: 0.0014567712787538767\n",
      "distill epoch 20, loss: 0.0016091177240014076\n",
      "distill epoch 20, loss: 0.001575187430717051\n",
      "distill epoch 20, loss: 0.0015888065099716187\n",
      "distill epoch 20, loss: 0.0015828801551833749\n",
      "distill epoch 20, loss: 0.0015192944556474686\n",
      "distill epoch 20, loss: 0.0014482797123491764\n",
      "distill epoch 20, loss: 0.0013948606792837381\n",
      "distill epoch 20, loss: 0.001510891946963966\n",
      "distill epoch 20, loss: 0.00030511117074638605\n",
      "total_client_data: 40000, data_per_class: 400, cluster_distribution: [0.5, 0.3, 0.2]\n",
      "first acc: 0.632, [0.631, 0.556, 0.747], 0.2\n",
      "acc before distill: 0.751, [0.779, 0.619, 0.881], 0.222\n",
      "last acc: 0.283, [0.336, 0.333, 0.075], 0.223\n",
      "number_of_cluster: 3\n",
      "client idcs generated!\n",
      "Train Label Distribution for client 0: Counter({2: 140, 0: 140, 1: 140})\n",
      "Evaluation Label Distribution for client 0: Counter({2: 60, 0: 60, 1: 60})\n",
      "Train Label Distribution for client 1: Counter({1: 140, 0: 140, 2: 140})\n",
      "Evaluation Label Distribution for client 1: Counter({2: 60, 0: 60, 1: 60})\n",
      "Train Label Distribution for client 2: Counter({2: 140, 0: 140, 1: 140})\n",
      "Evaluation Label Distribution for client 2: Counter({1: 60, 0: 60, 2: 60})\n",
      "Train Label Distribution for client 3: Counter({1: 140, 2: 140, 0: 140})\n",
      "Evaluation Label Distribution for client 3: Counter({1: 60, 0: 60, 2: 60})\n",
      "Train Label Distribution for client 4: Counter({1: 140, 0: 140, 2: 140})\n",
      "Evaluation Label Distribution for client 4: Counter({1: 60, 0: 60, 2: 60})\n",
      "Train Label Distribution for client 5: Counter({5: 140, 3: 140, 4: 140})\n",
      "Evaluation Label Distribution for client 5: Counter({4: 60, 5: 60, 3: 60})\n",
      "Train Label Distribution for client 6: Counter({5: 140, 4: 140, 3: 140})\n",
      "Evaluation Label Distribution for client 6: Counter({5: 60, 3: 60, 4: 60})\n",
      "Train Label Distribution for client 7: Counter({4: 140, 5: 140, 3: 140})\n",
      "Evaluation Label Distribution for client 7: Counter({4: 60, 3: 60, 5: 60})\n",
      "Train Label Distribution for client 8: Counter({8: 140, 6: 140, 7: 140})\n",
      "Evaluation Label Distribution for client 8: Counter({7: 60, 6: 60, 8: 60})\n",
      "Train Label Distribution for client 9: Counter({6: 140, 7: 140, 8: 140})\n",
      "Evaluation Label Distribution for client 9: Counter({6: 60, 8: 60, 7: 60})\n",
      "client count: 10\n",
      "client_acc: 0.44, cluster_acc: [0.5, 0.3, 0.2]: [0.441, 0.415, 0.475],  global_acc: 0.132\n",
      "output in train\n",
      "(tensor([ 8.6046,  5.1816,  4.4079,  1.6771,  3.8172,  1.5299,  7.8353,  3.1176,\n",
      "         3.3390,  3.4795,  1.4828,  2.9771,  8.1758,  3.0218,  1.7961,  5.6247,\n",
      "         2.8756,  5.9050,  3.3517,  6.8606,  2.3098,  1.9630,  3.9649,  0.9198,\n",
      "         1.6742,  6.3286,  3.3076,  7.1189,  5.6848,  7.4338,  3.5995,  5.1947,\n",
      "         5.0618,  1.3177,  7.9343,  5.4500,  4.9012,  8.4754,  4.5479,  3.8439,\n",
      "         2.1279,  4.5606,  4.4538,  4.5177,  5.0305,  0.9046,  3.6371,  1.2630,\n",
      "         0.9108,  0.9115,  3.5774,  4.7229,  7.6173,  4.9033,  6.5257,  5.2285,\n",
      "        10.7945,  6.9318,  5.3732,  4.8101,  2.1971,  4.6581,  7.7265,  3.3988,\n",
      "         3.8697,  5.6231,  3.7602,  6.7180,  6.4945,  2.4677,  8.1252,  3.9321,\n",
      "         2.9918,  2.5809,  5.9655,  2.7236,  2.4818,  4.2212,  3.0101,  4.4947,\n",
      "         4.9965,  4.6549,  4.2472,  5.6253,  2.2994,  6.8741,  3.2291,  0.7982,\n",
      "         2.9364,  3.4295,  4.5796,  9.0773,  4.3637,  3.3459,  4.1820,  6.1418,\n",
      "         2.9495,  8.6953,  3.7189,  6.3759,  5.5734,  5.1113,  1.5879,  2.3915,\n",
      "         2.1913,  6.1286,  2.7487,  5.0962,  2.3693,  4.0712,  7.3097,  2.9049,\n",
      "         5.9090,  5.0292,  6.6170,  5.0133,  4.0858,  3.0152,  4.8733,  4.5776,\n",
      "         4.2939,  4.6647,  2.4315,  2.3333,  4.1550,  6.2518,  3.8892,  5.1260],\n",
      "       device='cuda:0'), tensor([0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 2, 2, 1, 2, 0, 1, 1, 2, 2, 1, 2, 2, 0, 1,\n",
      "        0, 2, 1, 2, 0, 0, 0, 0, 2, 2, 0, 1, 1, 2, 0, 2, 0, 0, 0, 2, 0, 0, 1, 2,\n",
      "        1, 2, 1, 1, 1, 1, 2, 2, 0, 2, 2, 2, 1, 1, 2, 1, 0, 2, 0, 2, 1, 0, 2, 1,\n",
      "        1, 1, 0, 2, 1, 2, 0, 2, 1, 2, 1, 1, 1, 0, 0, 2, 2, 2, 0, 0, 2, 0, 2, 0,\n",
      "        0, 1, 2, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 1, 2, 2, 1, 0, 2, 1, 0, 2, 0,\n",
      "        1, 2, 0, 1, 1, 2, 0, 1], device='cuda:0'))\n",
      "client_acc: 0.65, cluster_acc: [0.5, 0.3, 0.2]: [0.669, 0.53, 0.783],  global_acc: 0.143\n",
      "client_acc: 0.716, cluster_acc: [0.5, 0.3, 0.2]: [0.732, 0.609, 0.836],  global_acc: 0.1\n",
      "client_acc: 0.735, cluster_acc: [0.5, 0.3, 0.2]: [0.76, 0.622, 0.842],  global_acc: 0.187\n",
      "output in train\n",
      "(tensor([3.2798, 5.0667, 5.7916, 4.3497, 3.7028, 3.1742, 7.1846, 4.1319, 2.5375,\n",
      "        2.4424, 2.2014, 4.3677, 4.8087, 3.9478, 1.8651, 4.7936, 5.1318, 4.1550,\n",
      "        3.3155, 2.8854, 2.9323, 4.8776, 5.0181, 4.7571, 3.1142, 2.7647, 4.5231,\n",
      "        3.6901, 6.8060, 5.0144, 1.0349, 6.2522, 5.7093, 3.6051, 4.2867, 4.5466],\n",
      "       device='cuda:0'), tensor([0, 2, 2, 1, 1, 0, 2, 0, 0, 0, 1, 2, 0, 2, 0, 2, 0, 0, 0, 0, 1, 1, 0, 1,\n",
      "        2, 1, 1, 0, 1, 0, 0, 1, 2, 2, 2, 1], device='cuda:0'))\n",
      "client_acc: 0.749, cluster_acc: [0.5, 0.3, 0.2]: [0.779, 0.622, 0.864],  global_acc: 0.187\n",
      "client 0 distill\n",
      "distill epoch 5, loss: 0.000935371732339263\n",
      "distill epoch 5, loss: 0.0010258215479552746\n",
      "distill epoch 5, loss: 0.0010062858927994967\n",
      "distill epoch 5, loss: 0.0009379241382703185\n",
      "distill epoch 5, loss: 0.0010141758248209953\n",
      "distill epoch 5, loss: 0.0010491606080904603\n",
      "distill epoch 5, loss: 0.0009417431429028511\n",
      "distill epoch 5, loss: 0.0010198696982115507\n",
      "distill epoch 5, loss: 0.000961249228566885\n",
      "distill epoch 5, loss: 0.0008785868994891644\n",
      "distill epoch 5, loss: 0.0008864820702001452\n",
      "distill epoch 5, loss: 0.0009589418768882751\n",
      "distill epoch 5, loss: 0.000876736652571708\n",
      "distill epoch 5, loss: 0.0009977661538869143\n",
      "distill epoch 5, loss: 0.0008756045717746019\n",
      "distill epoch 5, loss: 0.0008869137382134795\n",
      "distill epoch 5, loss: 0.0009372396161779761\n",
      "distill epoch 5, loss: 0.0007910829735919833\n",
      "distill epoch 5, loss: 0.0008143726736307144\n",
      "distill epoch 5, loss: 0.0008298340253531933\n",
      "distill epoch 5, loss: 0.00081883545499295\n",
      "distill epoch 5, loss: 0.0008230012026615441\n",
      "distill epoch 5, loss: 0.0008696847362443805\n",
      "distill epoch 5, loss: 0.0007428647368215024\n",
      "distill epoch 5, loss: 0.0007357198046520352\n",
      "distill epoch 5, loss: 0.0006964968633837998\n",
      "distill epoch 5, loss: 0.0007725114701315761\n",
      "distill epoch 5, loss: 0.0007908872794359922\n",
      "distill epoch 5, loss: 0.00081312854308635\n",
      "distill epoch 5, loss: 0.0007896156166680157\n",
      "distill epoch 5, loss: 0.0007796640275046229\n",
      "distill epoch 5, loss: 0.0002104718005284667\n",
      "distill epoch 10, loss: 0.0003467290080152452\n",
      "distill epoch 10, loss: 0.0003935604472644627\n",
      "distill epoch 10, loss: 0.0004344286862760782\n",
      "distill epoch 10, loss: 0.000376288837287575\n",
      "distill epoch 10, loss: 0.0004496722249314189\n",
      "distill epoch 10, loss: 0.0003885186742991209\n",
      "distill epoch 10, loss: 0.0004046233370900154\n",
      "distill epoch 10, loss: 0.00037735782098025084\n",
      "distill epoch 10, loss: 0.00036245916271582246\n",
      "distill epoch 10, loss: 0.0003897736896760762\n",
      "distill epoch 10, loss: 0.0003962941700592637\n",
      "distill epoch 10, loss: 0.00039216887671500444\n",
      "distill epoch 10, loss: 0.0004058716003783047\n",
      "distill epoch 10, loss: 0.00040181493386626244\n",
      "distill epoch 10, loss: 0.0003445517795626074\n",
      "distill epoch 10, loss: 0.00037605600664392114\n",
      "distill epoch 10, loss: 0.0004511296283453703\n",
      "distill epoch 10, loss: 0.0003883375902660191\n",
      "distill epoch 10, loss: 0.00037304579745978117\n",
      "distill epoch 10, loss: 0.0003578879695851356\n",
      "distill epoch 10, loss: 0.0004004957154393196\n",
      "distill epoch 10, loss: 0.0003706786083057523\n",
      "distill epoch 10, loss: 0.00032322367769666016\n",
      "distill epoch 10, loss: 0.00043113771243952215\n",
      "distill epoch 10, loss: 0.00038215750828385353\n",
      "distill epoch 10, loss: 0.0003895694389939308\n",
      "distill epoch 10, loss: 0.00033661024644970894\n",
      "distill epoch 10, loss: 0.0004054841701872647\n",
      "distill epoch 10, loss: 0.00039897902752272785\n",
      "distill epoch 10, loss: 0.0003491606912575662\n",
      "distill epoch 10, loss: 0.00035217381082475185\n",
      "distill epoch 10, loss: 7.92778009781614e-05\n",
      "distill epoch 15, loss: 0.0004427884123288095\n",
      "distill epoch 15, loss: 0.0004085007240064442\n",
      "distill epoch 15, loss: 0.000418828334659338\n",
      "distill epoch 15, loss: 0.00043478162842802703\n",
      "distill epoch 15, loss: 0.0004040398634970188\n",
      "distill epoch 15, loss: 0.0003849523200187832\n",
      "distill epoch 15, loss: 0.0004060884821228683\n",
      "distill epoch 15, loss: 0.0004220271948724985\n",
      "distill epoch 15, loss: 0.00042431222391314805\n",
      "distill epoch 15, loss: 0.0004373093252070248\n",
      "distill epoch 15, loss: 0.00044128234731033444\n",
      "distill epoch 15, loss: 0.0004421523481141776\n",
      "distill epoch 15, loss: 0.00048046273877844214\n",
      "distill epoch 15, loss: 0.0004927609115839005\n",
      "distill epoch 15, loss: 0.0003719070227816701\n",
      "distill epoch 15, loss: 0.00041143852286040783\n",
      "distill epoch 15, loss: 0.000374763912986964\n",
      "distill epoch 15, loss: 0.00040967337554320693\n",
      "distill epoch 15, loss: 0.0004514822503551841\n",
      "distill epoch 15, loss: 0.00039451103657484055\n",
      "distill epoch 15, loss: 0.0004876701859757304\n",
      "distill epoch 15, loss: 0.0004296110710129142\n",
      "distill epoch 15, loss: 0.000418824958615005\n",
      "distill epoch 15, loss: 0.0004107253917027265\n",
      "distill epoch 15, loss: 0.00043791066855192184\n",
      "distill epoch 15, loss: 0.000383600068744272\n",
      "distill epoch 15, loss: 0.0004217959940433502\n",
      "distill epoch 15, loss: 0.00039967341581359506\n",
      "distill epoch 15, loss: 0.00042574998224154115\n",
      "distill epoch 15, loss: 0.0004433467984199524\n",
      "distill epoch 15, loss: 0.00046989231486804783\n",
      "distill epoch 15, loss: 9.3397859018296e-05\n",
      "distill epoch 20, loss: 0.0004790002712979913\n",
      "distill epoch 20, loss: 0.000438999937614426\n",
      "distill epoch 20, loss: 0.0004492326988838613\n",
      "distill epoch 20, loss: 0.0004384053172543645\n",
      "distill epoch 20, loss: 0.00040589552372694016\n",
      "distill epoch 20, loss: 0.0004157768562436104\n",
      "distill epoch 20, loss: 0.000498992798384279\n",
      "distill epoch 20, loss: 0.0003764667781069875\n",
      "distill epoch 20, loss: 0.00043605873361229897\n",
      "distill epoch 20, loss: 0.0004288531490601599\n",
      "distill epoch 20, loss: 0.00042586459312587976\n",
      "distill epoch 20, loss: 0.00043239601654931903\n",
      "distill epoch 20, loss: 0.0003876879345625639\n",
      "distill epoch 20, loss: 0.00042339449282735586\n",
      "distill epoch 20, loss: 0.00047901493962854147\n",
      "distill epoch 20, loss: 0.00047207577154040337\n",
      "distill epoch 20, loss: 0.0003710211312863976\n",
      "distill epoch 20, loss: 0.0004690276982728392\n",
      "distill epoch 20, loss: 0.0004286578041501343\n",
      "distill epoch 20, loss: 0.0005147616611793637\n",
      "distill epoch 20, loss: 0.00042461883276700974\n",
      "distill epoch 20, loss: 0.0004794779233634472\n",
      "distill epoch 20, loss: 0.0005020122043788433\n",
      "distill epoch 20, loss: 0.00042685394873842597\n",
      "distill epoch 20, loss: 0.00044098205398768187\n",
      "distill epoch 20, loss: 0.0004531239392235875\n",
      "distill epoch 20, loss: 0.00042254640720784664\n",
      "distill epoch 20, loss: 0.00045984171447344124\n",
      "distill epoch 20, loss: 0.0004641300765797496\n",
      "distill epoch 20, loss: 0.00042829514131881297\n",
      "distill epoch 20, loss: 0.0004461169010028243\n",
      "distill epoch 20, loss: 0.00011052275658585131\n",
      "total_client_data: 40000, data_per_class: 400, cluster_distribution: [0.5, 0.3, 0.2]\n",
      "first acc: 0.44, [0.441, 0.415, 0.475], 0.132\n",
      "acc before distill: 0.749, [0.779, 0.622, 0.864], 0.187\n",
      "last acc: 0.169, [0.33, 0.013, 0.0], 0.446\n"
     ]
    }
   ],
   "source": [
    "now = datetime.datetime.now(pytz.timezone('Asia/Seoul'))\n",
    "date_time = now.strftime(\"%m%d_%H%M\")\n",
    "\n",
    "columns = pd.MultiIndex.from_product([['client_accs', 'cluster_accs', 'global_accs'], ['before_distill', 'after_distill']],\n",
    "                                     names=['acc_type', 'distill_state'])\n",
    "\n",
    "# The tuples for which we want to run the experiment \n",
    "desired_pairs = [(40000, 4000)]\n",
    "cluster_distribution = [0.5, 0.3, 0.2]\n",
    "# Add additional index 'global_distill' and 'cluster_distill'\n",
    "experiments = ['cluster_distill', 'global_distill']\n",
    "index = pd.MultiIndex.from_product([experiments, desired_pairs], names=['experiment', 'data_pair'])\n",
    "\n",
    "# Initialize an empty DataFrame with the desired index for rows and columns\n",
    "df = pd.DataFrame(index=index, columns=columns)\n",
    "\n",
    "for exp in experiments:\n",
    "    for pair in desired_pairs:\n",
    "        client_data, distill_data = pair\n",
    "\n",
    "        if exp == 'global_distill':\n",
    "            client_accs, cluster_accs, global_accs = global_distill_experiments(client_data, distill_data, ALPHA, NUMBER_OF_CLUSTER, cluster_distribution)\n",
    "        else:\n",
    "            client_accs, cluster_accs, global_accs = cluster_distill_experiments(client_data, distill_data, ALPHA, NUMBER_OF_CLUSTER, cluster_distribution)\n",
    "\n",
    "        # Set the values in the DataFrame\n",
    "        df.loc[(exp, pair), ('client_accs', 'before_distill')] = client_accs[-2]\n",
    "        df.loc[(exp, pair), ('client_accs', 'after_distill')] = client_accs[-1]\n",
    "        df.loc[(exp, pair), ('global_accs', 'before_distill')] = global_accs[-2]\n",
    "        df.loc[(exp, pair), ('global_accs', 'after_distill')] = global_accs[-1]\n",
    "        df.loc[(exp, pair), ('cluster_accs', 'before_distill')] = cluster_accs[-2]\n",
    "        df.loc[(exp, pair), ('cluster_accs', 'after_distill')] = cluster_accs[-1]\n",
    "\n",
    "        directory = f'results/Unbalanced_cluster'\n",
    "\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "        cluster_distribution_str = \"_\".join(map(str, cluster_distribution))\n",
    "        file_name = f'{directory}/client:{N_CLIENTS}_cluster:{NUMBER_OF_CLUSTER}_distribution:{cluster_distribution_str}_{date_time}.csv'\n",
    "        df = df.round(decimals=3)\n",
    "        df.to_csv(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-07T02:44:32.367148Z",
     "iopub.status.busy": "2023-08-07T02:44:32.366153Z",
     "iopub.status.idle": "2023-08-07T02:44:32.380302Z",
     "shell.execute_reply": "2023-08-07T02:44:32.379488Z",
     "shell.execute_reply.started": "2023-08-07T02:44:32.367114Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>acc_type</th>\n",
       "      <th colspan=\"2\" halign=\"left\">client_accs</th>\n",
       "      <th colspan=\"2\" halign=\"left\">cluster_accs</th>\n",
       "      <th colspan=\"2\" halign=\"left\">global_accs</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>distill_state</th>\n",
       "      <th>before_distill</th>\n",
       "      <th>after_distill</th>\n",
       "      <th>before_distill</th>\n",
       "      <th>after_distill</th>\n",
       "      <th>before_distill</th>\n",
       "      <th>after_distill</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment</th>\n",
       "      <th>data_pair</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cluster_distill</th>\n",
       "      <th>(40000, 4000)</th>\n",
       "      <td>0.751</td>\n",
       "      <td>0.283</td>\n",
       "      <td>[0.779, 0.619, 0.881]</td>\n",
       "      <td>[0.336, 0.333, 0.075]</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>global_distill</th>\n",
       "      <th>(40000, 4000)</th>\n",
       "      <td>0.749</td>\n",
       "      <td>0.169</td>\n",
       "      <td>[0.779, 0.622, 0.864]</td>\n",
       "      <td>[0.33, 0.013, 0.0]</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.446</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "acc_type                         client_accs                \\\n",
       "distill_state                 before_distill after_distill   \n",
       "experiment      data_pair                                    \n",
       "cluster_distill (40000, 4000)          0.751         0.283   \n",
       "global_distill  (40000, 4000)          0.749         0.169   \n",
       "\n",
       "acc_type                                cluster_accs                         \\\n",
       "distill_state                         before_distill          after_distill   \n",
       "experiment      data_pair                                                     \n",
       "cluster_distill (40000, 4000)  [0.779, 0.619, 0.881]  [0.336, 0.333, 0.075]   \n",
       "global_distill  (40000, 4000)  [0.779, 0.622, 0.864]     [0.33, 0.013, 0.0]   \n",
       "\n",
       "acc_type                         global_accs                \n",
       "distill_state                 before_distill after_distill  \n",
       "experiment      data_pair                                   \n",
       "cluster_distill (40000, 4000)          0.222         0.223  \n",
       "global_distill  (40000, 4000)          0.187         0.446  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-07T02:44:32.381726Z",
     "iopub.status.busy": "2023-08-07T02:44:32.381273Z",
     "iopub.status.idle": "2023-08-07T02:44:32.656597Z",
     "shell.execute_reply": "2023-08-07T02:44:32.654718Z",
     "shell.execute_reply.started": "2023-08-07T02:44:32.381697Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'results/global_distill/CIFAR_0720_0435.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mresults/global_distill/CIFAR_0720_0435.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# 그릴 데이터와 제목을 리스트로 저장\u001b[39;00m\n\u001b[1;32m      4\u001b[0m heatmap_data \u001b[38;5;241m=\u001b[39m [(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclient_accs\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchange_after_distill\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClient Accuracy change after Distillation\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m      5\u001b[0m                 (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mglobal_accs\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchange_after_distill\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGlobal Accuracy change after Distillation\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n",
      "File \u001b[0;32m~/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages/pandas/io/common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'results/global_distill/CIFAR_0720_0435.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('results/global_distill/CIFAR_0720_0435.csv', index_col=[0,1], header=[0,1])\n",
    "\n",
    "# 그릴 데이터와 제목을 리스트로 저장\n",
    "heatmap_data = [('client_accs', 'change_after_distill', 'Client Accuracy change after Distillation'),\n",
    "                ('global_accs', 'change_after_distill', 'Global Accuracy change after Distillation')]\n",
    "\n",
    "# Compute change in accuracy\n",
    "df[('client_accs', 'change_after_distill')] = df[('client_accs', 'after_distill')] - df[('client_accs', 'before_distill')]\n",
    "df[('global_accs', 'change_after_distill')] = df[('global_accs', 'after_distill')] - df[('global_accs', 'before_distill')]\n",
    "\n",
    "# 전체 데이터의 최솟값, 최댓값 계산\n",
    "vmin = min(df[data1][data2].min() for data1, data2, _ in heatmap_data)\n",
    "vmax = max(df[data1][data2].max() for data1, data2, _ in heatmap_data)\n",
    "\n",
    "for data1, data2, title in heatmap_data:\n",
    "    plt.figure(figsize=(9, 5))\n",
    "    sns.heatmap(df[(data1, data2)].unstack(), annot=True, cmap='coolwarm', center=0, vmin=-0.1, vmax=0.2)\n",
    "    plt.title(title)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Clustering 실험"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-07T02:44:32.657393Z",
     "iopub.status.idle": "2023-08-07T02:44:32.657603Z",
     "shell.execute_reply": "2023-08-07T02:44:32.657503Z",
     "shell.execute_reply.started": "2023-08-07T02:44:32.657494Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def do_clustering_experiments(total_client_data=total_client_data, data_per_class=data_per_class, ALPHA=ALPHA):\n",
    "    train_idcs, test_idcs = idcs[:int(total_client_data*10)], idcs[int(total_client_data*10):]\n",
    "    train_labels = data.train_labels.numpy()\n",
    "    test_labels = data.train_labels.numpy()[int(total_client_data*10):]\n",
    "\n",
    "    client_idcs = split_noniid(train_idcs, train_labels, alpha=ALPHA, n_clients=N_CLIENTS)#, data_per_class=int(total_client_data/10))\n",
    "    # server_idcs = generate_server_idcs(test_idcs, test_labels, int(total_client_data*10))\n",
    "\n",
    "    client_data = [CustomSubset(data, idcs) for idcs in client_idcs]\n",
    "    test_data = CustomSubset(data, test_idcs, transforms.Compose([transforms.ToTensor()]))\n",
    "    \n",
    "    for i, client_datum in enumerate(client_data):\n",
    "        client_datum.subset_transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "    server = Server(resnet18, lambda x : torch.optim.SGD(x, lr=0.1, momentum=0.9),test_data)\n",
    "\n",
    "    \n",
    "    distillation_data_file = f'distillation_data_{data_per_class}_per_class.pth'\n",
    "\n",
    "    # Check if the file already exists\n",
    "    if not os.path.exists(distillation_data_file):\n",
    "        # The file does not exist, generate and save the distillation data\n",
    "        distillation_data = server.make_distillation_data(data_per_class=data_per_class)\n",
    "        torch.save(distillation_data, distillation_data_file)\n",
    "\n",
    "    # Load the distillation data\n",
    "    distillation_data = torch.load(distillation_data_file)\n",
    "\n",
    "    clients = [Client(resnet18, lambda x : torch.optim.SGD(x, lr=0.1, momentum=0.9), dat, i, distillation_data) \n",
    "               for i, dat in enumerate(client_data)]\n",
    "\n",
    "    def aggregate(cluster_indices_new):\n",
    "        cluster_indices = cluster_indices_new\n",
    "        client_clusters = [[clients[i] for i in idcs] for idcs in cluster_indices]\n",
    "\n",
    "        server.aggregate_clusterwise(client_clusters)\n",
    "\n",
    "        return cluster_indices\n",
    "\n",
    "    cfl_stats = ExperimentLogger()\n",
    "\n",
    "    cluster_indices = [np.arange(len(clients)).astype(\"int\")]\n",
    "    client_clusters = [[clients[i] for i in idcs] for idcs in cluster_indices]\n",
    "\n",
    "\n",
    "    for epoch in range(1, LOCAL_EPOCHS+1):\n",
    "\n",
    "        if epoch == 1:\n",
    "            for client in clients:\n",
    "                client.synchronize_with_server(server)\n",
    "\n",
    "        participating_clients = server.select_clients(clients, frac=1.0)\n",
    "\n",
    "        for client in participating_clients:\n",
    "            if epoch == 1:\n",
    "                client.distill()\n",
    "\n",
    "            train_stats = client.compute_weight_update(epochs=1) #train client\n",
    "\n",
    "            if epoch == 1000:\n",
    "                client.reset()\n",
    "\n",
    "        cluster_indices_new = []\n",
    "\n",
    "        for idc in cluster_indices:\n",
    "            max_norm = server.compute_max_update_norm([clients[i] for i in idc])\n",
    "            mean_norm = server.compute_mean_update_norm([clients[i] for i in idc])\n",
    "\n",
    "            #cluster 나누는 기준\n",
    "            if epoch == LOCAL_EPOCHS: #무조건 한번 나누기\n",
    "                similarities = server.compute_pairwise_similarities(clients)\n",
    "\n",
    "                server.cache_model(idc, clients[idc[0]].W, acc_clients)\n",
    "\n",
    "                c1, c2, c3 = server.cluster_clients_GMM(similarities[idc][:,idc])\n",
    "                cluster_indices_new += [c1, c2, c3]\n",
    "\n",
    "        if epoch == 1000:\n",
    "            cluster_indices = aggregate(cluster_indices_new)\n",
    "\n",
    "        acc_clients = [client.evaluate() for client in clients]\n",
    "\n",
    "        if epoch == LOCAL_EPOCHS: #무조건 한번 나누기\n",
    "            label_accuracies = pd.DataFrame()\n",
    "            label_predicted = pd.DataFrame()\n",
    "            label_soft_sum = pd.DataFrame()\n",
    "            label_diff = pd.DataFrame()\n",
    "\n",
    "            for i, client in enumerate(clients):\n",
    "                acc, pred, sum_, diff = server.evaluate(client.model)\n",
    "                # Convert each dictionary to a DataFrame and append to the respective DataFrame\n",
    "                label_accuracies = label_accuracies.append(pd.DataFrame(acc, index=[i]))\n",
    "                label_predicted = label_predicted.append(pd.DataFrame(pred, index=[i]))\n",
    "                label_soft_sum = label_soft_sum.append(pd.DataFrame(sum_, index=[i]))\n",
    "                label_diff = label_diff.append(pd.DataFrame(diff, index=[i]))\n",
    "\n",
    "            # Reset index for all DataFrames\n",
    "            label_accuracies.reset_index(drop=True, inplace=True)\n",
    "            label_predicted.reset_index(drop=True, inplace=True)\n",
    "            label_soft_sum.reset_index(drop=True, inplace=True)\n",
    "            label_diff.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        if epoch == 1:\n",
    "            first_accuracies = pd.DataFrame()\n",
    "            for i, client in enumerate(clients):\n",
    "                first_acc, pred, sum_, diff = server.evaluate(client.model)\n",
    "                first_accuracies = pd.concat([first_accuracies, pd.DataFrame(first_acc, index=[i])])\n",
    "            first_accuracies = first_accuracies.fillna(0)\n",
    "\n",
    "            client_acc_after_distill = sum(acc_clients)/len(acc_clients)\n",
    "            global_acc_after_distill = np.mean(np.ravel(first_accuracies.values))\n",
    "\n",
    "\n",
    "        elif epoch == LOCAL_EPOCHS:\n",
    "            client_acc_final = sum(acc_clients)/len(acc_clients)\n",
    "            global_acc_final = np.mean(np.ravel(label_accuracies.values))\n",
    "\n",
    "        average_dw = server.get_average_dw(clients)\n",
    "        #print(average_dw)\n",
    "        cfl_stats.log({\"acc_clients\" : acc_clients, \"mean_norm\" : mean_norm, \"max_norm\" : max_norm,\n",
    "                      \"rounds\" : epoch, \"clusters\" : cluster_indices, \"average_dw\": average_dw})\n",
    "\n",
    "\n",
    "        display_train_stats(cfl_stats, EPS_1, EPS_2, LOCAL_EPOCHS)\n",
    "\n",
    "\n",
    "    for idc in cluster_indices:    \n",
    "        server.cache_model(idc, clients[idc[0]].W, acc_clients)\n",
    "    \n",
    "    client_acc_after_distill = round(client_acc_after_distill, 3)\n",
    "    global_acc_after_distill = round(global_acc_after_distill, 3)\n",
    "    client_acc_final = round(client_acc_final, 3)\n",
    "    global_acc_final = round(global_acc_final, 3)\n",
    "    \n",
    "    return client_acc_after_distill, global_acc_after_distill, client_acc_final, global_acc_final\n",
    "\n",
    "    print(client_acc_after_distill, global_acc_after_distill)\n",
    "    print(client_acc_final, global_acc_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-07T02:44:32.658433Z",
     "iopub.status.idle": "2023-08-07T02:44:32.658608Z",
     "shell.execute_reply": "2023-08-07T02:44:32.658531Z",
     "shell.execute_reply.started": "2023-08-07T02:44:32.658523Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "first_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-07T02:44:32.660260Z",
     "iopub.status.idle": "2023-08-07T02:44:32.660446Z",
     "shell.execute_reply": "2023-08-07T02:44:32.660362Z",
     "shell.execute_reply.started": "2023-08-07T02:44:32.660353Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "label_accuracies.sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-07T02:44:32.661574Z",
     "iopub.status.idle": "2023-08-07T02:44:32.661776Z",
     "shell.execute_reply": "2023-08-07T02:44:32.661676Z",
     "shell.execute_reply.started": "2023-08-07T02:44:32.661668Z"
    }
   },
   "outputs": [],
   "source": [
    "label_soft_sum.sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-07T02:44:32.663487Z",
     "iopub.status.idle": "2023-08-07T02:44:32.664122Z",
     "shell.execute_reply": "2023-08-07T02:44:32.663919Z",
     "shell.execute_reply.started": "2023-08-07T02:44:32.663901Z"
    }
   },
   "outputs": [],
   "source": [
    "label_diff.sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-07T02:44:32.665065Z",
     "iopub.status.idle": "2023-08-07T02:44:32.665356Z",
     "shell.execute_reply": "2023-08-07T02:44:32.665224Z",
     "shell.execute_reply.started": "2023-08-07T02:44:32.665210Z"
    }
   },
   "outputs": [],
   "source": [
    "label_predicted.sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-07T02:44:32.666347Z",
     "iopub.status.idle": "2023-08-07T02:44:32.666688Z",
     "shell.execute_reply": "2023-08-07T02:44:32.666523Z",
     "shell.execute_reply.started": "2023-08-07T02:44:32.666507Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "# Instantiate PCA\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "# Apply PCA to the dataframes\n",
    "label_accuracies_pca = pca.fit_transform(label_accuracies)\n",
    "label_predicted_pca = pca.fit_transform(label_predicted)\n",
    "label_soft_sum_pca = pca.fit_transform(label_soft_sum)\n",
    "label_diff_pca = pca.fit_transform(label_diff)\n",
    "transformed_data = pca.fit_transform(similarities)\n",
    "\n",
    "# Create labels\n",
    "labels = [0, 0, 0, 1, 1, 1, 2, 2, 2]\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(10, 10))\n",
    "\n",
    "# Scatter plots with larger dots\n",
    "dot_size = 50\n",
    "axs[0, 0].scatter(label_accuracies_pca[:, 0], label_accuracies_pca[:, 1], c=labels, s=dot_size)\n",
    "axs[0, 0].set_title('Label Accuracies')\n",
    "axs[0, 1].scatter(label_predicted_pca[:, 0], label_predicted_pca[:, 1], c=labels, s=dot_size)\n",
    "axs[0, 1].set_title('Label Predicted')\n",
    "axs[1, 0].scatter(label_soft_sum_pca[:, 0], label_soft_sum_pca[:, 1], c=labels, s=dot_size)\n",
    "axs[1, 0].set_title('Label Soft Sum')\n",
    "axs[1, 1].scatter(label_diff_pca[:, 0], label_diff_pca[:, 1], c=labels, s=dot_size)\n",
    "axs[1, 1].set_title('Label Soft Diff')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-07T02:44:32.668009Z",
     "iopub.status.idle": "2023-08-07T02:44:32.668316Z",
     "shell.execute_reply": "2023-08-07T02:44:32.668159Z",
     "shell.execute_reply.started": "2023-08-07T02:44:32.668146Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Calculate Silhouette Scores\n",
    "silhouette_accuracies = silhouette_score(label_accuracies_pca, labels)\n",
    "silhouette_predicted = silhouette_score(label_predicted_pca, labels)\n",
    "silhouette_soft_sum = silhouette_score(label_soft_sum_pca, labels)\n",
    "silhouette_diff = silhouette_score(label_diff_pca, labels)\n",
    "silhouette_transformed_data = silhouette_score(transformed_data, labels)\n",
    "\n",
    "print('Silhouette Score for Accuracies:', silhouette_accuracies)\n",
    "print('Silhouette Score for Predicted:', silhouette_predicted)\n",
    "print('Silhouette Score for Soft Sum:', silhouette_soft_sum)\n",
    "print('Silhouette Score for diff:', silhouette_diff)\n",
    "print('Silhouette Score for Model params:', silhouette_transformed_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-07T02:44:32.669312Z",
     "iopub.status.idle": "2023-08-07T02:44:32.669621Z",
     "shell.execute_reply": "2023-08-07T02:44:32.669464Z",
     "shell.execute_reply.started": "2023-08-07T02:44:32.669450Z"
    }
   },
   "outputs": [],
   "source": [
    "#df.sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 Cluster 별 모델 파라미터 분포"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-07T02:44:32.670707Z",
     "iopub.status.idle": "2023-08-07T02:44:32.670905Z",
     "shell.execute_reply": "2023-08-07T02:44:32.670822Z",
     "shell.execute_reply.started": "2023-08-07T02:44:32.670815Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Fit and transform your data to 2D\n",
    "pca = PCA(n_components=2)\n",
    "transformed_data = pca.fit_transform(similarities)\n",
    "\n",
    "# Assign labels based on index ranges\n",
    "labels = [0, 0, 0, 1, 1, 1, 2, 2, 2]\n",
    "unique_labels = np.unique(labels)\n",
    "colors = plt.cm.Spectral(np.linspace(0, 0.35, len(unique_labels)))\n",
    "\n",
    "# Plot the transformed data with labels\n",
    "for label, color in zip(unique_labels, colors):\n",
    "    idx = np.where(labels == label)\n",
    "    plt.scatter(transformed_data[idx, 0], transformed_data[idx, 1], color=color, label=f'Cluster {label}')\n",
    "\n",
    "# Add a legend\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch1.12.1-py3.8-cuda11.3",
   "language": "python",
   "name": "torch1.12.1-py3.8-cuda11.3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "f79394e62bebc70f4ea6374f6a04753660b8235adfdaf8a6dfe67d7c0f65c745"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

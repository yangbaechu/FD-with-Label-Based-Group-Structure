{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-11T02:01:25.341592Z",
     "iopub.status.busy": "2023-09-11T02:01:25.341429Z",
     "iopub.status.idle": "2023-09-11T02:01:26.839103Z",
     "shell.execute_reply": "2023-09-11T02:01:26.838221Z",
     "shell.execute_reply.started": "2023-09-11T02:01:25.341578Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Standard library imports\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "import os\n",
    "from copy import deepcopy\n",
    "import pickle\n",
    "\n",
    "# Third-party libraries imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytz\n",
    "import seaborn as sns\n",
    "import random\n",
    "from itertools import combinations\n",
    "\n",
    "# from IPython.display import clear_output\n",
    "from scipy.spatial import distance\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset, Subset\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Local application/library specific imports\n",
    "from data_utils import (generate_server_idcs, CustomSubset, split_3class_unbalanced, split_contain_multiclass,\n",
    "                        split_7plus3class_unbalanced, CombinedCustomSubset)\n",
    "from fl_devices import Server, Client\n",
    "from helper import ExperimentLogger, display_train_stats\n",
    "from models import ConvNet, Representation, Ten_class_classifier, Four_class_classifier\n",
    "\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-11T02:01:26.840414Z",
     "iopub.status.busy": "2023-09-11T02:01:26.840145Z",
     "iopub.status.idle": "2023-09-11T02:01:26.844402Z",
     "shell.execute_reply": "2023-09-11T02:01:26.843568Z",
     "shell.execute_reply.started": "2023-09-11T02:01:26.840397Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "LOCAL_EPOCHS = 25\n",
    "N_CLIENTS = 6\n",
    "NUMBER_OF_CLUSTER = 3\n",
    "ALPHA = 0.1\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-11T02:01:26.846184Z",
     "iopub.status.busy": "2023-09-11T02:01:26.845752Z",
     "iopub.status.idle": "2023-09-11T02:01:26.914227Z",
     "shell.execute_reply": "2023-09-11T02:01:26.913207Z",
     "shell.execute_reply.started": "2023-09-11T02:01:26.846157Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data = datasets.CIFAR10(root=\"CIFAR10/\", download=True)\n",
    "data = datasets.MNIST(root=\"MNIST/\", download=False)\n",
    "idcs = np.random.permutation(len(data))\n",
    "\n",
    "def cluster(server, clients, number_of_cluster):\n",
    "    label_predicted = pd.DataFrame()\n",
    "    # label_acc = pd.DataFrame()\n",
    "    for i, client in enumerate(clients):\n",
    "        pred = server.check_cluster(client.model)\n",
    "        # print(f'pred: {pred}')\n",
    "        label_predicted = pd.concat([label_predicted, pd.DataFrame(pred, index=[i])])\n",
    "        # label_acc = pd.concat([label_acc, pd.DataFrame(acc, index=[i])])\n",
    "    label_predicted.reset_index(drop=True, inplace=True)\n",
    "    label_predicted.fillna(0, inplace=True)\n",
    "    \n",
    "    print(f'predicted label')\n",
    "    print(label_predicted)\n",
    "\n",
    "    cluster_idcs, number_of_cluster= server.cluster_clients(label_predicted)\n",
    "    return label_predicted, cluster_idcs, number_of_cluster\n",
    "\n",
    "\n",
    "\n",
    "def get_cluster_averages(df, cluster_idcs):\n",
    "    cluster_averages = {}\n",
    "\n",
    "    for i, cluster in enumerate(cluster_idcs):\n",
    "        cluster_data = df.loc[cluster, :]\n",
    "        cluster_average = cluster_data.mean()\n",
    "        cluster_averages[i] = cluster_average\n",
    "\n",
    "    cluster_averages_df = pd.DataFrame(cluster_averages).T\n",
    "\n",
    "    # calculate percentage for each value in a row\n",
    "    cluster_percentages_df = cluster_averages_df.div(cluster_averages_df.sum(axis=1), axis=0).multiply(100)\n",
    "\n",
    "    # apply threshold and rounding\n",
    "    cluster_percentages_df = cluster_percentages_df.where(cluster_percentages_df >= 5, 0).round()\n",
    "\n",
    "    return cluster_percentages_df / 10\n",
    "\n",
    "\n",
    "def get_cluster_weights(cluster_logits, cluster_weight_per_class):\n",
    "    # Step 1: Find the class with the maximum value in each logit in cluster_logits\n",
    "    # Assuming the dimension for classes is the second one\n",
    "    max_classes = [torch.argmax(logit, dim=1) for logit in cluster_logits]\n",
    "    \n",
    "    print(max_classes)\n",
    "    cluster_weights = []\n",
    "    #c luster별로 \n",
    "    for i, iogits in enumerate(cluster_logits):\n",
    "        weights = []\n",
    "        for j, logit in enumerate(logits):\n",
    "            \n",
    "            # print(f'max_classes: {max_classes[i][j]}')\n",
    "            # print(\"Shape of cluster_weight_per_class[{}]: \".format(i), cluster_weight_per_class[i].shape)\n",
    "            weights.append(max_classes[i][j])\n",
    "        print(weights)\n",
    "        cluster_weights.append(weights)\n",
    "\n",
    "def visualize_clusters(label_predicted, real_cluster_distribution):\n",
    "    # Reduce the dimension of the data\n",
    "    pca = PCA(n_components=2)\n",
    "    label_predicted_pca = pca.fit_transform(label_predicted)\n",
    "    \n",
    "    # Define colors for the clusters\n",
    "    colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']\n",
    "\n",
    "    # Calculate the number of samples in each real cluster\n",
    "    n_samples = len(label_predicted)\n",
    "    real_cluster_sizes = [int(n_samples * dist) for dist in real_cluster_distribution]\n",
    "\n",
    "    # Plot the clusters\n",
    "    plt.figure(figsize=(8, 5))\n",
    "\n",
    "    start_idx = 0  # To keep track of the start index of each real cluster\n",
    "    for i, size in enumerate(real_cluster_sizes):\n",
    "        end_idx = start_idx + size  # Calculate the end index for this real cluster\n",
    "        color = colors[i % len(colors)]  # Determine the color for this real cluster\n",
    "\n",
    "        # Scatter plot for points belonging to this real cluster\n",
    "        for j in range(start_idx, end_idx):\n",
    "            plt.scatter(label_predicted_pca[j, 0], label_predicted_pca[j, 1], c=color, s=50, label=f'Group {i+1}' if j == start_idx else \"\")\n",
    "\n",
    "        start_idx = end_idx  # Update the start index for the next real cluster\n",
    "    \n",
    "    # Remove duplicate labels in legend\n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    by_label = dict(zip(labels, handles))\n",
    "    plt.legend(by_label.values(), by_label.keys(), fontsize='xx-large')\n",
    "\n",
    "    # Remove x and y ticks\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    # Save the figure with narrow margins\n",
    "    plt.subplots_adjust(left=0.01, right=0.99, top=0.99, bottom=0.01)\n",
    "    current_time = datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "    plt.savefig(f'Figures/cluster_visualization_{current_time}.png', dpi=300, format='png')\n",
    "\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "#     # Print the real cluster distribution\n",
    "#     print(\"Real cluster distribution:\", real_cluster_distribution)\n",
    "\n",
    "#     # Calculate and print each client's cluster identity based on the real_cluster_distribution\n",
    "#     n_clients = len(label_predicted)\n",
    "#     cumulative_distribution = [0] + [sum(real_cluster_distribution[:i+1]) for i in range(len(real_cluster_distribution))]\n",
    "#     client_cluster_id_real = [next((i for i, val in enumerate(cumulative_distribution) if val > client_idx / n_clients), -1) - 1 for client_idx in range(n_clients)]\n",
    "\n",
    "#     print(\"Real cluster identity for each client:\", client_cluster_id_real)\n",
    "\n",
    "#     # Print each client's cluster identity based on the clusters argument\n",
    "#     client_cluster_id_predicted = [next((i for i, cluster in enumerate(clusters) if client_idx in cluster), -1) for client_idx in range(n_clients)]\n",
    "#     print(\"Predicted cluster identity for each client:\", client_cluster_id_predicted)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def test_acc(server, clients, cluster_distribution):\n",
    "    \n",
    "    # Get individual client accuracies\n",
    "    acc_clients = [client.evaluate() for client in clients]\n",
    "\n",
    "    # Compute the average accuracy for each client\n",
    "    client_acc = round(sum(acc_clients) / len(acc_clients), 3) if len(acc_clients) > 0 else 0\n",
    "\n",
    "    # Compute cluster accuracies for this iteration\n",
    "    cluster_accs_iteration = []\n",
    "    start_idx = 0\n",
    "    for distribution in cluster_distribution:\n",
    "        end_idx = start_idx + int(distribution * len(clients))\n",
    "        cluster_acc = round(sum(acc_clients[start_idx:end_idx]) / (end_idx - start_idx) + 0.000001, 3)\n",
    "        cluster_accs_iteration.append(cluster_acc)\n",
    "        start_idx = end_idx\n",
    "\n",
    "    # Compute global accuracy for this iteration\n",
    "    accuracies = [server.evaluate_distil(client.classifier) for client in clients]\n",
    "    global_acc = round(np.mean(accuracies), 3)\n",
    "    \n",
    "    return client_acc, cluster_accs_iteration, global_acc\n",
    "\n",
    "\n",
    "def get_global_logits(client_logits):\n",
    "    avg_logits = torch.mean(torch.stack(client_logits), dim=0)\n",
    "    return avg_logits\n",
    "\n",
    "# def get_cluster_logits(client_logits, cluster_idcs):\n",
    "#     cluster_logits = []\n",
    "#     for i, cluster in enumerate(cluster_idcs):\n",
    "#         cluster_client_logits = [client_logits[i] for i in cluster]\n",
    "#         avg_cluster_logits = torch.mean(torch.stack(cluster_client_logits), dim=0)\n",
    "#         cluster_logits.append(avg_cluster_logits)\n",
    "#     return cluster_logits\n",
    "\n",
    "\n",
    "def get_cluster_averages(df, cluster_idcs):\n",
    "    cluster_averages = {}\n",
    "\n",
    "    for i, cluster in enumerate(cluster_idcs):\n",
    "        cluster_data = df.loc[cluster, :]\n",
    "        cluster_average = cluster_data.mean()\n",
    "        cluster_averages[i] = cluster_average\n",
    "\n",
    "    cluster_averages_df = pd.DataFrame(cluster_averages).T\n",
    "\n",
    "    # calculate percentage for each value in a row\n",
    "    cluster_percentages_df = cluster_averages_df.div(cluster_averages_df.sum(axis=1), axis=0).multiply(100)\n",
    "\n",
    "    # apply threshold and rounding\n",
    "    cluster_percentages_df = cluster_percentages_df.where(cluster_percentages_df >= 5, 0).round()\n",
    "\n",
    "    return cluster_percentages_df / 10\n",
    "\n",
    "def compute_accuracy(global_logits, data_targets, server_idcs):\n",
    "    \"\"\"\n",
    "    Compute accuracy of predictions based on global logits.\n",
    "\n",
    "    Args:\n",
    "    - global_logits (list of Tensors): Each Tensor represents the logits for a data instance, \n",
    "                                       and its size is the number of classes.\n",
    "    - data_targets (list of ints): List of true labels for all data.\n",
    "    - server_idcs (list of ints): Indices of data instances we're interested in.\n",
    "\n",
    "    Returns:\n",
    "    - accuracy (float): Computed accuracy.\n",
    "    \"\"\"\n",
    "    true_labels = [data_targets[i] for i in server_idcs]\n",
    "    \n",
    "    correct_predictions = 0\n",
    "    total_predictions = len(true_labels)\n",
    "\n",
    "    for logits, label in zip(global_logits, true_labels):\n",
    "        predicted_label = np.argmax(logits.cpu().numpy())  # Convert Tensor to numpy and get index of max value\n",
    "        if predicted_label == label:\n",
    "            correct_predictions += 1\n",
    "\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def save_tensor_to_csv(tensor, filename):\n",
    "    # Convert tensor to numpy array\n",
    "    array = tensor.cpu().detach().numpy()\n",
    "    \n",
    "    # Save numpy array to CSV file\n",
    "    np.savetxt(filename, array, delimiter=\",\")\n",
    "\n",
    "# def get_cluster_weights(cluster_logits, cluster_weight_per_class):\n",
    "#     # Step 1: Find the class with the maximum value in each logit in cluster_logits\n",
    "#     # Assuming the dimension for classes is the second one\n",
    "#     max_classes = [torch.argmax(logit, dim=1) for logit in cluster_logits]\n",
    "    \n",
    "#     print(max_classes)\n",
    "#     cluster_weights = []\n",
    "#     #c luster별로 \n",
    "#     for i, iogits in enumerate(cluster_logits):\n",
    "#         weights = []\n",
    "#         for j, logit in enumerate(logits):\n",
    "            \n",
    "#             # print(f'max_classes: {max_classes[i][j]}')\n",
    "#             # print(\"Shape of cluster_weight_per_class[{}]: \".format(i), cluster_weight_per_class[i].shape)\n",
    "#             weights.append(max_classes[i][j])\n",
    "#         print(weights)\n",
    "#         cluster_weights.append(weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-11T02:01:26.916226Z",
     "iopub.status.busy": "2023-09-11T02:01:26.915513Z",
     "iopub.status.idle": "2023-09-11T02:01:26.928683Z",
     "shell.execute_reply": "2023-09-11T02:01:26.928024Z",
     "shell.execute_reply.started": "2023-09-11T02:01:26.916201Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_global_logit(n_clients, total_client_data, distill_data, number_of_cluster, cluster_distribution, instance_per_class, instances_per_class_per_client):\n",
    "    data_per_class=int(distill_data//10)\n",
    "    train_idcs, test_idcs = idcs[:total_client_data], idcs[total_client_data:(total_client_data + int(distill_data * 2))]\n",
    "    train_labels = data.targets\n",
    "    test_labels = data.targets\n",
    "    server_idcs = generate_server_idcs(test_idcs, test_labels, int(distill_data//10))\n",
    "    print(f'sever idcs: {len(server_idcs)}')\n",
    "    #client_idcs, _ = split_7plus3class_unbalanced(train_idcs, train_labels, n_clients, cluster_distribution, instance_per_class, instance_per_minor_class)\n",
    "    client_idcs = split_contain_multiclass(train_idcs, train_labels, n_clients, instance_per_class, instances_per_class_per_client, cluster_distribution)\n",
    "    \n",
    "    client_data = [CustomSubset(data, idcs) for idcs in client_idcs]\n",
    "    test_data = CustomSubset(data, server_idcs, transforms.Compose([transforms.ToTensor()]))\n",
    "    print(f'test_data: {len(test_data)}')\n",
    "    \n",
    "    for i, client_datum in enumerate(client_data):\n",
    "        client_datum.subset_transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "    server = Server(ConvNet, lambda x : torch.optim.Adam(x),test_data)\n",
    "\n",
    "    clients = [Client(Representation, dat, i) \n",
    "           for i, dat in enumerate(client_data) if len(dat) > 20]\n",
    "    \n",
    "    # print(f'client count: {len(clients)}')\n",
    "\n",
    "    client_logits = []\n",
    "    \n",
    "        \n",
    "    # 1. Train classifier\n",
    "    for i, client in enumerate(clients):\n",
    "        client.classifier = Ten_class_classifier(client.model).to(device)\n",
    "        client.train_classifier(lr=1e-3)\n",
    "\n",
    "    client_acc, cluster_accs, global_acc = test_acc(server, clients, cluster_distribution)\n",
    "    \n",
    "    # 2. get client loigt\n",
    "    for i, client in enumerate(clients):\n",
    "        client_logits.append(server.get_clients_logit(client.classifier))\n",
    "\n",
    "    # 3. make global logit\n",
    "    global_logits = server.get_global_logits(client_logits)\n",
    "    accuracy = compute_accuracy(global_logits, test_labels, server_idcs)\n",
    "    \n",
    "    print(f\"Global Logit's Accuracy: {accuracy * 100:.2f}%\")\n",
    "    \n",
    "    return server, clients, client_logits, global_logits, number_of_cluster, server_idcs, cluster_distribution, client_acc, cluster_accs, global_acc\n",
    "\n",
    "def distill_with_cluster_logit(server, clients, client_logits, global_logits, number_of_cluster, server_idcs, cluster_distribution, t):\n",
    "    cluster_logits,  cluster_idcs, label_predicted = server.get_cluster_logits(client_logits, number_of_cluster, t)\n",
    "    visualize_clusters(label_predicted, cluster_distribution)\n",
    "    silhouette, ari = server.evaluate_clustering(label_predicted, cluster_distribution, cluster_idcs)\n",
    "    \n",
    "    print(f'silhouette: {silhouette}, ari: {ari}')\n",
    "\n",
    "    cluster_distill_loaders = []\n",
    "    \n",
    "    for cluster_logit in cluster_logits:\n",
    "        distill_loader = server.create_distill_loader(data, server_idcs, cluster_logit)\n",
    "        cluster_distill_loaders.append(distill_loader)\n",
    "        \n",
    "    for i, client in enumerate(clients):\n",
    "        if i % 10 == 0:\n",
    "            print(f'client {i} distill')\n",
    "        \n",
    "        cluster_idx = next(j for j, cluster in enumerate(cluster_idcs) if i in cluster)\n",
    "        \n",
    "        client.distill((cluster_distill_loaders[cluster_idx]))\n",
    "    \n",
    "    client_acc, cluster_accs, global_acc = test_acc(server, clients, cluster_distribution)\n",
    "    \n",
    "    return client_acc, cluster_accs, global_acc, silhouette, ari\n",
    "\n",
    "\n",
    "def get_cluster_acc(server, clients, client_logits, global_logits, number_of_cluster, server_idcs, cluster_distribution, t):\n",
    "    cluster_logits,  cluster_idcs, label_predicted = server.get_cluster_logits(client_logits, number_of_cluster, t)\n",
    "    visualize_clusters(label_predicted, cluster_distribution)\n",
    "    silhouette, ari = server.evaluate_clustering(label_predicted, cluster_distribution, cluster_idcs)\n",
    "    \n",
    "    print(f'silhouette: {silhouette}, ari: {ari}')\n",
    "    return silhouette, ari\n",
    "\n",
    "\n",
    "def distill_with_global_logit(server, clients, client_logits, global_logits, number_of_cluster, server_idcs, cluster_distribution):\n",
    "    distill_loader = server.create_distill_loader(data, server_idcs, global_logits)\n",
    "    \n",
    "    for i, client in enumerate(clients):\n",
    "        if i % 10 == 0:\n",
    "            print(f'client {i} distill')\n",
    "        client.distill(distill_loader)\n",
    "    \n",
    "    client_acc, cluster_accs, global_acc = test_acc(server, clients, cluster_distribution)\n",
    "    \n",
    "    return client_acc, cluster_accs, global_acc\n",
    "\n",
    "def copy_classifiers(clients):\n",
    "    classifiers_state = []\n",
    "    for client in clients:\n",
    "        classifier_state = client.classifier.state_dict()\n",
    "        classifiers_state.append(classifier_state)\n",
    "    return classifiers_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-11T02:01:26.930084Z",
     "iopub.status.busy": "2023-09-11T02:01:26.929620Z",
     "iopub.status.idle": "2023-09-11T02:01:26.939460Z",
     "shell.execute_reply": "2023-09-11T02:01:26.938968Z",
     "shell.execute_reply.started": "2023-09-11T02:01:26.930065Z"
    }
   },
   "outputs": [],
   "source": [
    "def cluster_train_result_exp(n_clients, total_client_data, distill_data, number_of_cluster, cluster_distribution, instance_per_class, instances_per_class_per_client, t):\n",
    "   \n",
    "    client_accs = []\n",
    "    cluster_accs = []\n",
    "    global_accs = []\n",
    "    \n",
    "    (\n",
    "        server, clients, client_logits, global_logits,\n",
    "        number_of_cluster, server_idcs, cluster_distribution,\n",
    "        new_client_acc, new_cluster_accs, new_global_acc\n",
    "    ) = make_global_logit(\n",
    "        n_clients, total_client_data, distill_data,\n",
    "        number_of_cluster, cluster_distribution,\n",
    "        instance_per_class, instances_per_class_per_client\n",
    "    )\n",
    "\n",
    "    \n",
    "    print(f'acc before distill: {new_client_acc}, {new_cluster_accs}, {new_global_acc}')\n",
    "    client_accs.append(new_client_acc)\n",
    "    cluster_accs.append(new_cluster_accs)\n",
    "    global_accs.append(new_global_acc)\n",
    "\n",
    "    classifiers_state = copy_classifiers(clients)\n",
    "    \n",
    "    new_client_acc, new_cluster_accs, new_global_acc, silhouette, ari = distill_with_cluster_logit(server, clients, client_logits, global_logits, number_of_cluster, server_idcs, cluster_distribution, t)\n",
    "    \n",
    "    \n",
    "    for i, client in enumerate(clients):\n",
    "        client.classifier.load_state_dict(classifiers_state[i])\n",
    "    \n",
    "    client_accs.append(new_client_acc)\n",
    "    cluster_accs.append(new_cluster_accs)\n",
    "    global_accs.append(new_global_acc)\n",
    "    \n",
    "    new_client_acc, new_cluster_accs, new_global_acc = distill_with_global_logit(server, clients, client_logits, global_logits, number_of_cluster, server_idcs, cluster_distribution)\n",
    "   \n",
    "    \n",
    "    client_accs.append(new_client_acc)\n",
    "    cluster_accs.append(new_cluster_accs)\n",
    "    global_accs.append(new_global_acc)\n",
    "    \n",
    "    print(f'acc after global distill: {client_accs[1]}, {cluster_accs[1]}, {global_accs[1]}')\n",
    "    print(f'acc after cluster distill: {client_accs[-1]}, {cluster_accs[-1]}, {global_accs[-1]}')\n",
    "    return client_accs, cluster_accs, global_accs, silhouette, ari\n",
    "\n",
    "def clustering_exp(n_clients, total_client_data, distill_data, number_of_cluster, cluster_distribution, instance_per_class, instance_per_minor_class, instances_per_class_per_client, t):\n",
    "   \n",
    "    client_accs = []\n",
    "    cluster_accs = []\n",
    "    global_accs = []\n",
    "    \n",
    "    (\n",
    "        server, clients, client_logits, global_logits,\n",
    "        number_of_cluster, server_idcs, cluster_distribution,\n",
    "        new_client_acc, new_cluster_accs, new_global_acc\n",
    "    ) = make_global_logit(\n",
    "        n_clients, total_client_data, distill_data,\n",
    "        number_of_cluster, cluster_distribution,\n",
    "        instance_per_class, instance_per_minor_class, instances_per_class_per_client\n",
    "    )\n",
    "\n",
    "    \n",
    "    print(f'acc before distill: {new_client_acc}, {new_cluster_accs}, {new_global_acc}')\n",
    "    client_accs.append(new_client_acc)\n",
    "    cluster_accs.append(new_cluster_accs)\n",
    "    global_accs.append(new_global_acc)\n",
    "\n",
    "    classifiers_state = copy_classifiers(clients)\n",
    "    \n",
    "    sil, ari = get_cluster_acc(server, clients, client_logits, global_logits, number_of_cluster, server_idcs, cluster_distribution, t)\n",
    "    return sil, ari\n",
    "\n",
    "\n",
    "def get_combination(array_length, class_per_cluster):\n",
    "    if class_per_cluster == 1:\n",
    "        combinations = [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9]]\n",
    "    elif class_per_cluster == 2:\n",
    "        combinations = [[0,1], [2,3], [4,5], [6,7], [8,9], [0,5], [1,6], [2,7], [3,8], [4,9], [0,3], [1,4], [2,5], [6,8], [7,9], [0,4], [1,5], [2,9], [3,7], [8,6]]\n",
    "    elif class_per_cluster == 3:\n",
    "        combinations = [[0,1,2], [3,4,5], [6,7,8], [9,0,1], [2,3,4], [5,6,7], [8,9,0], [1,2,3], [4,5,6], [7,8,9]]\n",
    "    elif class_per_cluster == 4:\n",
    "        combinations = [[0,1,2,3],[4,5,6,7],[8,9,0,1],[2,3,4,5],[6,7,8,9],[2,4,6,8],[1,3,5,9],[0,3,6,9],[1,4,7,0],[2,5,8,1]]\n",
    "    elif class_per_cluster == 5:\n",
    "        combinations = [[0,1,2,3,4],[4,5,6,7,8],[8,9,0,1,2],[2,3,4,5,6],[6,7,8,9,0],[2,4,6,8,0],[1,3,5,7,9],[0,2,3,6,9],[1,4,6,7,0],[2,5,6,8,1]]\n",
    "    else:\n",
    "        return \"Invalid class_per_cluster\"\n",
    "    \n",
    "    return combinations[:array_length]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-11T02:01:26.940225Z",
     "iopub.status.busy": "2023-09-11T02:01:26.940092Z",
     "iopub.status.idle": "2023-09-11T02:01:26.945237Z",
     "shell.execute_reply": "2023-09-11T02:01:26.944743Z",
     "shell.execute_reply.started": "2023-09-11T02:01:26.940214Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def model_clustering_exp(n_clients, total_client_data, distill_data, number_of_cluster, cluster_distribution, instance_per_class, instances_per_class_per_client):\n",
    "    print(f'number_of_cluster: {number_of_cluster}')\n",
    "    data_per_class=int(distill_data//10)\n",
    "    train_idcs, test_idcs = idcs[:total_client_data], idcs[total_client_data:(total_client_data + int(distill_data * 2))]\n",
    "    train_labels = data.targets\n",
    "    test_labels = data.targets\n",
    "    \n",
    "    server_idcs = generate_server_idcs(test_idcs, test_labels, int(distill_data//10))\n",
    "\n",
    "    # client_idcs = split_noniid(train_idcs, train_labels, alpha=alpha, n_clients=N_CLIENTS)\n",
    "    client_idcs = split_contain_multiclass(train_idcs, train_labels, n_clients, instance_per_class, instances_per_class_per_client)\n",
    "    \n",
    "    client_data = [CustomSubset(data, idcs) for idcs in client_idcs]\n",
    "    test_data = CustomSubset(data, server_idcs, transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "    for i, client_datum in enumerate(client_data):\n",
    "        client_datum.subset_transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "    server = Server(Representation, lambda x : torch.optim.Adam(x),test_data)\n",
    "\n",
    "    clients = [Client(Representation, dat, i) for i, dat in enumerate(client_data) if len(dat) > 20]\n",
    "    \n",
    "\n",
    "    # 1. Train classifier\n",
    "    for i, client in enumerate(clients):\n",
    "        client.train_classifier(lr=1e-3)\n",
    "\n",
    "    similarities = server.compute_pairwise_similarities(clients)\n",
    "    # print('similarities')\n",
    "    # print(type(similarities))\n",
    "    # print(similarities)\n",
    "    cluster_idcs = server.cluster_clients_KMeans(similarities, number_of_cluster)\n",
    "    \n",
    "    visualize_clusters(similarities, cluster_distribution)\n",
    "    silhouette, ari = server.evaluate_clustering(similarities, cluster_distribution, cluster_idcs)\n",
    "    print(f'silhouette: {silhouette}, ari: {ari}')\n",
    "    return silhouette, ari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-11T02:02:20.755299Z",
     "iopub.status.busy": "2023-09-11T02:02:20.754776Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sever idcs: 4000\n",
      "num_groups: 3\n",
      "[0.3333333333333333, 0.3333333333333333, 0.3333333333333333]\n",
      "test_data: 4000\n",
      "32\n",
      "Global Logit's Accuracy: 64.12%\n",
      "acc before distill: 0.914, [0.954, 0.88, 0.909], 0.32\n",
      "S_normalized\n",
      "[[0.9638424  0.30479452 0.5640255  0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.45763627 0.48159248 0.76117164 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.3448462  0.60102737 0.73488545 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.61953586 0.46875    0.6597822  0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.6292499  0.2958048  0.8047315  0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.47760388 1.         0.29252723 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.6475985  0.39554796 0.70446867 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.45925525 0.36130136 0.8655651  0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.84727466 0.31378424 0.6372512  0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.4430653  0.32063356 0.9125047  0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.76416624 0.27311644 0.7307548  0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.80733943 0.45333904 0.5426211  0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.53750676 0.36344177 0.8092377  0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.4662709  0.36515412 0.8573038  0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.4786832  0.19263698 1.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.77549917 0.40796232 0.6045813  0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.55801404 0.3364726  0.8186256  0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [1.         0.39212328 0.4622606  0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.5747436  0.40710616 0.7450244  0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.5369671  0.26755136 0.89372885 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.7585353  0.73945075 0.73755413\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.7110341  0.7809779  0.75595236\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.8134586  0.9243134  0.5281385\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.893617   0.76758206 0.5670996\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.8668975  0.82585394 0.54924244\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.49381492 0.91761553 0.8831169\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.71845615 0.76624244 0.75974023\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.7318159  0.66979235 0.8230519\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.896091   0.7006028  0.6185065\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.4275111  0.86269253 1.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.6541316  0.95981246 0.6737013\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.8000989  0.8412592  0.6098485\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.8208807  0.75619555 0.65584415\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.66600686 0.7937039  0.7949134\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.99999994 0.58004016 0.60227275\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.5383473  0.82719356 0.90746754\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.72587824 0.79236436 0.7305195\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.55368626 1.         0.75108224\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.93369615 0.79437375 0.5016234\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.8520534  0.7689216  0.61147183\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.7748977  0.9230769  0.7274283  0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  1.         0.6431404  0.73727    0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.7680764  0.7089611  0.84724003 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.79058665 0.48770815 0.9525032  0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.7933152  0.69865185 0.83697045 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.57435197 0.7961935  0.92169446 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.79126877 0.5519429  0.9174155  0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.59276944 0.6566217  0.9854514  0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.5886767  0.66534495 0.98331195 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.6589359  0.8176051  0.8570817  0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.72100955 0.7192704  0.8712024  0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.7257845  0.49801743 0.9875909  0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.7169168  0.666138   0.902439   0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.7469304  0.71847737 0.8553701  0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.9024557  0.8675654  0.6773641  0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.59276944 1.         0.80017114 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.7469304  0.5487708  0.9469405  0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.6582537  0.55352896 1.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.9311051  0.88659793 0.6491228  0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.87994546 0.35844567 0.96619594 0.        ]]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAygAAAICCAYAAAAktOkVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/P9b71AAAACXBIWXMAAA9hAAAPYQGoP6dpAAA4AUlEQVR4nO3de3RUVZ728eecyqUScuGeiOESHA0GHTDTjqggqA2CtC1eQBlYeLdpdNrWVpllA++aDrS2aLc4go4iCIKib8uoDCKggkArNBrnZbg2QrhDAibkoqmkUue8f1SnTEggFyrUTvL9rFWL5Jx99v5VVi3Nk3322Zbruq4AAAAAwAB2pAsAAAAAgCoEFAAAAADGIKAAAAAAMAYBBQAAAIAxCCgAAAAAjEFAAQAAAGAMAgoAAAAAY0Q19ULHcXTkyBElJibKsqxw1gQAAACglXFdVyUlJerWrZts+/TzJE0OKEeOHFH37t2bejkAAACANujgwYNKS0s77fkmB5TExMTQAElJSU3tBgAAAEAbUFxcrO7du4dyxOk0OaBU3daVlJREQAEAAADQIPUtD2GRPAAAAABjEFAAAAAAGIOAAgAAAMAYBBQAAAAAxiCgAAAAADAGAQUAAACAMQgoAAAAAIxBQAEAAABgjCZv1AgAAIDGc11Xfr9fjuNEuhSg0WzbVnR0dL2bLZ4NAgoAAMA5EAgEdOLECZWUlMjv90e6HKDJoqOjlZiYqM6dO8vj8YS9fwIKAABAMwsEAjp48KDKy8uVnJyshIQEeTyeZv0rNBBurusqEAiotLRUJ0+eVFlZmbp37x72kEJAAQAAaGYnTpxQeXm5evToobi4uEiXA5yVhIQEJScn68CBAzpx4oRSUlLC2j+L5AEAAJqR67oqKSlRcnIy4QStRlxcnJKSklRSUiLXdcPaNwEFAM7EXyaV5gf/BYAm8Pv98vv9SkhIiHQpQFglJiaGPt/hxC1eAFCX/V9KX86Wdi2XXEeybCljpHTVw1KPAZGuDkALUvW0ruZYTAxEUtVnOtxPpGMGBQBOtXmuNH+E9LcVwXAiBf/92wpp3nBp8+uRrQ9Ai8SCeLQ2zfWZJqAAQHX7v5SWPy7JlZzKmuecyuDx5b+RDmyMRHUAALR6BBQAqO7L2ZJd320YVrAdAAAIOwIKAFTxlwXXnJw6c1KLI+34kIXzAAA0AwIKAFQpL/lxzUlDbPrP5qsFAIA2ioACAFViE4NP62qov8xqvloAAGijCCgAUCU6TvqHoQ1vX1Yg/VDQfPUAAGrw+Xx67bXXdNtttyk9PV0JCQmKjY1VamqqrrvuOk2dOlVbtmyJdJnGOXTokBYvXqxf//rXuvrqq9WuXTtZlqXU1NRIl1Yn9kEBgOoyRkq7Vza8fcE+Kb5js5UDAAhatmyZHnzwQR07dix0zOv1ql27djp+/LjWrFmjNWvWaPr06Ro2bJgWL16szp07R7Biczz33HOaNavlzPozgwIA1XW6oHHt/T80Tx0AgJDXX39do0aN0rFjx5SRkaF58+bpyJEjKisrU0FBgSoqKvT1118rOztb3bp106pVq3To0KFIl20My7J0wQUX6I477tBzzz2nxx57LNIlnREzKABQXcG+xrX/9lMpfWCzlAIAkHJycjRp0iQ5jqObb75ZS5YskdfrrdHG4/EoKytLWVlZevLJJ5Wdna3o6OgIVWye5557Tn/6059C37/xxhuRK6YBmEEBgOq+/65x7f+2onnqAIAw8/kDOl5SLp8/EOlSGmXKlCmqqKhQz549tWjRolrh5FQxMTHKzs5W3759axxfu3atLMtSr169JEkrVqzQiBEj1LVrV9m2rRdeeKFG+6VLl2r48OHq0qWLYmNjlZaWpnHjxiknJ6fOcU/tvy5vvPGGLMvSkCFDap2zLEuWZWnfvn3aunWr7rzzTqWmpsrr9apPnz7Kzs5WeXn5Gd/76Xg89e3vZRZmUACguqRGLhg8viO4H0p0XPPUAwBnafO+As1dv1ert+fJcSXbkoZmpuiBQb31k15mr6E7ePCgVqwI/iHokUceUUJCQlj6ff755/X444/LsiwlJyfLtn/8m73jOLrnnnu0cOFCScFf7hMTE3X48GG99dZbWrJkiV566SX98pe/DEstp/riiy/04IMP6vvvv1dSUpJc19WuXbs0bdo0ffTRR1q9enXYfg6mYgYFAKpLH9T4a8pLwl8HAITBmxv3a8wrX+qTHfly3OAxx5U+2ZGv0a98qUUb90e2wHp8/vnnoa9HjhwZlj7z8vI0efJkTZo0SUePHlVhYaFKS0t1++23S5KeffZZLVy4UJZlKTs7W4WFhSosLNShQ4c0evRoOY6jhx9+WOvWrQtLPaeaNGmSMjMztWXLFhUVFamkpETz589XXFycNm7caPz6kXAgoABAdcndJFmNu8ZmMhqAeTbvK9C097fKlRSoSid/F3BcuZKmvr9VX+0z93HpO3bskBR8WteFF14Ylj59Pp/GjBmj2bNnKyUlJdR/WlqaSktL9fTTT0uSJk+erClTpigxMVGSdP755+vtt9/WwIED5TiOpkyZEpZ6ThUbG6uPP/5Yl156qaTgLWt333235syZIyn4wIADBw40y9imIKAAwKn6j29c+9z1zVMHAJyFuev3yrbP/AcX27Y0d0PuOaqo8QoKguGpffv2sqy638uMGTOUmppa6/XII4+ctt8nnniizuOrV69WcXGxYmJi9OSTT9Y67/F4NHXqVEnS+vXrazzyOFwmTpyojh1r33o3YcIEpaWlyXEcLV26NOzjmoSAAgCnuvpXjWv/1fzmqQMAmsjnD2j19rxaMyenCjiuVm071uIWzldXUlKivLy8Wq+ioqI628fFxalfv351nqtaAN+vXz916NChzjbXXHNNaNH56RbMn426FtBLkm3bGjRoULONaxICCgDUcub/odeSuya4UB4ADFHiq1Q92STEcYPtTVQ1k3Dy5Em5bt1v6JlnnpHruqHXuHHjzthnp06daiyKr+748eOSgrdznY7X6w1tAFnVPpzONHbVueYY1yQEFAA4VVQTnsjFQnkABkn0Rqmeu7tCbCvY3kQXX3yxpOC6kd27d4elz4Y8ctfn84VlLDQNAQUATpXQpXHtLVuKTWyeWgCgCbzRHg3NTJGnnpTisS0N65sqb7SZ+2QMHjw49PXy5cubfbwuXYL//T/TInSfz6fvvvuuRntJioqKCp0/ndPddlbdkSNH6j1XfdzWiIACAKeKjpN6XNXw9n1+xj4oAIxz/6Decuq5z8txXN0/MP0cVdR43bt314gRIyRJs2bNUmlpabOOl5WVJUnavXu3Dh8+XGebdevWqbKyskZ7KbiQX5Ly8/NVUVFR57WbN2+ut4bqj1auznXd0KONq4/bGhFQAKAu109reNsrH2q+OgCgiS7v1VHZoy6RJdWaSfHYlixJ2aMuMX6zxunTpysmJkb79+/X+PHjm/X2q2HDhikpKUl+v18zZ86sdT4QCCg7O1uSNGjQIKWm/ri570UXXaTY2Fi5rqtly5bVuvbbb7/Ve++9V28NL7/8sk6ePFnr+KJFi3To0CHZtq1bb721Ee+q5SGgAEBdel4pjfxj/e1G/lHqMaD56wGAJhg/oKf+78QrNTQzJbQmpWon+f878UqNH9AzsgU2QFZWlubMmSPbtvXBBx+of//+mjdvno4ePRpq47qu9uzZo5kzZ2rlypVNHqtdu3Z66qmnJEkvvviiZsyYEZq1OXz4sMaOHasNGzbItm1Nnz69xrUxMTG6+eabJUmPPvqoNmzYIMdx5DiOVq1apaFDhyourv7Zdp/Pp+HDh2vr1q2SJL/frwULFmjixImSpPvuu089evRo1Pvy+/06ceJE6FX1nlzXrXG8sLCwUf02G7eJioqKXEluUVFRU7sAAPPt/9J1541w3f+TVPM178bgOQCoR1lZmbt9+3a3rKwssnVUVLr5xT63rKIyonU01Ycffuimpqa6Cj5q0ZXker1et3Pnzm5sbGyN4yNGjHB37txZ4/o1a9a4ktyePXuecZzKykp3woQJob48Ho/boUMH17IsV5Jr27Y7e/bsOq/ds2eP26lTp9C18fHxrtfrdSW5/fv3d2fNmuVKcgcPHlzr2qprFi9e7MbHx7uS3OTkZDcmJiZ0bsCAAW5JSUmjf3ZV772+V30/m1M19rPd0Pxg5iMbAMAUPQZI93wUfIxw6d8f65jQhTUnAFocb7TH2MXwDXHTTTdp7969WrRokVasWKGcnBwdP35cxcXF6tixozIyMnT11Vdr3LhxyszMbPI4Ho9HCxYs0M9//nO9+uqr+vrrr1VcXKzzzjtPgwcP1m9+8xv90z/9U53X9u7dW5s2bdLUqVP1ySefqLi4WN27d9cdd9yhp556Su+++26941911VXatGmTsrOztXbtWvl8PmVkZGjcuHF68sknFRsb2+T31lJYrnuah0rXo7i4WMnJySoqKlJSUlK46wIAAGgVfD6fcnNzlZ6eLq/XG+lyYCjLCt6Dl5ubq169ekW2mAZq7Ge7ofmBNSgAAAAAjEFAAQAAAGAMAgoAAAAAYxBQAAAAABiDp3gBAAAAEdbE51a1SsygAAAAADAGAQUAAACAMQgoAAAAAIxBQAEAAABgDAIKAAAAAGMQUAAAAAAYg4ACAAAAwBgEFAAAAADGIKAAAAAAMAYBBQAAAIAxCCgAAAAAjEFAAQAAAGAMAgoAAABaBJ/Pp9dee0233Xab0tPTlZCQoNjYWKWmpuq6667T1KlTtWXLlkiXaZyvv/5a06ZN05AhQ9S1a1dFR0erY8eOGjRokF588UX5fL5Il1iD5bqu25QLi4uLlZycrKKiIiUlJYW7LgAAgFbB5/MpNzdX6enp8nq9kS6nxVq2bJkefPBBHTt2LHTM6/UqLi5ORUVFchwndHzYsGFavHixOnfuHIlSjbJ48WKNHz8+9L1t20pKStLJkydDxzIzM7Vq1Sqdf/75jeq7sZ/thuYHZlAAAABgtNdff12jRo3SsWPHlJGRoXnz5unIkSMqKytTQUGBKioq9PXXXys7O1vdunXTqlWrdOjQoUiXbQS/36/4+Hg98MAD+uyzz/TDDz+osLBQxcXF+o//+A+1a9dO27dv12233aYmzluEXVSkCwAAAABOJycnR5MmTZLjOLr55pu1ZMmSWn+t93g8ysrKUlZWlp588kllZ2crOjo6QhWb5aqrrtLevXuVkpJS43hiYqIefvhhJSYm6u6779amTZu0bt06DR48OEKV/ogZFAAAgLbAXyaV5gf/bUGmTJmiiooK9ezZU4sWLar3VqKYmBhlZ2erb9++NY6vXbtWlmWpV69ekqQVK1ZoxIgR6tq1q2zb1gsvvFCj/dKlSzV8+HB16dJFsbGxSktL07hx45STk1PnuKf2X5c33nhDlmVpyJAhtc5ZliXLsrRv3z5t3bpVd955p1JTU+X1etWnTx9lZ2ervLz8jO+9LhdddFGtcFLdv/zLvygmJkZScK2KCQgoAAAArdn+L6Ul46Xfd5OeuzD475Lx0oGNka6sXgcPHtSKFSskSY888ogSEhLC0u/zzz+vG2+8UStXrpTf75dt//grseM4uuuuu3Tbbbdp5cqVKiwsVHx8vA4fPqy33npLl19+uV5++eWw1FGXL774QgMGDNA777yjsrIyua6rXbt2hRa5l5aWhnW86OhoJSYmSpICgUBY+24qAgoAAEBrtXmuNH+E9LcVkvv3ReSuE/x+3nBp8+uRra8en3/+eejrkSNHhqXPvLw8TZ48WZMmTdLRo0dVWFio0tJS3X777ZKkZ599VgsXLpRlWcrOzlZhYaEKCwt16NAhjR49Wo7j6OGHH9a6devCUs+pJk2apMzMTG3ZskVFRUUqKSnR/PnzFRcXp40bN+qxxx4L63jbtm3Td999J0m65JJLwtp3UxFQAAAAWqP9X0rLH5fkSk5lzXNOZfD48t8YPZOyY8cOScGndV144YVh6dPn82nMmDGaPXt26NYnr9ertLQ0lZaW6umnn5YkTZ48WVOmTAnNLpx//vl6++23NXDgQDmOoylTpoSlnlPFxsbq448/1qWXXiopeMva3XffrTlz5kgKPjDgwIEDYRuv6n306NFD119/fdj6PRsEFAAAgNboy9mS7TlzG9sTbGeogoICSVL79u1lWVadbWbMmKHU1NRar0ceeeS0/T7xxBN1Hl+9erWKi4sVExOjJ598stZ5j8ejqVOnSpLWr19f45HH4TJx4kR17Nix1vEJEyYoLS1NjuNo6dKlYRnrtdde0/vvvy9J+tOf/hRaixJpBBQAAIDWxl8m7Vpee+bkVE6ltPO/W9zC+epKSkqUl5dX61VUVFRn+7i4OPXr16/Oc1UL4Pv166cOHTrU2eaaa66Rx+Op0T6c6lpALwX3Lxk0aFDYxv3888/1r//6r5Kkhx56SLfeeutZ9xkuBBQAAIDWprzkxzUn9XGdYHsDVc0knDx58rR7dDzzzDNyXTf0Gjdu3Bn77NSpU41F8dUdP35cks64YaHX6w1tAFnVPpzONHbVubMd96uvvtLPf/5zlZeX65ZbbtGsWbPOqr9wI6AAAAC0NrGJktXAX/MsO9jeQBdffLGk4LqR3bt3h6XPqtmPM/H5fGEZy0RbtmzRDTfcoOLiYg0bNkxLlixp0M/kXCKgAAAAtDbRcVLGSMmuZ09uO0rq87NgewNV3zRw+fLlzT5ely5dJOmMi9B9Pl/oqVdV7SUpKioqdP50TnfbWXVHjhyp91z1cRtj586dGjp0qAoKCjRo0CD913/9lzHrTqojoAAAALRGVz4kOfXsa+EEgu0M1b17d40YMUKSNGvWrLDvAXKqrKwsSdLu3bt1+PDhOtusW7dOlZWVNdpLwYX8kpSfn6+Kioo6r928eXO9NVR/tHJ1ruuGHm1cfdyG2rNnj66//nrl5+fr8ssv1/LlyxUfH9/ofs4FAgoAAEBr1PNKaeTzkqzaMyl2VPD4yOelHgMiUV2DTZ8+XTExMdq/f7/Gjx/frLdfDRs2TElJSfL7/Zo5c2at84FAQNnZ2ZKkQYMGKTU1NXTuoosuUmxsrFzX1bJly2pd++233+q9996rt4aXX35ZJ0+erHV80aJFOnTokGzbbvSC9oMHD+r666/XkSNH1K9fP61cuTL0+GQTEVAAAABaq8vvk+79WMq48cc1KZYd/P7ej4PnDZeVlaU5c+bItm198MEH6t+/v+bNm6ejR4+G2riuqz179mjmzJlauXJlk8dq166dnnrqKUnSiy++qBkzZoRmbQ4fPqyxY8dqw4YNsm1b06dPr3FtTEyMbr75ZknSo48+qg0bNshxHDmOo1WrVmno0KGKi6v/Vjqfz6fhw4dr69atkiS/368FCxZo4sSJkqT77rtPPXr0aPB7ys/P109/+lPt379fmZmZWr169WmfUGYMt4mKiopcSW5RUVFTuwAAAGj1ysrK3O3bt7tlZWWRLaTiB9ctyQv+2wJ9+OGHbmpqqisp9PJ6vW7nzp3d2NjYGsdHjBjh7ty5s8b1a9ascSW5PXv2POM4lZWV7oQJE0J9eTwet0OHDq5lWa4k17Ztd/bs2XVeu2fPHrdTp06ha+Pj412v1+tKcvv37+/OmjXLleQOHjy41rVV1yxevNiNj493JbnJycluTExM6NyAAQPckpKSRv3c/v3f/z10fVJSkpuSknLa169+9atG9d3Yz3ZD8wMzKAAAAG1BdJyU0NXYBfH1uemmm7R37169+uqruuWWW9SzZ0/Ztq3i4mJ16NBBgwcP1lNPPaVt27bpo48+UkZGRpPG8Xg8WrBggf785z9r2LBhat++vUpLS3Xeeedp7Nix+utf/6pJkybVeW3v3r21adMmjR07Vl26dFEgEFBaWpp++9vf6i9/+YuSkpLqHf+qq67Spk2bNGbMGMXGxsqyLGVkZOh3v/ud1q5dq4SEhEa9H8f58XHTxcXFde4ZU9/eMeea5bqneah0PYqLi5WcnKyioqIG/bABAADaIp/Pp9zcXKWnp8vr9Ua6HBjKsixJUm5urnr16hXZYhqosZ/thuYHZlAAAAAAGIOAAgAAAMAYBBQAAAAAxiCgAAAAADBGVP1NAAAAADSnJj63qlViBgUAAACAMQgoAAAAAIxBQAEAAABgDAIKAAAAAGMQUAAAAAAYg4ACAAAAwBgEFAAAAADGIKAAAAAAMAYBBQAAAIAxCCgAAAAAjEFAAQAAAGAMAgoAAAAAY0RFugAAAACgIXw+n9588019/PHHysnJ0fHjx+X3+9WhQwdlZmbq6quv1ujRo/WP//iPkS7VKB988IHWrFmjr776SgcPHtTx48clSeeff76uueYaPfTQQ8rKyopwlT+yXNd1m3JhcXGxkpOTVVRUpKSkpHDXBQAA0Cr4fD7l5uYqPT1dXq830uW0WMuWLdODDz6oY8eOhY55vV7FxcWpqKhIjuOEjg8bNkyLFy9W586dI1Gqcfr06aNdu3aFvm/fvr1KS0tVWVkpSbJtW3/4wx/0+OOPN6rfxn62G5ofuMULAAAARnv99dc1atQoHTt2TBkZGZo3b56OHDmisrIyFRQUqKKiQl9//bWys7PVrVs3rVq1SocOHYp02ca44447NG/ePP3tb39TeXm5CgsLVV5erm+++UYjR46U4zh64okntH79+kiXKokZFAAAgGbFDMrZycnJ0ZVXXqmKigrdfPPNWrJkyRl/jhUVFcrOztadd96pvn37nsNKW6aKigpdfPHF2rt3r+699169/vrrDb6WGRQAAAA0ma/SpxNlJ+Sr9EW6lEaZMmWKKioq1LNnTy1atKjeX4RjYmKUnZ1dK5ysXbtWlmWpV69ekqQVK1ZoxIgR6tq1q2zb1gsvvFCj/dKlSzV8+HB16dJFsbGxSktL07hx45STk1PnuKf2X5c33nhDlmVpyJAhtc5ZliXLsrRv3z5t3bpVd955p1JTU+X1etWnTx9lZ2ervLz8jO+9KWJiYtSvXz9J0pEjR8Lef1OwSB4AAKAVy8nL0cLtC7Xm4Bo5riPbsnVt92t1V9+7dFnXyyJd3hkdPHhQK1askCQ98sgjSkhICEu/zz//vB5//HFZlqXk5GTZ9o9/s3ccR/fcc48WLlwoSfJ4PEpMTNThw4f11ltvacmSJXrppZf0y1/+Miy1nOqLL77Qgw8+qO+//15JSUlyXVe7du3StGnT9NFHH2n16tVh+zlIwVmQb775RpKUnp4etn7PBjMoAAAArdQ7O9/R3R/frbUH18pxg4vIHdfR2oNrddeKu/TurncjWl99Pv/889DXI0eODEufeXl5mjx5siZNmqSjR4+qsLBQpaWluv322yVJzz77rBYuXCjLspSdna3CwkIVFhbq0KFDGj16tBzH0cMPP6x169aFpZ5TTZo0SZmZmdqyZYuKiopUUlKi+fPnKy4uThs3btRjjz0WlnEKCgq0du1a/exnP9O+ffvk8Xg0ceLEsPR9tggoAAAArVBOXo5mbJohV64CbqDGuYAbkCtX0zdO1zf530Sowvrt2LFDUvBpXRdeeGFY+vT5fBozZoxmz56tlJSUUP9paWkqLS3V008/LUmaPHmypkyZosTEREnBR/K+/fbbGjhwoBzH0ZQpU8JSz6liY2P18ccf69JLL5UUvAXr7rvv1pw5cyQFHxhw4MCBJvW9aNGi0K1knTp10rXXXqtPP/1UXbt21QcffGDM45kJKAAAAK3Qwu0LZVtn/lXPtmwt3LbwHFXUeAUFBZKCj8W1LKvONjNmzFBqamqt1yOPPHLafp944ok6j69evVrFxcWKiYnRk08+Weu8x+PR1KlTJUnr16+v8cjjcJk4caI6duxY6/iECROUlpYmx3G0dOnSJvUdFxenlJSU0LobSerUqZP++Mc/6oYbbjirusOJgAIAANDK+Cp9WnNwTa2Zk1MF3IA+O/hZi1s4X11JSYny8vJqvYqKiupsHxcXF1oUfqqqBfD9+vVThw4d6mxzzTXXyOPx1GgfTnUtoJeCe5UMGjTorMa97bbbdOzYMeXl5emHH37Q+vXrdfHFF2v8+PEaNmzYaX9m5xoBBQAAoJUp9ZeG1pzUx3EdlfpLm7mipqmaSTh58qROtzPGM888I9d1Q69x48adsc9OnTrVWBRfXfUd1k/H6/WGNoCsah9OZxq76lw4xo2NjdXAgQO1Zs0aXXHFFVqzZo2mTZt21v2GAwEFAACglUmITqj39q4qtmUrITp8T4UKp4svvlhScN3I7t27w9Jn1ezHmfh8LXdGqbGioqJCi+PnzZsX4WqCCCgAAACtjDfKq2u7XyuPdeZfxj2WR9d1v07eKDM3kBw8eHDo6+XLlzf7eF26dJGkMy5C9/l8+u6772q0l4K/6FedP52G3EJ1pr1Iqs5VHzccqmZmSktLlZ+fH9a+m4KAAgAA0ApNyJxQ721ejutoQt8J56iixuvevbtGjBghSZo1a5ZKS5v3VrSsrCxJ0u7du3X48OE626xbt06VlZU12kvBhfySlJ+fr4qKijqv3bx5c701VH+0cnWu64YebVx93HDIzc0NfR3OPVaaioACAADQCmWlZGnKgCmyZNWaSfFYHlmyNGXAFOM3a5w+fbpiYmK0f/9+jR8/vllvvxo2bJiSkpLk9/s1c+bMWucDgYCys7MlSYMGDVJqamro3EUXXaTY2Fi5rqtly5bVuvbbb7/Ve++9V28NL7/8sk6ePFnr+KJFi3To0CHZtq1bb721we+pKkydTllZmV566SVJweATHx/f4L6bCwEFAACglRqTMUYLRizQtd2vDa1JqdpJfsGIBRqTMSbCFdYvKytLc+bMkW3b+uCDD9S/f3/NmzdPR48eDbVxXVd79uzRzJkztXLlyiaP1a5dOz311FOSpBdffFEzZswIzdocPnxYY8eO1YYNG2TbtqZPn17j2piYGN18882SpEcffVQbNmyQ4zhyHEerVq3S0KFDFRcXV28NPp9Pw4cP19atWyVJfr9fCxYsCK0Tue+++9SjR48Gv6fFixfrlltu0X//93+rsLAwdLy8vFyrV6/W4MGD9b//+7+SZMwieblNVFRU5Epyi4qKmtoFAABAq1dWVuZu377dLSsri2wd/jL3+A/H3TJ/ZOtoqg8//NBNTU11JYVeXq/X7dy5sxsbG1vj+IgRI9ydO3fWuH7NmjWuJLdnz55nHKeystKdMGFCqC+Px+N26NDBtSzLleTatu3Onj27zmv37NnjdurUKXRtfHy86/V6XUlu//793VmzZrmS3MGDB9e6tuqaxYsXu/Hx8a4kNzk52Y2JiQmdGzBggFtSUtKon9v8+fNr/GwSExPdTp06uR6PJ3QsNjbWfemllxrVr+s2/rPd0PzADAoAAEAb4I3yqnNcZ2MXxNfnpptu0t69e/Xqq6/qlltuUc+ePWXbtoqLi9WhQwcNHjxYTz31lLZt26aPPvpIGRkZTRrH4/FowYIF+vOf/6xhw4apffv2Ki0t1XnnnaexY8fqr3/9qyZNmlTntb1799amTZs0duxYdenSRYFAQGlpafrtb3+rv/zlL0pKSqp3/KuuukqbNm3SmDFjFBsbK8uylJGRod/97ndau3Zto9eIjBw5Uq+88opGjx6tPn36KCoqSkVFRUpKStI///M/69/+7d+0fft2PfTQQ43qtzlZrnuah0rXo7i4WMnJyaE3CAAAgNp8Pp9yc3OVnp4ur7dlhgM0P8uyJAUXrPfq1SuyxTRQYz/bDc0PzKAAAAAAMAYBBQAAAIAxCCgAAAAAjEFAAQAAAGCMqEgXAAAAALR1TXxuVavEDAoAAAAAYxBQAAAAABiDgAIAAADAGAQUAACAc4A1BmhtmuszTUABAABoRlFRwWcSlZeXR7gSILyqPtNVn/FwIaAAAAA0o6ioKLVr104FBQUKBAKRLgcIi0AgoIKCArVr1y7sAYXHDAMAADSzzp076+DBg8rNzVVycrLi4uLk8XhkWVakSwMazHVdBQIBlZWVqaioSI7j6Lzzzgv7OAQUAACAZhYfH6/09HTl5+ersLBQJ06ciHRJQJN5PB7Fx8era9euiomJCXv/BBQAAIBzICYmRmlpaXJdV36/X47jRLokoNFs21Z0dHSzzv4RUAAAAM4hy7Ka5a/OQGvBInkAAAAAxiCgAAAAADAGAQUAAACAMQgoAAAAAIxBQAEAAABgDAIKAAAAAGMQUAAAAAAYg4ACAAAAwBgEFAAAAADGIKAAAAAAMAYBBQAAAIAxCCgAAAAAjEFAAQAAAGAMAgoAAAAAYxBQAAAAABiDgAIAAADAGAQUAAAAAMYgoAAAAAAwBgEFAAAAgDEIKAAAAACMQUABAAAAYAwCCgAAAABjEFAAAAAAGIOAAgAAAMAYBBQAAAAAxiCgAAAAADAGAQUAAACAMQgoAAAAAIxBQAEAAABgDAIKAAAAAGMQUAAAAAAYg4ACAAAAwBgEFAAAAADGIKAAAAAAMAYBBQAAAIAxCCgAAAAAjEFAAQAAAGAMAgoAAAAAYxBQAAAAABiDgAIAAADAGAQUAAAAAMYgoAAAAAAwBgEFAAAAgDEIKAAAAACMQUABAAAAYAwCCgAAAABjEFAAAAAAGIOAAgAAAMAYBBQAAAAAxiCgAAAAADAGAQUAAACAMQgoAAAAAIxBQAEAAABgDAIKAAAAAGMQUAAAAAAYg4ACAAAAwBgEFAAAAADGIKAAAAAAMAYBBQAAAIAxCCgAAAAAjEFAAQAAAGAMAgoAAAAAYxBQAAAAABiDgAIAAADAGAQUAAAAAMYgoAAAAAAwBgEFAAAAgDEIKAAAAACMQUABAAAAYAwCCgAAAABjEFAAAAAAGIOAAgAAAMAYBBQAAAAAxiCgAAAAADAGAQUAAACAMQgoAAAAAIxBQAEAAABgDAIKAAAAAGMQUAAAAAAYg4ACAAAAwBgEFAAAAADGIKAAAAAAMAYBBQAAAIAxCCgAAAAAjEFAAQAAAGAMAgoAAAAAYxBQAAAAABiDgAIAAADAGAQUAAAAAMYgoAAAAAAwBgEFAAAAgDEIKAAAAACMQUABAAAAYAwCCgAAAABjEFAAAAAAGIOAAgAAAMAYBBQAAAAAxiCgAAAAADAGAQUAAACAMQgoAAAAAIxBQAEAAABgDAIKAAAAAGMQUAAAAAAYg4ACAAAAwBgEFAAAAADGIKAAAAAAMAYBBQAAAIAxCCgAAAAAjEFAAQAAAGAMAgoAAAAAYxBQAAAAABiDgAIAAADAGAQUAAAAAMYgoAAAAAAwBgEFAAAAgDEIKAAAAACMQUABAAAAYAwCCgAAAABjEFAAAAAAGIOAAgAAAMAYBBQAAAAAxiCgAAAAADAGAQUAAACAMQgoAAAAAIxBQAEAAABgDAIKAAAAAGMQUAAAAAAYg4ACAAAAwBgEFAAAAADGIKAAAAAAMAYBBQAAAIAxCCgAAAAAjEFAAQAAAGAMAgoAAAAAYxBQAAAAABiDgAIAAADAGAQUAAAAAMYgoAAAAAAwBgEFAAAAgDEIKAAAAACMQUABAAAAYAwCCgAAAABjEFAAAAAAGIOAAgAAAMAYBBQAAAAAxiCgAAAAADAGAQUAAACAMQgoAAAAAIxBQAEAAABgDAIKAAAAAGMQUAAAAAAYg4ACAAAAwBgEFAAAAADGIKAAAAAAMAYBBQAAAIAxCCgAAAAAjEFAAQAAAGAMAgoAAAAAYxBQAAAAABiDgAIAAADAGAQUAAAAAMYgoAAAAAAwBgEFAAAAgDEIKAAAAACMQUABAAAAYAwCCgAAAABjEFAAAAAAGIOAAgAAAMAYBBQAAAAAxiCgAAAAADAGAQUAAACAMQgoAAAAAIxBQAEAAABgDAIKAAAAAGMQUAAAAAAYg4ACAAAAwBgEFAAAAADGIKAAAAAAMAYBBQAAAIAxCCgAAAAAjEFAAQAAAGAMAgoAAAAAYxBQAAAAABiDgAIAAADAGAQUAAAAAMYgoAAAAAAwBgEFAAAAgDEIKAAAAACMQUABAAAAYAwCCgAAAABjEFAAAAAAGIOAAgAAAMAYBBQAAAAAxiCgAAAAADAGAQUAAACAMQgoAAAAAIxBQAEAAABgDAIKAAAAAGMQUAAAAAAYg4ACAAAAwBgEFAAAAADGIKAAAAAAMAYBBQAAAIAxCCgAAAAAjEFAAQAAAGAMAgoAAAAAYxBQAAAAABiDgAIAAADAGAQUAAAAAMYgoAAAAAAwBgEFAAAAgDEIKAAAAACMQUABAAAAYAwCCgAAAABjEFAAAAAAGIOAAgAAAMAYBBQAAAAAxiCgAAAAADAGAQUAAACAMQgoAAAAAIxBQAEAAABgDAIKAAAAAGMQUAAAAAAYg4ACAAAAwBgEFAAAAADGIKAAAAAAMAYBBQAAAIAxCCgAAAAAjEFAAQAAAGAMAgoAAAAAYxBQAAAAABiDgAIAAADAGAQUAAAAAMYgoAAAAAAwBgEFAAAAgDEIKAAAAACMQUABAAAAYAwCCgAAACDJV+nTibIT8lX6Il1KmxYV6QIAAACASMrJy9HC7Qu15uAaOa4j27J1bfdrNTZjrC7ocIESohPkjfJGusw2g4ACAACANuudne9oxqYZsi1bjutIkhzX0WcHPtOnBz6VpFBguavvXbqs62WRLLdN4BYvAAAAtEk5eTmasWmGXLkKuIEa51y5oa8d19Hag2t114q79O6ud7kVrJlZruu69Terrbi4WMnJySoqKlJSUlK46wIAAACa1a/X/FprD66tFU7qY8mSK7fWzIqv0qdSfym3hJ1GQ/MDt3gBAACgzfFV+kJrThqranalambl0wOfKqNDhnaf3C3HdWTJ0tXnX627+96tK867IsyVt37c4gUAAIA2p9Rf2qRwcqqq2ZddhbtC/blyteHwBt2/6n7d/uHt+ib/m7Mepy0hoAAAAKDNSYhOkG01/6/Cuwp3acKKCXp317vNPlZrQUABAABAm+ON8ura7tfKY3nOyXjTN06vNZPiq/Rp78m92np8q076Tp6TOloC1qAAAACgTZqQOUGfHfjsnIxlW7YWbluoy7peppy8HP1+4++16+SuGm2SopN076X3atzF49r0Inue4gUAAIA2691d72r6xumyLbvRT/NqLNuy9cRPntAfNv+h3rbX97i+1e270tD8QEABAABAm/ZN/jdauG2hPjv4WVgWzoeDJUuSNPmfJ2tI2hBJUqe4Ti16ZoWAAgAAADRC1T4me07u0ZKdS0KBpWrfExNc1uUy3XvpvRpw3oAWF1YIKAAAAMBZqL7x4od7PjyrW8E8liest5BZsnRdj+s0ts9YXdD+AkVZUap0K43eJJKAAgAAAITRqbeC2Zati9pfpJ2FOyNdWg1XdrtS911yn3GbRBJQAAAAgGZQfWbFG+XVN/nf6Pcbf19nUPFYHjmuo8mXT9YfNv/hnN4qlhKfol/2+6Wu73G92nvbn7NxT4eAAgAAAJxDm45s0sLtC7Xh8AY5Cs6wXNf9Ok3oO0GXdb1Mv17za3164NOI1NY+pr0eznpYd2TcEZHxJQIKAAAAEBGnzrBUycnL0V0f3xXByqQb02/UH66p/zHHzaGh+YGd5AEAAIAw8kZ51Tmuc63F6lkpWZo6YGqEqgr6KPcjvbPrnYjWUB8CCgAAAHCOjMkYo4UjFiolPiViNfzn//vPiI3dEAQUAAAA4By6rOtl+mT0J5o7dK6uPO/K0KaM58rxsuM66Tt5TsdsjKhIFwAAAAC0RVd0u0JXdLsitGalai+Tlbkr9czmZ5p17PyyfCOe7FUXAgoAAAAQQd4ob431KuMyxymzc6ZezHlRX+V91Sxjdo3r2iz9hgMBBQAAADDMZV0v0/zh8+Wr9Om7su+09butWr53uT4/9Lkc1zmrvrvEdTF29kQioAAAAADG8kZ5dX7i+To/8Xzd0OuG0O1gewr3aMmuJfr0wKeN3vzxF/1+0UzVhgcBBQAAAGghqm4H6xzXObR+ZePRjXr9f1/X/xz/n3qvvzH9xohu1tgQBBQAAACghfJGeTWk+xAN6T5Evkqf1h1apzn/M0d7ivbUaGfCTvINxU7yAAAAQCvjq/TpSOkRfV/5vbondDdizUlD8wMzKAAAAEAr443yqnf73pEuo0nYqBEAAACAMQgoAAAAAIxBQAEAAABgDAIKAAAAAGMQUAAAAAAYg4ACAAAAwBgEFAAAAADGIKAAAAAAMAYBBQAAAIAxCCgIG58/oOMl5fL5A5EuBQAAAC1UVKQLQMu3eV+B5q7fq9Xb8+S4km1JQzNT9MCg3vpJr46RLg8AAAAtCDMoOCtvbtyvMa98qU925Mtxg8ccV/pkR75Gv/KlFm3cH9kCAQAA0KIQUNBkm/cVaNr7W+VKClSlk78LOK5cSVPf36qv9hVEpD4AAAC0PAQUNNnc9Xtl29YZ29i2pbkbcs9RRQAAAGjpCChoEp8/oNXb82rNnJwq4Lhate0YC+cBAADQIAQUNEmJr1L1ZJMQxw22BwAAAOpDQEGTJHqjVM/dXSG2FWwPAAAA1IeAgibxRns0NDNFnnpSise2NKxvqrzRnnNUGQAAAFoyAgqa7P5BveXUc5+X47i6f2D6OaoIAAAALR0BBU12ea+Oyh51iSyp1kyKx7ZkScoedQmbNQIAAKDBWBiAszJ+QE/1SU3U3A25WrXtWI2d5O8fmE44AQAAQKMQUHDWftKro37Sq6N8/oBKfJVK9Eax5gQAAABNQkBB2HijPQQTAAAAnBXWoAAAAAAwBgEFAAAAgDEIKAAAAACMQUABAAAAYAwCCgAAAABjEFAAAAAAGIOA0gr4/AEdLymXzx+IdCkAAADAWWEflBZs874CzV2/V6u359XYwf2BQb3ZwR0AAAAtEjMoLdSbG/drzCtf6pMd+XLc4DHHlT7Zka/Rr3ypRRv3R7ZAAAAAoAkIKC3Q5n0Fmvb+VrmSAlXp5O8CjitX0tT3t+qrfQURqQ8AAABoKgJKC1F9ncnc9Xtl29YZ29u2pbkbcs9RdQAAAEB4sAbFcKeuM7EkufVeFZxJWbXtmHz+gLzRnuYuEwAAAAgLAorB3ty4X9Pe3yrbtkLrTBoSTqo4rlTiqySgAAAAoMXgFi9DnWmdSUPZlpToJYMCAACg5eC3V4P4/AGV+CqV6I0KrTNpajjx2JaGZqYwewIAAIAWhYBigM37CvSfn+/Rpzvy5arh60zOxHFc3T8wPQzVAQAAAOcOASXCpi/frrnraz5t62zCice25DiuskddwmaNAAAAaHEIKBFQdSvX7DW79cYXZ7+hom2pxk7y9w9MJ5wAAACgRSKgnEOn3sp1tqrWmbxwR//Q2hXWnAAAAKAlI6CcI3XdynW2qtaZeKM9BBMAAAC0CgSUc+DfP9ym+V/sC1t/rDMBAABAa0VAaUYbvj2u51bu0v8cLDrrvlhnAgAAgLaAgNIMNu8r0LQPtmnH0eKw9Dc0M0X/MfYy1pkAAACg1SOghNmbG/dr6vtbw9rnL67pzToTAAAAtAl2pAtoTdbszA97OHlgELdyAQAAoO1gBiUMXt+wVy+v3aMTpRVh7feBQen67cjMsPYJAAAAmIyAchY27yvQv771jY4V+8LWp21JP704RQ9e05uZEwAAALQ5BJQmCvdak3uu6qlJ117IIngAAAC0aQSURvD5AyrxVWpXXrGmhTGccCsXAAAAEERAaYA1O/M1d/1efbHnO7lh7PfyXh00eXgfbuUCAAAA/o6AcgYLv9ynmR/vVEl5IOx9/5+bMnXP1elh7xcAAABoyQgodfD5A/rV299o1fa8sPed2S1Jv/t5X2ZNAAAAgDoQUKrZvK9Ar36+R6t35Ie972v7dNEDA3vrqn/oHPa+AQAAgNaCgPJ305dv19z1uc3S97SfXax7B/Zulr4BAACA1oSd5NW84eTn/boRTgAAAIAGarMzKD5/QMdLyrXl0MlmCSeJ3ihNviFD46/sFfa+AQAAgNaqzQWUzfsKNPPjnfrrvsKw921JuuofOumBgb01pE/XsPcPAAAAtHZtKqCEe/d3KRhKFt9/hS5MSWQXeAAAAOAstZmAsnlfQdjDiSRlj7qEJ3MBAAAAYdJmAsrc9XvD2l9qklcv/ctl7GcCAAAAhFGbCCg+f0CrtoVn08XOCTGaNOQCnswFAAAANIM2EVBKfJVyz7KP27LO19SfZap9fExYagIAAABQW5sIKIneKFlSk0PKA4PS9duRmeEsCQAAAEAdWkVA8fkDKvFVnvYpWt5oj4b1TdHKRtzmZUn6aWaKfnFNb9aZAAAAAOdIiw4om/cVaO76vVq9PU+OK9mWNDQzRQ8Mqh0q7h/Uu8EBZe6En2jghZ15ZDAAAABwjtmRLqCp3ty4X2Ne+VKf7MiX8/d7txxX+mRHvka/8qUWbdxfo/3lvTpq+qhL6u13+qhL9NPMFMIJAAAAEAEtMqBs3legae9vlSsp4NRcWRJwXLmSpr6/VV/tK6hxbvyAnvrzxCt1RXrtW7auSO+oP0+8UuMH9GzGygEAAACcSYu8xWvu+r2ybatWOKnOti3N3ZBb61avn/TqqHd+caV8/oCOl5TLsqTOCbHMmAAAAAAGaHEBxecPhNacnEnAcbVq2zH5/IHTLpzv3jG+maoEAAAA0BQt7havEl9lveGkiuMG2wMAAABoGVpcQEn0Rsm2GtbWtoLtAQAAALQMLS6geKM9GpqZIk89KcVjWxrWN5W1JQAAAEAL0uICihTc08Sp5z4vx3F1/8D0c1QRAAAAgHBokQHl8l4dlT3qEllSrZkUj23JkpQ96hJ2gAcAAABamBa7QGP8gJ7qk5qouRtytWrbsRo7yd8/MJ1wAgAAALRALTagSME9TX7Sq6N8/oBKfJVK9Eax5gQAAABowVp0QKnijfYQTAAAAIBWoEWuQQEAAADQOhFQAAAAABiDgAIAAADAGAQUAAAAAMYgoAAAAAAwBgEFAAAAgDEIKAAAAACMQUABAAAAYAwCCgAAAABjEFAAAAAAGIOAAgAAAMAYBBQAAAAAxiCgAAAAADBGVFMvdF1XklRcXBy2YgAAAAC0TlW5oSpHnE6TA0pJSYkkqXv37k3tAgAAAEAbU1JSouTk5NOet9z6IsxpOI6jI0eOKDExUZZlNblAAAAAAK2f67oqKSlRt27dZNunX2nS5IACAAAAAOHGInkAAAAAxiCgAAAAADAGAQUAAACAMQgoAAAAAIxBQAEAAABgDAIKAAAAAGMQUAAAAAAYg4ACAAAAwBgEFAAAAADGIKAAAAAAMAYBBQAAAIAxCCgAAAAAjPH/AbwojppKsE3EAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "silhouette: 0.82566899061203, ari: 0.9495627013875189\n",
      "client 0 distill\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Initialize empty DataFrame to store results with simplified columns\n",
    "minor_class_ratios = [5, 10, 20, 30, 40]\n",
    "cluster_distribution = [1/3, 1/3, 1/3]\n",
    "clustering_acc = pd.DataFrame(columns=['silhouette', 'ari'], index=minor_class_ratios)\n",
    "client_acc = pd.DataFrame(columns=['before_distill', 'global_distill', 'cluster_distill'], index=minor_class_ratios)\n",
    "cluster_acc = pd.DataFrame(columns=['before_distill', 'global_distill', 'cluster_distill'], index=minor_class_ratios)\n",
    "\n",
    "cluster_count = 3\n",
    "t = 2\n",
    "\n",
    "instance_per_classes = [158, 150, 133, 117, 100, 84]\n",
    "instance_per_minor_classes = [4, 7, 14, 21, 29, 36]\n",
    "\n",
    "\n",
    "# Iterate over different minor_class_ratios, instance_per_classes, and instance_per_minor_classes values\n",
    "for minor_class_ratio, instance_per_class, instance_per_minor_class in zip(minor_class_ratios, instance_per_classes, instance_per_minor_classes):\n",
    "    n_clients = cluster_count * 20\n",
    "    instances_per_class_per_client = get_combination(cluster_count, 3)\n",
    "    \n",
    "    # Replace with your actual clustering_exp function\n",
    "    # Assume it accepts t as a parameter\n",
    "    client_accs, cluster_accs, global_accs, silhouette, ari = cluster_train_result_exp(\n",
    "            n_clients, 40000, 4000, cluster_count, cluster_distribution, 50, instances_per_class_per_client, t\n",
    "    )\n",
    "    \n",
    "    # Update DataFrame\n",
    "    clustering_acc.loc[minor_class_ratio, 'silhouette'] = silhouette\n",
    "    clustering_acc.loc[minor_class_ratio, 'ari'] = ari\n",
    "    \n",
    "    client_acc.loc[minor_class_ratio, 'before_distill'] = client_accs[0]\n",
    "    client_acc.loc[minor_class_ratio, 'cluster_distill'] = client_accs[1]\n",
    "    client_acc.loc[minor_class_ratio, 'global_distill'] = client_accs[2]\n",
    "    \n",
    "    client_acc.loc[minor_class_ratio, 'before_distill'] = cluster_accs[0]\n",
    "    client_acc.loc[minor_class_ratio, 'cluster_distill'] = cluster_accs[1]\n",
    "    client_acc.loc[minor_class_ratio, 'global_distill'] = cluster_accs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clustering_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cluster_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-09-11T02:01:26.959592Z",
     "iopub.status.idle": "2023-09-11T02:01:26.960154Z",
     "shell.execute_reply": "2023-09-11T02:01:26.959952Z",
     "shell.execute_reply.started": "2023-09-11T02:01:26.959930Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_mean = df_client_accs.mean()\n",
    "df_mean = df_mean.reset_index()\n",
    "df_mean.columns = ['class_per_cluster', 'Metric', 'Value']\n",
    "\n",
    "# Pivot the table so Metrics become columns\n",
    "df_pivot = df_mean.pivot(index='class_per_cluster', columns='Metric', values='Value')\n",
    "\n",
    "# Create a new feature\n",
    "df_pivot['cluster_global_diff'] = df_pivot['cluster_distill'] - df_pivot['global_distill']\n",
    "\n",
    "# Reset the index for the final DataFrame\n",
    "df_pivot.reset_index(inplace=True)\n",
    "df_pivot_filtered = df_pivot.iloc[1:]\n",
    "\n",
    "plt.bar(df_pivot_filtered['class_per_cluster'], df_pivot_filtered['cluster_global_diff'])\n",
    "plt.xlabel('Class Per Cluster')\n",
    "plt.ylabel('Cluster Global Difference')\n",
    "plt.title('Bar Graph of Cluster Global Difference by Class Per Cluster')\n",
    "xticks = np.arange(min(df_pivot_filtered['class_per_cluster']), max(df_pivot_filtered['class_per_cluster']) + 1)\n",
    "xticks = [tick for tick in xticks if tick >= 0]  # Remove negative numbers, if any\n",
    "plt.xticks(xticks)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-09-11T02:01:26.960950Z",
     "iopub.status.idle": "2023-09-11T02:01:26.961281Z",
     "shell.execute_reply": "2023-09-11T02:01:26.961128Z",
     "shell.execute_reply.started": "2023-09-11T02:01:26.961111Z"
    }
   },
   "outputs": [],
   "source": [
    "df_global_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-09-11T02:01:26.962362Z",
     "iopub.status.idle": "2023-09-11T02:01:26.962796Z",
     "shell.execute_reply": "2023-09-11T02:01:26.962601Z",
     "shell.execute_reply.started": "2023-09-11T02:01:26.962578Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Global_TC_experiments(total_client_data, distill_data, alpha, number_of_cluster, cluster_distribution):\n",
    "    print(f'number_of_cluster: {number_of_cluster}')\n",
    "    data_per_class=int(distill_data//10)\n",
    "    train_idcs, test_idcs = idcs[:total_client_data], idcs[total_client_data:(total_client_data + int(distill_data * 2))]\n",
    "    train_labels = data.targets\n",
    "    test_labels = data.targets\n",
    "    \n",
    "    server_idcs = generate_server_idcs(test_idcs, test_labels, int(distill_data//10))\n",
    "\n",
    "    # client_idcs = split_noniid(train_idcs, train_labels, alpha=alpha, n_clients=N_CLIENTS)\n",
    "    client_idcs, major_class_per_client = split_7plus3class_unbalanced(train_idcs, train_labels, N_CLIENTS, cluster_distribution, data_per_class_3, data_per_class_7)\n",
    "    \n",
    "    client_data = [CustomSubset(data, idcs) for idcs in client_idcs]\n",
    "    test_data = CustomSubset(data, server_idcs, transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "    for i, client_datum in enumerate(client_data):\n",
    "        client_datum.subset_transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "    server = Server(ConvNet, lambda x : torch.optim.Adam(x),test_data)\n",
    "\n",
    "    clients = [Client(Representation, dat, major_class_per_client[i], i) \n",
    "           for i, dat in enumerate(client_data) if len(dat) > 20]\n",
    "    \n",
    "    print(f'client count: {len(clients)}')\n",
    "\n",
    "    client_accs = []\n",
    "    cluster_accs = []\n",
    "    global_accs = []\n",
    "    client_logits = []\n",
    "    \n",
    "    # # 0. Representational Learning\n",
    "    # for i, client in enumerate(clients):\n",
    "    #     Total_data = CustomSubset(data, np.concatenate((server_idcs, client_idcs[i])), transforms.Compose([transforms.ToTensor()]))\n",
    "    #     # print(f'data used to trian representation: {len(Total_data)}')\n",
    "    #     client.learn_representation(Total_data)\n",
    "        \n",
    "    # 1. Train classifier\n",
    "    for i, client in enumerate(clients):\n",
    "        client.classifier = Ten_class_classifier(client.model).to(device)\n",
    "        client.train_classifier(lr=1e-3)\n",
    "\n",
    "    client_accs, cluster_accs, global_accs = test_acc(server, clients, client_accs, cluster_accs, global_accs, cluster_distribution)\n",
    "    print(f'client_acc: {client_accs[-1]}, cluster_acc: {cluster_distribution}: {cluster_accs[-1]},  global_acc: {global_accs[-1]}')\n",
    "    \n",
    "    # 2. get cluster loigt\n",
    "    for i, client in enumerate(clients):\n",
    "        client_logits.append(server.get_clients_logit(client.classifier))\n",
    "    \n",
    "\n",
    "    # 3. make global logit\n",
    "    global_logits = server.get_global_logits(client_logits)\n",
    "    accuracy = compute_accuracy(global_logits, test_labels, server_idcs)\n",
    "    \n",
    "    print(f\"Global Logit's Accuracy: {accuracy * 100:.2f}%\") \n",
    "    \n",
    "    \n",
    "     # 4. Distillation\n",
    "    distill_loader = server.create_distill_loader(data, server_idcs, global_logits)\n",
    "    \n",
    "    for i, client in enumerate(clients):\n",
    "        if i % 10 == 0:\n",
    "            print(f'client {i} distill')\n",
    "        client.distill(distill_loader)\n",
    "    \n",
    "    client_accs, cluster_accs, global_accs = test_acc(server, clients, client_accs, cluster_accs, global_accs, cluster_distribution)\n",
    "    \n",
    "    print(f'total_client_data: {total_client_data}, cluster_distribution: {cluster_distribution}')\n",
    "    print(f'acc before distill: {client_accs[-2]}, {cluster_accs[-2]}, {global_accs[-2]}')\n",
    "    print(f'last acc: {client_accs[-1]}, {cluster_accs[-1]}, {global_accs[-1]}')\n",
    "    return client_accs, cluster_accs, global_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-09-11T02:01:26.964846Z",
     "iopub.status.idle": "2023-09-11T02:01:26.965655Z",
     "shell.execute_reply": "2023-09-11T02:01:26.965378Z",
     "shell.execute_reply.started": "2023-09-11T02:01:26.965353Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TC_experiments(50000, 5000, 1, 3, [1/3, 1/3, 1/3], 117, 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-09-11T02:01:26.966713Z",
     "iopub.status.idle": "2023-09-11T02:01:26.967000Z",
     "shell.execute_reply": "2023-09-11T02:01:26.966868Z",
     "shell.execute_reply.started": "2023-09-11T02:01:26.966854Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "clustering_by_model_experiments(50000, 5000, 1, 3, [1/3, 1/3, 1/3], 100, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-09-11T02:01:26.967903Z",
     "iopub.status.idle": "2023-09-11T02:01:26.968173Z",
     "shell.execute_reply": "2023-09-11T02:01:26.968047Z",
     "shell.execute_reply.started": "2023-09-11T02:01:26.968034Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "now = datetime.datetime.now(pytz.timezone('Asia/Seoul'))\n",
    "date_time = now.strftime(\"%m%d_%H%M\")\n",
    "\n",
    "columns = pd.MultiIndex.from_product([['client_accs', 'cluster_accs', 'global_accs'], ['before_distill', 'after_distill']],\n",
    "                                     names=['acc_type', 'distill_state'])\n",
    "\n",
    "desired_pairs = [(50000, 5000)]\n",
    "cluster_distribution = [1/3, 1/3, 1/3]\n",
    "experiments = ['cluster_distill', 'sim', 'global_distill']\n",
    "index = pd.MultiIndex.from_product([experiments, desired_pairs], names=['experiment', 'data_pair'])\n",
    "\n",
    "df = pd.DataFrame(index=index, columns=columns)\n",
    "runs = 2  # number of times each experiment should be run\n",
    "\n",
    "for exp in experiments:\n",
    "    for pair in desired_pairs:\n",
    "        total_client_accs = [0, 0]\n",
    "        total_cluster_accs = [0, 0]\n",
    "        total_global_accs = [0, 0]\n",
    "\n",
    "        for _ in range(runs):\n",
    "            client_data, distill_data = pair\n",
    "\n",
    "            if exp == 'sim':\n",
    "                client_accs, cluster_accs, global_accs = SimCLR_distill_experiments(client_data, distill_data, ALPHA, NUMBER_OF_CLUSTER, cluster_distribution)\n",
    "            elif exp == 'global_distill':\n",
    "                client_accs, cluster_accs, global_accs = global_distill_experiments(client_data, distill_data, ALPHA, NUMBER_OF_CLUSTER, cluster_distribution)\n",
    "            else:\n",
    "                client_accs, cluster_accs, global_accs = four_class_classification_experiments(client_data, distill_data, ALPHA, NUMBER_OF_CLUSTER, cluster_distribution)\n",
    "\n",
    "            total_client_accs = [x+y for x, y in zip(total_client_accs, [client_accs[-2], client_accs[-1]])]\n",
    "            total_cluster_accs = [x+y for x, y in zip(total_cluster_accs, [cluster_accs[-2], cluster_accs[-1]])]\n",
    "            total_global_accs = [x+y for x, y in zip(total_global_accs, [global_accs[-2], global_accs[-1]])]\n",
    "\n",
    "        avg_client_accs = [x/runs for x in total_client_accs]\n",
    "        avg_cluster_accs = [x/runs for x in total_cluster_accs]\n",
    "        avg_global_accs = [x/runs for x in total_global_accs]\n",
    "\n",
    "        df.loc[(exp, pair), ('client_accs', 'before_distill')] = avg_client_accs[0]\n",
    "        df.loc[(exp, pair), ('client_accs', 'after_distill')] = avg_client_accs[1]\n",
    "        df.loc[(exp, pair), ('global_accs', 'before_distill')] = avg_global_accs[0]\n",
    "        df.loc[(exp, pair), ('global_accs', 'after_distill')] = avg_global_accs[1]\n",
    "        df.loc[(exp, pair), ('cluster_accs', 'before_distill')] = avg_cluster_accs[0]\n",
    "        df.loc[(exp, pair), ('cluster_accs', 'after_distill')] = avg_cluster_accs[1]\n",
    "\n",
    "directory = f'results/SimCLR'\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "cluster_distribution_str = \"_\".join(map(str, cluster_distribution))\n",
    "file_name = f'{directory}/client:{N_CLIENTS}_cluster:{NUMBER_OF_CLUSTER}_distribution:{cluster_distribution_str}_{date_time}.csv'\n",
    "df = df.round(decimals=3)\n",
    "df.to_csv(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-09-11T02:01:26.969044Z",
     "iopub.status.idle": "2023-09-11T02:01:26.969313Z",
     "shell.execute_reply": "2023-09-11T02:01:26.969188Z",
     "shell.execute_reply.started": "2023-09-11T02:01:26.969175Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('results/global_distill/CIFAR_0720_0435.csv', index_col=[0,1], header=[0,1])\n",
    "\n",
    "# 그릴 데이터와 제목을 리스트로 저장\n",
    "heatmap_data = [('client_accs', 'change_after_distill', 'Client Accuracy change after Distillation'),\n",
    "                ('global_accs', 'change_after_distill', 'Global Accuracy change after Distillation')]\n",
    "\n",
    "# Compute change in accuracy\n",
    "df[('client_accs', 'change_after_distill')] = df[('client_accs', 'after_distill')] - df[('client_accs', 'before_distill')]\n",
    "df[('global_accs', 'change_after_distill')] = df[('global_accs', 'after_distill')] - df[('global_accs', 'before_distill')]\n",
    "\n",
    "# 전체 데이터의 최솟값, 최댓값 계산\n",
    "vmin = min(df[data1][data2].min() for data1, data2, _ in heatmap_data)\n",
    "vmax = max(df[data1][data2].max() for data1, data2, _ in heatmap_data)\n",
    "\n",
    "for data1, data2, title in heatmap_data:\n",
    "    plt.figure(figsize=(9, 5))\n",
    "    sns.heatmap(df[(data1, data2)].unstack(), annot=True, cmap='coolwarm', center=0, vmin=-0.1, vmax=0.2)\n",
    "    plt.title(title)\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch1.12.1-py3.8-cuda11.3",
   "language": "python",
   "name": "torch1.12.1-py3.8-cuda11.3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "f79394e62bebc70f4ea6374f6a04753660b8235adfdaf8a6dfe67d7c0f65c745"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

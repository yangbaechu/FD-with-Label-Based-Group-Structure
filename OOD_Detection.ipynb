{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2de69f4-fdc7-4ea9-9c9b-128506d599a8",
   "metadata": {},
   "source": [
    "## 1. Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0f876a-d2f5-4bfb-b6bf-30ed28602acf",
   "metadata": {},
   "source": [
    "### 1) Prepare dataset & NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5eb5fff2-46d5-4f60-91ed-d28e957edf35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-11T06:24:43.844290Z",
     "iopub.status.busy": "2023-08-11T06:24:43.844164Z",
     "iopub.status.idle": "2023-08-11T06:24:45.603296Z",
     "shell.execute_reply": "2023-08-11T06:24:45.601993Z",
     "shell.execute_reply.started": "2023-08-11T06:24:43.844277Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import ConcatDataset\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Transform for MNIST\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Load MNIST dataset\n",
    "trainset = MNIST(root='./MNIST', train=True, download=False, transform=transform)\n",
    "testset = MNIST(root='./MNIST', train=False, download=False, transform=transform)\n",
    "\n",
    "major_class_num = 420\n",
    "minor_class_num = 90\n",
    "images = []\n",
    "targets = []\n",
    "\n",
    "for i in range(10):\n",
    "    class_indices = np.where(np.array(trainset.targets) == i)[0]\n",
    "    num_samples = major_class_num if i < 3 else minor_class_num\n",
    "    selected_indices = class_indices[:num_samples]\n",
    "    \n",
    "    for idx in selected_indices:\n",
    "        images.append(trainset[idx][0])\n",
    "        targets.append(1 if i < 3 else 0)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "images = torch.stack(images)\n",
    "targets = torch.tensor(targets, dtype=torch.float32)\n",
    "\n",
    "# Create a TensorDataset with the selected instances and modified labels\n",
    "subset = TensorDataset(images, targets.view(-1, 1))\n",
    "\n",
    "trainloader = DataLoader(subset, batch_size=64, shuffle=True)\n",
    "\n",
    "\n",
    "# Major 3 classes\n",
    "major_indices = [idx for idx, label in enumerate(testset.targets) if label in [0, 1, 2]]\n",
    "major_images = torch.stack([testset[idx][0] for idx in major_indices])\n",
    "major_targets = torch.tensor([1] * len(major_indices), dtype=torch.float32)\n",
    "major_test_subset = TensorDataset(major_images, major_targets.view(-1, 1))\n",
    "\n",
    "# Other classes\n",
    "other_indices = [idx for idx, label in enumerate(testset.targets) if label not in [0, 1, 2]]\n",
    "other_images = torch.stack([testset[idx][0] for idx in other_indices])\n",
    "other_targets = torch.tensor([0] * len(other_indices), dtype=torch.float32)\n",
    "other_test_subset = TensorDataset(other_images, other_targets.view(-1, 1))\n",
    "\n",
    "combined_test_dataset = ConcatDataset([major_test_subset, other_test_subset])\n",
    "testloader = DataLoader(combined_test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f294b58-6a1f-4dbe-b75c-3dc60ca04847",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-11T06:24:45.604990Z",
     "iopub.status.busy": "2023-08-11T06:24:45.604689Z",
     "iopub.status.idle": "2023-08-11T06:24:45.613145Z",
     "shell.execute_reply": "2023-08-11T06:24:45.612142Z",
     "shell.execute_reply.started": "2023-08-11T06:24:45.604972Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, 5) # Change the input channel to 1 since MNIST is grayscale\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 5)\n",
    "        self.fc1 = nn.Linear(32 * 4 * 4, 128) # Change the input size to match the output of the last convolutional layer\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # Flatten the output for the fully connected layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "net = Net()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca2f44d-0ae9-4a8a-8962-0a81b135534e",
   "metadata": {},
   "source": [
    "### 2) Train & Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c68cf99-73bc-41d0-8b5e-4d9c15e6ce04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-11T06:24:45.614530Z",
     "iopub.status.busy": "2023-08-11T06:24:45.614307Z",
     "iopub.status.idle": "2023-08-11T06:24:45.627096Z",
     "shell.execute_reply": "2023-08-11T06:24:45.626276Z",
     "shell.execute_reply.started": "2023-08-11T06:24:45.614508Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_network(trainloader, epochs=10):\n",
    "    net = Net()\n",
    "    net.to(device)\n",
    "\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "    return net\n",
    "\n",
    "\n",
    "\n",
    "def evaluate(testloader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    output_distribution = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = net(images)\n",
    "            predicted = (outputs > 0.5).float()\n",
    "            output_distribution.extend(outputs.cpu().numpy())\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy, output_distribution\n",
    "\n",
    "# def evaluate_with_known_OOD_proportion(testloader, major_count):\n",
    "#     major_correct = 0\n",
    "#     other_correct = 0\n",
    "#     total_major = 0\n",
    "#     total_other = 0\n",
    "#     major_output_distribution = []\n",
    "#     other_output_distribution = []\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         for idx, (images, labels) in enumerate(testloader):\n",
    "#             images, labels = images.to(device), labels.to(device)\n",
    "#             outputs = net(images)\n",
    "#             predicted = (outputs > 0.5).float()\n",
    "            \n",
    "#             # Split based on major and other classes\n",
    "#             if idx * 64 < major_count:\n",
    "#                 major_output_distribution.extend(outputs.cpu().numpy())\n",
    "#                 total_major += labels.size(0)\n",
    "#                 major_correct += (predicted == labels).sum().item()\n",
    "#             else:\n",
    "#                 other_output_distribution.extend(outputs.cpu().numpy())\n",
    "#                 total_other += labels.size(0)\n",
    "#                 other_correct += (predicted == labels).sum().item()\n",
    "\n",
    "#     major_accuracy = 100 * major_correct / total_major\n",
    "#     other_accuracy = 100 * other_correct / (len(combined_test_dataset) - major_count)\n",
    "#     return major_accuracy, other_accuracy, major_output_distribution, other_output_distribution\n",
    "\n",
    "\n",
    "def evaluate_with_known_OOD_proportion(testloader, major_count):\n",
    "    major_correct_adaptive = 0\n",
    "    other_correct_adaptive = 0\n",
    "    major_correct_fixed = 0\n",
    "    other_correct_fixed = 0\n",
    "    total_major = 0\n",
    "    total_other = 0\n",
    "    major_output_distribution = []\n",
    "    other_output_distribution = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (images, labels) in enumerate(testloader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = net(images)\n",
    "            \n",
    "            # Record outputs for threshold calculation\n",
    "            if idx * 64 < major_count:\n",
    "                major_output_distribution.extend(outputs.cpu().numpy())\n",
    "            else:\n",
    "                other_output_distribution.extend(outputs.cpu().numpy())\n",
    "\n",
    "        # Calculate adaptive threshold\n",
    "        combined_output_distribution = [item for sublist in major_output_distribution + other_output_distribution for item in sublist]\n",
    "        threshold_adaptive = sorted(combined_output_distribution)[-major_count]\n",
    "\n",
    "        # Calculate accuracy using both adaptive and fixed thresholds\n",
    "        for idx, (images, labels) in enumerate(testloader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = net(images)\n",
    "            predicted_adaptive = (outputs > threshold_adaptive).float()\n",
    "            predicted_fixed = (outputs > 0.5).float()\n",
    "            \n",
    "            if idx * 64 < major_count:\n",
    "                total_major += labels.size(0)\n",
    "                major_correct_adaptive += (predicted_adaptive == labels).sum().item()\n",
    "                major_correct_fixed += (predicted_fixed == labels).sum().item()\n",
    "            else:\n",
    "                total_other += labels.size(0)\n",
    "                other_correct_adaptive += (predicted_adaptive == labels).sum().item()\n",
    "                other_correct_fixed += (predicted_fixed == labels).sum().item()\n",
    "\n",
    "    major_accuracy_adaptive = 100 * major_correct_adaptive / total_major\n",
    "    other_accuracy_adaptive = 100 * other_correct_adaptive / total_other\n",
    "    major_accuracy_fixed = 100 * major_correct_fixed / total_major\n",
    "    other_accuracy_fixed = 100 * other_correct_fixed / total_other\n",
    "\n",
    "    adaptive_average_accuracy = (major_accuracy_adaptive + other_accuracy_adaptive) / 2\n",
    "    fixed_average_accuracy = (major_accuracy_fixed + other_accuracy_fixed) / 2\n",
    "    threshold_adaptive = round(threshold_adaptive, 3)\n",
    "\n",
    "    return fixed_average_accuracy, adaptive_average_accuracy, major_output_distribution, other_output_distribution, threshold_adaptive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "039e439a-5ee2-4057-9959-71ede34876fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-11T06:24:45.628553Z",
     "iopub.status.busy": "2023-08-11T06:24:45.628012Z",
     "iopub.status.idle": "2023-08-11T06:25:13.935206Z",
     "shell.execute_reply": "2023-08-11T06:25:13.933933Z",
     "shell.execute_reply.started": "2023-08-11T06:24:45.628528Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0:\n",
      "Iteration 10:\n",
      "Iteration 20:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m iteration \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIteration \u001b[39m\u001b[38;5;132;01m{\u001b[39;00miteration\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m net \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_network\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m Fixed_threshold_accuracy, Adaptive_threshold_accuracy, major_output_distribution, other_output_distribution, threshold \u001b[38;5;241m=\u001b[39m evaluate_with_known_OOD_proportion(testloader, \u001b[38;5;28mlen\u001b[39m(major_test_subset))\n\u001b[1;32m     17\u001b[0m major_output_distribution \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(major_output_distribution)\u001b[38;5;241m.\u001b[39mflatten()\n",
      "Cell \u001b[0;32mIn[3], line 12\u001b[0m, in \u001b[0;36mtrain_network\u001b[0;34m(trainloader, epochs)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(trainloader, \u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m     11\u001b[0m     inputs, labels \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device), data[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 12\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m net(inputs)\n\u001b[1;32m     14\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n",
      "File \u001b[0;32m~/.venv/torch1.12.1-py3.8-cuda11.3/lib/python3.8/site-packages/torch/optim/optimizer.py:249\u001b[0m, in \u001b[0;36mOptimizer.zero_grad\u001b[0;34m(self, set_to_none)\u001b[0m\n\u001b[1;32m    247\u001b[0m     p\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39mrequires_grad_(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m foreach \u001b[38;5;129;01mor\u001b[39;00m p\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39mis_sparse):\n\u001b[0;32m--> 249\u001b[0m     \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    251\u001b[0m     per_device_and_dtype_grads[p\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39mdevice][p\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39mdtype]\u001b[38;5;241m.\u001b[39mappend(p\u001b[38;5;241m.\u001b[39mgrad)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fixed_threshold_accuracies = []\n",
    "adaptive_threshold_accuracies = []\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "for iteration in range(100):\n",
    "    if iteration % 10 == 0:\n",
    "        print(f\"Iteration {iteration}:\")\n",
    "\n",
    "    net = train_network(trainloader)\n",
    "    \n",
    "    Fixed_threshold_accuracy, Adaptive_threshold_accuracy, major_output_distribution, other_output_distribution, threshold = evaluate_with_known_OOD_proportion(testloader, len(major_test_subset))\n",
    "\n",
    "    major_output_distribution = np.array(major_output_distribution).flatten()\n",
    "    other_output_distribution = np.array(other_output_distribution).flatten()\n",
    "\n",
    "    # print(f'major class: {major_class_num}, minor class: {minor_class_num}')\n",
    "    # print('Accuracy for threshold 0.5:', Fixed_threshold_accuracy, '%')\n",
    "    # print('Accuracy for adaptive threshold:', Adaptive_threshold_accuracy, '%')\n",
    "\n",
    "    # Save the accuracies for later plotting\n",
    "    fixed_threshold_accuracies.append(Fixed_threshold_accuracy)\n",
    "    adaptive_threshold_accuracies.append(Adaptive_threshold_accuracy)\n",
    "    \n",
    "avg_fixed_accuracy = np.mean(fixed_threshold_accuracies)\n",
    "avg_adaptive_accuracy = np.mean(adaptive_threshold_accuracies)\n",
    "print(f'avg_fixed_accuracy: {avg_fixed_accuracy}')\n",
    "print(f'avg_adaptive_accuracy: {avg_adaptive_accuracy}')\n",
    "\n",
    "# Plot the accuracy distributions\n",
    "plt.hist(fixed_threshold_accuracies, bins=10, alpha=0.5, label='Fixed Threshold (0.5)')\n",
    "plt.hist(adaptive_threshold_accuracies, bins=10, alpha=0.5, label='Adaptive Threshold')\n",
    "plt.xlabel('Accuracy')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Accuracies')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "    # # Plotting the distribution for major and minor classes\n",
    "    # plt.hist(major_output_distribution, bins=50, density=True, alpha=0.5, label='Major 3 classes')\n",
    "    # plt.hist(other_output_distribution, bins=50, density=True, alpha=0.5, label='Other classes')\n",
    "    # plt.xlabel('Model Output')\n",
    "    # plt.ylabel('Density')\n",
    "    # plt.title(f'Distribution of Model Outputs')\n",
    "    # plt.axvline(x=0.5, color='red', label='Threshold 0.5')\n",
    "    # plt.axvline(x=threshold, color='green', label=f'Adaptive Threshold')# {threshold}')\n",
    "    # plt.legend(loc='upper right')\n",
    "    # # plt.savefig(f'output_distribution_{iteration}.png') # Save plot as image with iteration number\n",
    "    # plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch1.12.1-py3.8-cuda11.3",
   "language": "python",
   "name": "torch1.12.1-py3.8-cuda11.3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
